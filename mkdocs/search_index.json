{
    "docs": [
        {
            "location": "/", 
            "text": "OpenSensorHub Documentation\n\n\nOpenSensorHub allows one to easily build interoperable and evolutive sensor networks, based on open-standards for all data exchanges, and providing advanced processing capabilities. The open-standards used are mostly \nOGC\n standards from the \nSensor Web Enablement\n (SWE) initiative and are key to design sensor networks that can largely evolve with time (addition of new types of sensors, reconfigurations, etc.).\n\n\nThe Java framework allows one to connect any kind of sensors and actuators to a common bus via a simple yet generic driver API. Sensors can be connected through any available hardware interface such as \nRS232/422\n, \nSPI\n, \nI2C\n, \nUSB\n, \nEthernet\n, \nWifi\n, \nBluetooth\n, \nZigBee\n, \nHTTP\n, etc... Once drivers are available for a specific sensor, it is automatically connected to the bus and it is then trivial to send commands and read data from it. An intuitive user interface allows the user to configure the network to suit its needs and more advanced processing capabilities are available via a plugin system.\n\n\nSensorHub embeds the full power of OGC web services (\nSensor Observation Service\n or SOS, \nSensor Planning Service\n or SPS) to communicate with all connected sensors in the network and provide robust metadata (owner, location and orientation, calibration, etc.). Through these standards, several SensorHub instances can also communicate with each other to form larger networks.\n\n\nLow level functions of SensorHub (send commands and read data from sensor) are coded efficiently and can be used on embedded hardware running \nJava SE\u00ae\n, \nJava ME\u00ae\n or \nAndroid\u00ae\n while more advanced data processing capabilities are fully multi-threaded and can thus benefit from a more powerful hardware platform (e.g. multi-processor servers or even clusters).\n\n\nSensorHub is pure java software but we have plans to release parts of this software in other languages (Arduino, C++) to be used on low power micro-controllers (note that some more powerful ARM micro-controllers can also run the Java version directly using \nJava ME\u00ae\n).\n\n\nIf you're interested in knowing more, this \nFOSS4G Presentation\n gives an overview of SensorHub's architecture and APIs. We also encourage you to read through the technical documentation available on this website.\n\n\nPlease report all problems related to the SensorHub software including documentation errors via the \nGitHub Issue Tracker\n of the corresponding repository.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#opensensorhub-documentation", 
            "text": "OpenSensorHub allows one to easily build interoperable and evolutive sensor networks, based on open-standards for all data exchanges, and providing advanced processing capabilities. The open-standards used are mostly  OGC  standards from the  Sensor Web Enablement  (SWE) initiative and are key to design sensor networks that can largely evolve with time (addition of new types of sensors, reconfigurations, etc.).  The Java framework allows one to connect any kind of sensors and actuators to a common bus via a simple yet generic driver API. Sensors can be connected through any available hardware interface such as  RS232/422 ,  SPI ,  I2C ,  USB ,  Ethernet ,  Wifi ,  Bluetooth ,  ZigBee ,  HTTP , etc... Once drivers are available for a specific sensor, it is automatically connected to the bus and it is then trivial to send commands and read data from it. An intuitive user interface allows the user to configure the network to suit its needs and more advanced processing capabilities are available via a plugin system.  SensorHub embeds the full power of OGC web services ( Sensor Observation Service  or SOS,  Sensor Planning Service  or SPS) to communicate with all connected sensors in the network and provide robust metadata (owner, location and orientation, calibration, etc.). Through these standards, several SensorHub instances can also communicate with each other to form larger networks.  Low level functions of SensorHub (send commands and read data from sensor) are coded efficiently and can be used on embedded hardware running  Java SE\u00ae ,  Java ME\u00ae  or  Android\u00ae  while more advanced data processing capabilities are fully multi-threaded and can thus benefit from a more powerful hardware platform (e.g. multi-processor servers or even clusters).  SensorHub is pure java software but we have plans to release parts of this software in other languages (Arduino, C++) to be used on low power micro-controllers (note that some more powerful ARM micro-controllers can also run the Java version directly using  Java ME\u00ae ).  If you're interested in knowing more, this  FOSS4G Presentation  gives an overview of SensorHub's architecture and APIs. We also encourage you to read through the technical documentation available on this website.  Please report all problems related to the SensorHub software including documentation errors via the  GitHub Issue Tracker  of the corresponding repository.", 
            "title": "OpenSensorHub Documentation"
        }, 
        {
            "location": "/download/", 
            "text": "How To Download\n\n\nReleases\n\n\nBinary and Source distributions archives can be downloaded directly from the \nReleases Section\n of our GitHub account.\n\n\nYou'll soon find there pre-configured distributions for the most common devices such as:\n\n\n\n\nAndroid\n\n\nRaspberry Pi\n\n\nDesktop Linux\n\n\nWindows\n\n\n\n\nSee the \nInstall Section\n for instructions on how to set it up on your device.\n\n\nMaven\n\n\nYou can also use Maven to include OSH in your own project. \nFor instance, if you want to develop a new sensor driver, you can simply add a dependency to the OpenSensorHub Core module in your POM:\n\n\ndependency\n\n   \ngroupId\norg.sensorhub\n/groupId\n\n   \nartifactId\nsensorhub-core\n/artifactId\n\n   \nversion\n1.0\n/version\n\n   \ntype\nbundle\n/type\n\n\n/dependency\n \n\n\n\n\nHowever, OpenSensorHub is not available from Maven Central yet, so you'll also have to include the following repository in your POM:\n\n\nrepositories\n\n   \nrepository\n\n      \nid\nsensiasoft\n/id\n\n      \nurl\nhttp://sensiasoft.net/maven-repo\n/url\n\n   \n/repository\n\n\n/repositories\n   \n\n\n\n\nOur Maven repository is also an OSGI Bundle Repository, so you can also use any OSGI implementation to download Bundles dynamically.", 
            "title": "Download"
        }, 
        {
            "location": "/download/#how-to-download", 
            "text": "Releases  Binary and Source distributions archives can be downloaded directly from the  Releases Section  of our GitHub account.  You'll soon find there pre-configured distributions for the most common devices such as:   Android  Raspberry Pi  Desktop Linux  Windows   See the  Install Section  for instructions on how to set it up on your device.  Maven  You can also use Maven to include OSH in your own project. \nFor instance, if you want to develop a new sensor driver, you can simply add a dependency to the OpenSensorHub Core module in your POM:  dependency \n    groupId org.sensorhub /groupId \n    artifactId sensorhub-core /artifactId \n    version 1.0 /version \n    type bundle /type  /dependency    However, OpenSensorHub is not available from Maven Central yet, so you'll also have to include the following repository in your POM:  repositories \n    repository \n       id sensiasoft /id \n       url http://sensiasoft.net/maven-repo /url \n    /repository  /repositories      Our Maven repository is also an OSGI Bundle Repository, so you can also use any OSGI implementation to download Bundles dynamically.", 
            "title": "How To Download"
        }, 
        {
            "location": "/install/", 
            "text": "How To Install\n\n\nThis page describes how to install OpenSensorHub (OSH for short) binary release so you can test it on your own platform. The process is actually really easy thanks to the use of embedded Jetty, so it should not take you more than 5 minutes to get a running OSH instance on your machine. (\nNOTE: Installation on Android phones and tablets is through a separate APK file\n).\n\n\nPrerequisistes\n\n\nIn order for OSH to run, you will need a working installation of Java JDK 7.\n\n\nOn Linux, we have successfully tested SensorHub with both OpenJDK and Oracle JDK.\n\n\nSetup\n\n\n\n\nFirst download the latest OSH binary release (both 'core' and 'sensors' zip files) from our \nGitHub Release Page\n\n\nUnzip both files to a directory of your choice\n\n\nExecute the \nlaunch.sh\n script (on Linux)\n\n\nYou should now be able to connect to \nhttp://localhost:8181/sensorhub/test\n and get the message \nSensorHub web server is up\n\n\n\n\nNote: This release has been tested on Ubuntu Linux, MacOS X and Windows 7.\n\n\nDemo Configuration\n\n\nThe demo configuration provided with the binary release instructs OSH to start the following components:\n\n\n\n\nThe embedded Jetty server\n\n\nThe web admin UI\n\n\nThe simulated GPS example sensor\n\n\nThe simulated weather example sensor\n\n\nEmbedded storage instances for data produced by the 2 sensors\n\n\nAn SOS service connected to the real-time feeds and storages\n\n\n\n\nConnect to the Sensor Observation Service (SOS)\n\n\nYou can connect to the SOS deployed at \nhttp://localhost:8181/sensorhub/sos\n right away, to get sensor data and metadata:\n\n\n\n\nGetCapabilities\n\n\nGet Weather Result Template\n\n\nGet Latest Weather Measurement\n\n\nGet Historical Weather Measurements\n\n\n\n\nAlso take a look at this simple \ndemo client\n that connects to the fake GPS live feed through websockets to display it on a map using OpenLayers. You can easily reproduce this locally.\n\n\nMore example data feed are also available \nHere\n.\n\n\nConnect to the Admin Console\n\n\nYou can connect to the \nAdmin Console\n at \nhttp://localhost:8181/sensorhub/admin\n.\n\n\nWhen active, the console allows you to manage all OSH modules including sensors, processing chains, storage units, as well as service interfaces such as Sensor Observation Services (SOS) or Sensor Planning Services (SPS).\n\n\nLogging Configuration\n\n\nAll logging is made via logback and the configuration is done via the \nlogback.xml\n file included in the distribution.\nFor instance, you can enable SensorHub debug logs by changing the following line in this file:\n\n\nlogger name=\"org.sensorhub\" level=\"info\"/\n\n\n\n\nto\n\n\nlogger name=\"org.sensorhub\" level=\"debug\"/\n\n\n\n\nSee the \nLogback Documentation\n for more details.", 
            "title": "Installation"
        }, 
        {
            "location": "/install/#how-to-install", 
            "text": "This page describes how to install OpenSensorHub (OSH for short) binary release so you can test it on your own platform. The process is actually really easy thanks to the use of embedded Jetty, so it should not take you more than 5 minutes to get a running OSH instance on your machine. ( NOTE: Installation on Android phones and tablets is through a separate APK file ).  Prerequisistes  In order for OSH to run, you will need a working installation of Java JDK 7.  On Linux, we have successfully tested SensorHub with both OpenJDK and Oracle JDK.  Setup   First download the latest OSH binary release (both 'core' and 'sensors' zip files) from our  GitHub Release Page  Unzip both files to a directory of your choice  Execute the  launch.sh  script (on Linux)  You should now be able to connect to  http://localhost:8181/sensorhub/test  and get the message  SensorHub web server is up   Note: This release has been tested on Ubuntu Linux, MacOS X and Windows 7.  Demo Configuration  The demo configuration provided with the binary release instructs OSH to start the following components:   The embedded Jetty server  The web admin UI  The simulated GPS example sensor  The simulated weather example sensor  Embedded storage instances for data produced by the 2 sensors  An SOS service connected to the real-time feeds and storages   Connect to the Sensor Observation Service (SOS)  You can connect to the SOS deployed at  http://localhost:8181/sensorhub/sos  right away, to get sensor data and metadata:   GetCapabilities  Get Weather Result Template  Get Latest Weather Measurement  Get Historical Weather Measurements   Also take a look at this simple  demo client  that connects to the fake GPS live feed through websockets to display it on a map using OpenLayers. You can easily reproduce this locally.  More example data feed are also available  Here .  Connect to the Admin Console  You can connect to the  Admin Console  at  http://localhost:8181/sensorhub/admin .  When active, the console allows you to manage all OSH modules including sensors, processing chains, storage units, as well as service interfaces such as Sensor Observation Services (SOS) or Sensor Planning Services (SPS).  Logging Configuration  All logging is made via logback and the configuration is done via the  logback.xml  file included in the distribution.\nFor instance, you can enable SensorHub debug logs by changing the following line in this file:  logger name=\"org.sensorhub\" level=\"info\"/   to  logger name=\"org.sensorhub\" level=\"debug\"/   See the  Logback Documentation  for more details.", 
            "title": "How To Install"
        }, 
        {
            "location": "/user-guide/", 
            "text": "User's Guide\n\n\nThis guide will walk you through basics of using OpenSensorHub. I you haven't installed it on your platform yet, please do so first by following instructions on the \nDownload\n and \nInstall\n pages.\n\n\nWeb-based Admin Interface\n\n\nThe easiest way to use SensorHub is via the web-based interface. However, if something is not available from the UI, you can always edit the configuration file manually (See section \nConfiguration File\n). \n\n\nWhen SensorHub is running, you can connect to the following URL to access the administration page:\n\n\nhttp://localhost:8181/sensorhub/admin\n\n\n\nThis admin page allows you to do the following actions:\n\n\n\n\nAdd and configure new sensors (when proper driver was previously installed)\n\n\nAdd and configure sensor data storage\n\n\nAdd and configure SOS and SPS service instances\n\n\nExpose data streams and/or storage through SOS\n\n\nExpose sensor commands through SPS\n\n\n\n\nFor more details, see the \nWeb Admin Interface Manual\n.\n\n\nExample Javascript Clients\n\n\nAn example Javascript client that connects to OSH SOS service is included in the core distribution. This client displays GPS position on the map and receives real-time data via websockets.\nYou can access it \nHere\n.\n\n\nYou can also look at our other demo clients that are running online directly from our \nGitHub Demo Site\n\n\nConfiguration File\n\n\nOpenSensorHub's configuration is centralized in a single file. It is in JSON format so it can be easily viewed or modified in any text editor.\n\n\nThis file contains a list of module's configuration that are loaded in order when starting SensorHub. \n\n\nSWE Services\n\n\nOpenSensorHub includes implementations of standard web service interfaces from the OGC \nSensor Web Enablement\n (SWE) initiative.\n\n\nBelow are topics giving more information about these SWE services:\n\n\n\n\nSensor Observation Service (SOS)\n\n\nSensor Planning Service (SPS)\n\n\n\n\n(*) Modules are loaded in order except if a module needs another module to start. In this case, the dependent module is loaded as needed by the calling module. \n\n\nModule State\n\n\nThe internal state of each module is saved in a subfolder of the \nmodules\n folder whose name is the module's local ID. This folder can contain:\n\n\n\n\nA \nstate.txt\n file containing a list of key/value pairs corresponding to state properties that the module has saved\n\n\nZero or more \n.dat\n files that contain arbitrary data saved by the module", 
            "title": "Introduction"
        }, 
        {
            "location": "/user-guide/#users-guide", 
            "text": "This guide will walk you through basics of using OpenSensorHub. I you haven't installed it on your platform yet, please do so first by following instructions on the  Download  and  Install  pages.  Web-based Admin Interface  The easiest way to use SensorHub is via the web-based interface. However, if something is not available from the UI, you can always edit the configuration file manually (See section  Configuration File ).   When SensorHub is running, you can connect to the following URL to access the administration page:  http://localhost:8181/sensorhub/admin  This admin page allows you to do the following actions:   Add and configure new sensors (when proper driver was previously installed)  Add and configure sensor data storage  Add and configure SOS and SPS service instances  Expose data streams and/or storage through SOS  Expose sensor commands through SPS   For more details, see the  Web Admin Interface Manual .  Example Javascript Clients  An example Javascript client that connects to OSH SOS service is included in the core distribution. This client displays GPS position on the map and receives real-time data via websockets.\nYou can access it  Here .  You can also look at our other demo clients that are running online directly from our  GitHub Demo Site  Configuration File  OpenSensorHub's configuration is centralized in a single file. It is in JSON format so it can be easily viewed or modified in any text editor.  This file contains a list of module's configuration that are loaded in order when starting SensorHub.   SWE Services  OpenSensorHub includes implementations of standard web service interfaces from the OGC  Sensor Web Enablement  (SWE) initiative.  Below are topics giving more information about these SWE services:   Sensor Observation Service (SOS)  Sensor Planning Service (SPS)   (*) Modules are loaded in order except if a module needs another module to start. In this case, the dependent module is loaded as needed by the calling module.   Module State  The internal state of each module is saved in a subfolder of the  modules  folder whose name is the module's local ID. This folder can contain:   A  state.txt  file containing a list of key/value pairs corresponding to state properties that the module has saved  Zero or more  .dat  files that contain arbitrary data saved by the module", 
            "title": "User's Guide"
        }, 
        {
            "location": "/web-admin/", 
            "text": "Web-Admin User Interface\n\n\nTODO", 
            "title": "Web Admin"
        }, 
        {
            "location": "/web-admin/#web-admin-user-interface", 
            "text": "TODO", 
            "title": "Web-Admin User Interface"
        }, 
        {
            "location": "/swe-services/sos/", 
            "text": "Sensor Observation Service (SOS)\n\n\nOpenSensorHub's SOS implementation supports both \nhistorical\n and \nreal-time\n requests for sensor data.\n\n\nHistorical requests are automatically enabled (and properly advertised in the capabilities) when a storage is configured and associated to a sensor. Likewise, real-time requests are automatically enabled when a sensor is directly connected to the SOS (and the sensor module is itself enabled and reports the sensor as connected).\n\n\nRegarding temporal filtering, SensorHub's implementation only supports the \nTEquals\n operator for time instants and \nDuring\n operator for time periods and, currently, filtering can only be done on the 'phenomenonTime' property. The special value 'now' represents the limit between historical and real-time data.\n\n\nThe following tables explain how the server responds to different temporal filter settings:\n\n\nTime Instants\n\n\n\n\n\n\n\n\nBehavior\n\n\nRequest\n\n\n\n\n\n\n\n\n\n\nGet observation at exact time\n\n\ntemporalFilter=phenomenonTime,2014-04-01T00:00:00Z\n\n\n\n\n\n\nGet latest observation\n\n\ntemporalFilter=phenomenonTime,now\n\n\n\n\n\n\n\n\nTime Periods\n\n\nIn all the examples below, 'now' is considered to be at 2014-02-20 and we assume storage contains data until this date.\n\n\n\n\n\n\n\n\nBehavior\n\n\nRequest\n\n\n\n\n\n\n\n\n\n\nGet observations for a historical time range\n\n\ntemporalFilter=phenomenonTime,2014-01-01/2014-02-01\n\n\n\n\n\n\nGet historical data up to the latest observation\n\n\ntemporalFilter=phenomenonTime,2014-01-01/now\n\n\n\n\n\n\nGet real-time stream ending at specific time (1,2)\n\n\ntemporalFilter=phenomenonTime,now/2014-03-01\n\n\n\n\n\n\nGet observations for a time range overlapping past and future (1,3) (\nnot supported for now\n)\n\n\ntemporalFilter=time,2014-01-01/2014-03-01\n\n\n\n\n\n\n\n\n(1) A real-time stream is only available through a persistent connection if sampling period is lower than a certain threshold (usually a few seconds). For lower rate data producers, the subscription service can be used (\nTODO:\n implement SOS subscription service)\n\n\n(2) The stream will be closed as soon as an observation more recent than the end date is produced. A date very far in the future can be used to get a virtually never ending data stream.\n\n\n(3) If real-time streaming is available, the stream will be closed as in (2). Otherwise it will be closed right after the latest available observation has been sent, even if it is much earlier than the end date (i.e. the request will be treated as \ntemporalFilter=time,2014-01-01/now\n).\n\n\nNote: Dates used are in the ISO8601 format and can include the time part or not (e.g. both 2014-01-01Z and 2013-05-06T12:05:00.111Z are valid). When no time is specified, midnight (00:00:00) is assumed.\n\n\nReplay Extension\n\n\nThe SOS implementation also supports replaying historical observations at arbitrary speed (i.e. at real-time speed, or slower/faster than real-time). This is supported by adding the \nreplaySpeed\n parameter to a historical GetResult KVP request, such as in \ntemporalFilter=phenomenonTime,2014-01-01/2014-02-01\nreplaySpeed=2\n. The parameter has no effect for a live stream request (i.e. if the requested period starts at 'now')\n\n\nObservations are replayed at exactly real-time speed (according to observations time tags) with \nreplaySpeed=1\n. The replay value is in fact a factor relative to real-time so that 10 means replaying 10x faster than real-time (if bandwidth permits!) and 0.1 means replaying 10x slower than real-time.\n\n\nSensorHub implements this functionality by pausing the SOS data provider thread just the right amount of time to match the period infered by two successive measurement time stamps.", 
            "title": "SOS Service"
        }, 
        {
            "location": "/swe-services/sos/#sensor-observation-service-sos", 
            "text": "OpenSensorHub's SOS implementation supports both  historical  and  real-time  requests for sensor data.  Historical requests are automatically enabled (and properly advertised in the capabilities) when a storage is configured and associated to a sensor. Likewise, real-time requests are automatically enabled when a sensor is directly connected to the SOS (and the sensor module is itself enabled and reports the sensor as connected).  Regarding temporal filtering, SensorHub's implementation only supports the  TEquals  operator for time instants and  During  operator for time periods and, currently, filtering can only be done on the 'phenomenonTime' property. The special value 'now' represents the limit between historical and real-time data.  The following tables explain how the server responds to different temporal filter settings:  Time Instants     Behavior  Request      Get observation at exact time  temporalFilter=phenomenonTime,2014-04-01T00:00:00Z    Get latest observation  temporalFilter=phenomenonTime,now     Time Periods  In all the examples below, 'now' is considered to be at 2014-02-20 and we assume storage contains data until this date.     Behavior  Request      Get observations for a historical time range  temporalFilter=phenomenonTime,2014-01-01/2014-02-01    Get historical data up to the latest observation  temporalFilter=phenomenonTime,2014-01-01/now    Get real-time stream ending at specific time (1,2)  temporalFilter=phenomenonTime,now/2014-03-01    Get observations for a time range overlapping past and future (1,3) ( not supported for now )  temporalFilter=time,2014-01-01/2014-03-01     (1) A real-time stream is only available through a persistent connection if sampling period is lower than a certain threshold (usually a few seconds). For lower rate data producers, the subscription service can be used ( TODO:  implement SOS subscription service)  (2) The stream will be closed as soon as an observation more recent than the end date is produced. A date very far in the future can be used to get a virtually never ending data stream.  (3) If real-time streaming is available, the stream will be closed as in (2). Otherwise it will be closed right after the latest available observation has been sent, even if it is much earlier than the end date (i.e. the request will be treated as  temporalFilter=time,2014-01-01/now ).  Note: Dates used are in the ISO8601 format and can include the time part or not (e.g. both 2014-01-01Z and 2013-05-06T12:05:00.111Z are valid). When no time is specified, midnight (00:00:00) is assumed.  Replay Extension  The SOS implementation also supports replaying historical observations at arbitrary speed (i.e. at real-time speed, or slower/faster than real-time). This is supported by adding the  replaySpeed  parameter to a historical GetResult KVP request, such as in  temporalFilter=phenomenonTime,2014-01-01/2014-02-01 replaySpeed=2 . The parameter has no effect for a live stream request (i.e. if the requested period starts at 'now')  Observations are replayed at exactly real-time speed (according to observations time tags) with  replaySpeed=1 . The replay value is in fact a factor relative to real-time so that 10 means replaying 10x faster than real-time (if bandwidth permits!) and 0.1 means replaying 10x slower than real-time.  SensorHub implements this functionality by pausing the SOS data provider thread just the right amount of time to match the period infered by two successive measurement time stamps.", 
            "title": "Sensor Observation Service (SOS)"
        }, 
        {
            "location": "/swe-services/sps/", 
            "text": "Sensor Planning Service (SPS)\n\n\nTODO", 
            "title": "SPS Service"
        }, 
        {
            "location": "/swe-services/sps/#sensor-planning-service-sps", 
            "text": "TODO", 
            "title": "Sensor Planning Service (SPS)"
        }, 
        {
            "location": "/dev-guide/", 
            "text": "Developer's Guide\n\n\nThis guide is meant to help you setup a development environment based on the Eclipse IDE so that you can extend OpenSensorHub (OSH for short) with your own sensor drivers, web services and other components.\n\n\nDon't forget to send us a Pull Request if you want to contribute your work back to this project. Other users may be interested by your modules and bug fixes! \n\n\nOf course, contributing new modules to the community is optional as our license does not prevent proprietary and commercial derived work. However, keep in mind that \nif you modify the source files we provide, you must make it available publicly in source form\n. \n\n\nThis page provides instructions for three possible options, depending on your level of involvement:\n\n\n\n\nExploring the code online\n\n\nDownloading and building from source with Maven or Eclipse\n\n\nContributing software and fixes to the project\n\n\n\n\nExploring the Code\n\n\nIf you just want to explore the code, you can browse the source online directly on \nGithub\n. Alternatively, you can download it to your computer using the \nDownload ZIP\n link on each GitHub repository or using the \ngit\n program (please see the next section if you want to do just that).\n\n\nTo start with, the repositories of interest are \nOpenSensorHub Core\n and \nSensor Drivers\n.\n\n\nBuilding from Source\n\n\nBelow are the steps to download and build the code using either command line tools or the Eclipse IDE.\n\n\nUsing Command-Line Tools\n\n\nIf you want to build the code and run it on your computer, you'll need \ngit\n and \nMaven 3\n.\nTo clone the code repository locally, first create a directory called \nopensensorhub\n (or anything else you want really) and \ncd\n in this directory:\n\n\n$ mkdir opensensorhub\n$ cd opensensorhub\n\n\n\n\nThen and use the following commands to clone the two main repositories:\n\n\n$ git clone --recursive https://github.com/opensensorhub/osh-core\n$ git clone https://github.com/opensensorhub/osh-sensors\n\n\n\n\nThis will create folders containing the code of the different Maven modules. You can also clone other repositories of the project to get other types of modules. The \nservices\n and \nsecurity\n repositories are probably of interest if you want to go further. There are also some Android specific modules in the \nandroid\n repository if you are interested in deploying on Android.\n\n\nYou can then build the project and install it to your local Maven repository by launching the following commands:\n\n\nFirst build the core modules:\n\n\n$ cd core\n$ mvn clean install \n\n\n\n\nThen build the sensor drivers you are interested in. To start with, you can build the simulated sensor since they don't require you to connect any hardware.\n\n\n$ cd ../osh-sensors/sensorhub-driver-fakegps\n$ mvn clean install\n$ cd ../sensorhub-driver-fakeweather\n$ mvn clean install\n\n\n\n\nNote 1: The first time you launch Maven, the build process can take a while because Maven goes to fetch its own dependencies (i.e. Maven plugins) as well as OpenSensorHub's dependencies. Later builds will go faster because these dependencies are cached in a local Maven repository.\n\n\nNote 2: Some of the JUnit tests automatically run during the 'test' phase of the OSH build process need to instantiate a server on port 8888. These tests will fail if something else is running on this port when you launch the commands above.\n\n\nYou can then run OpenSensorHub with an example configuration file. For instance, the following command launches OpenSensorHub configured with some simulated sensors, storage databases and an SOS service:\n\n\n$ cd ../../osh-core/sensorhub-test\n$ mvn -N -e exec:java -Dexec.mainClass=\norg.sensorhub.impl.SensorHub\n -Dexec.args=\nsensorhub-test/src/test/resources/config_fakesensors_with_storage.json db\n\n\n\n\n\nUsing Eclipse\n\n\nWe provide Eclipse project configuration directly from the repository so it is the easiest way to get started, especially if you're already familiar with Eclipse. \n\n\nPre-requisites\n\n\nMake sure you have the following Eclipse components installed:\n\n\n\n\nEclipse Helios or newer (the exact steps described here are for Luna)\n\n\nEgit plugin for Eclipse (included in \"Eclipse IDE for Java Developers\" release)\n\n\nMaven plugin for Eclipse M2E (you can install it using the \"Help \n Install New Software..\". You will find it under the \"Collaboration\" section of the Eclipse releases repository) \n\n\n\n\nClone the project in your Eclipse workspace\n\n\n\n\nIn the Package Explorer, right click and select \"Import\" from the popup menu\n\n\nOpen the \"Git\" category, select \"Projects from Git\" and click \"Next\"\n\n\nSelect \"Clone URI\" and click \"Next\"\n\n\nIn the \"URI\" text box, enter the URL of the OpenSensorHub Core repository \nhttps://github.com/opensensorhub/osh-core.git\n and click \"Next\"\n\n\nLeave \"master\" selected and click \"Next\"\n\n\nYou can leave the Directory settings as-is on this page or change it to the location of your choice (Note that the Egit manual discourages cloning directly in the Eclipse workspace for performance reasons, however we haven't had any issue doing this with the opensensorhub code base. If you want to do like us, change the \"Directory\" to points directly to a sub-directory of your Eclipse workspace, for instance, \"/home/user/workspace/osh-core\")\n\n\nSelect \"Clone submodules\" and click \"Next\"\n\n\nAfter the download is complete, leave \"Import existing projects\" selected and click \"Next\"\n\n\nLeave all projects selected and click \"Finish\"\n\n\nAll projects should be imported successfully and visible in the \"Package Explorer\". Everything should compile without error.\n\n\nIf you like to keep your workspace tidy, you can group all the projects we just imported in a single Working Set\n\n\n\n\nRepeat the steps above with the desired repositories of the opensensorhub github account. You'll need at least some sensor drivers to test the software. You can get these from the following repository:\n\n\nhttps://github.com/opensensorhub/osh-sensors.git\n\n\nThere may be other repositories of interest for you:\n\n\n\n\nAndroid: \nhttps://github.com/opensensorhub/osh-android.git\n\n\nOther Services : \nhttps://github.com/opensensorhub/osh-services.git\n\n\nData-Processing : \nhttps://github.com/opensensorhub/osh-processing.git\n\n\nSecurity Stuff : \nhttps://github.com/opensensorhub/osh-security.git\n\n\n\n\nContributing\n\n\nIf you want to contribute, we feel the best way is that you create your own fork on GitHub, work on it, and when you have something working and tested, send us a Pull Request. To set this up, please follow the steps below:\n\n\nFork one or more repository of the project\n\n\nThe first step is to fork a repo by clicking the \nFork\n button on GitHub. This will clone the original code to your own GitHub account so you can then modify it and/or add to it as you wish. For this you'll need to have a GitHub account (it can be done in 30s using your email address) and log into it.\n\n\nForking the project this way will allow you to send us \nPull Requests\n via GitHub which makes it much easier for us to incorporate your contribution to the master branch. In addition, it creates a community around the software and lets others see what contributors are up to even before a patch is submitted. This can help you get the proper guidance when necessary.\n\n\nClone your GitHub repository\n\n\nClone your new GitHub repository locally by following the steps in the \nBuilding from Source\n section except you'll be using your own fork URL (e.g. https://github.com/yourusername/osh-*\n) instead of the \nopensensorhub\n version.\n\n\nWork on something new!\n\n\nYou can then start modifying the code and/or add new modules/features. We don't have coding guidelines yet but try to mimic the code that is already there. Don't forget to include Javadoc, especially on public parts of your APIs, and also inline comments explaining the different steps of your code.\n\n\nWhether you're trying to fix bugs or adding a brand new functionality, don't hesitate to tell us early-on what you're planning to work on. We may be able to point you in the right direction or maybe to somebody who has similar needs than you.\n\n\nYou can start by reading the instructions to \nCreate a New Module\n and \nAdd a New Sensor Driver\n for instance.\n\n\nAlso see the \nEclipse Tips\n section if you encounter problems while creating a new module.\n\n\nGet the latest updates from us\n\n\nWhile you're working on your stuff, don't forget to pull changes from the main repository once in a while. This will greatly help us merge your changes into the main branch when we receive your Pull Request. You can either do that from command line git or within Eclipse:\n\n\nUsing the \ngit\n command\n\n\nFirst add a new remote pointing to the \nopensensorhub\n master branch (you only have to do that the first time). For example, for the osh-core repository:\n\n\n$ git remote add upstream https://github.com/opensensorhub/osh-core\n\n\n\n\nThen pull changes from the \"upstream\" remote:\n\n\n$ git pull upstream master\n$ git submodule update\n\n\n\n\nNote 1: The \nsubmodule update\n command is only required in the \nosh-core\n repo that has submodules.\n\n\nNote 2: that you may have to manually merge things with your working copy if you have made conflicting changes.\n\n\nUsing Eclipse\n\n\nFirst add a new remote pointing to the \nopensensorhub\n master branch (you only have to do that the first time):\n\n\n\n\nOpen the \"Git Repositories\" view (Window -\n Show view -\n Other -\n Git)\n\n\nOpen the \"sensorhub\" repository, right click on \"Remotes\" and select \"Create Remote\"\n\n\nEnter \"upstream\" as the remote name, select \"Configure fetch\" and click \"OK\"\n\n\nClick the \"Change\" button next to the URI text box\n\n\nEnter \nhttps://github.com/opensensorhub/osh-core\n as the URI and click \"Finish\"\n\n\nClick \"Save\"\n\n\n\n\nThen pull changes from the \"upstream\" remote:\n\n\n\n\nOpen the \"Git Repositories\" view (Window -\n Show view -\n Other -\n Git)\n\n\nRight click on the \"osh-core\" repository and select \"Remote -\n Fetch\" in the popup menu\n\n\nSelect the \"opensensorhub\" remote in the \"Configured remote repository\" item and click \"Finish\"\n\n\nRight click on the \"Submodules\" folder and select \"Update Submodule\" from the popup menu\n\n\n\n\nYou'll then eventually have to merge our changes with yours using the Egit merge command. Please see \nGit Documentation\n for more details\n\n\nNote: Also don't forget to import new Eclipse projects that may have been added since your last update. For this, follow these steps:\n\n\n\n\nRight click in your workspace and select \"Import...\" in the context menu\n\n\nSelect \"Existing project into workspace\" from the \"General\" section and click \"Next\"\n\n\nBrowse to the folder where you cloned our repo (usually called \"osh-core\" for the core software)\n\n\nSelect the missing projects in the list (all the projects that are not already in your workspace should already be selected) and click \"Finish\"   \n\n\n\n\nPush your changes to your own repo\n\n\nYou can push your changes to your own GitHub repo at any time, even if your code doesn't work yet. Remember this is your own sandbox so you won't mess up anybody else code base. We actually recommend that you do that often since it will provide you a good backup of your work, with full history.\n\n\nYou won't be able to push directly to the opensensorhub repos directly since you don't have write permissions (not until you become part of the team anyway). \n\n\nUsing the \ngit\n command\n\n\nTo do this with git command line tool, first stage and commit your changes locally:\n\n\n$ git commit -am \nYour commit message\n\n\n\n\n\nand then push them to your remote GitHub repository:\n\n\n$ git push\n\n\n\n\n(Please see the \ngit online documentation\n for more details and other ways to use git)\n\n\nUsing Eclipse\n\n\nWithin Eclipse, follow these steps:\n\n\nTo commit your changes locally:\n\n\n\n\nRight click on one of the Eclipse project with a name starting with \"sensorhub\"\n\n\nSelect \"Team -\n Commit\" from the popup menu\n\n\nEnter a commit message and select files you want to commit\n\n\nClick \"Commit\" (or \"Commit and Push\" if you want to commit locally and push to your remote repository in a single step)\n\n\nIf you have just pressed \"Commit\" you will see a arrow with a number on the right of the project names in the package explorer. This indicates that you have N local changes that need to be pushed to the remote repository (i.e. in git terms, your local repository is N commits ahead of your remote).\n\n\n\n\nIf you only want to push your last committed changes to your remote repository:\n\n\n\n\nRight click on one of the Eclipse project with a name starting with \"sensorhub\"\n\n\nSelect \"Team -\n Push to Upstream\" from the popup menu\n\n\nClick OK\n\n\n\n\n(Please see \nEgit online documentation\n for more advanced functionality)\n\n\nContribute your code\n\n\nWhen you feel you're ready to contribute all or some of your changes to the community, please send us a \nPull Request\n via GitHub.\n\n\nSo that we can better evaluate your contribution, please describe your improvements in as much details as you can. We'll do our best to process \nPull Request\n as fast as possible.\n\n\nThanks in advance for your contribution!\n\n\nEclipse Tips\n\n\nUpdate Maven Settings\n\n\nOne problem we have encountered several times with Eclipse is that the POM files and Projects Settings get out of sync and it causes various Java and/or Maven related dependency errors (e.g. dependency YYY cannot be found, etc). If you get such errors even though everything seems fine in your POM and code, you may have to follow these steps to resync eveything:\n\n\n\n\nClick one of the SensorHub module project\n\n\nSelect \"Maven \n Update Project...\" from the context menu\n\n\nClick the \"Select All\" button\n\n\nConfirm by clicking \"OK\"", 
            "title": "Introduction"
        }, 
        {
            "location": "/dev-guide/#developers-guide", 
            "text": "This guide is meant to help you setup a development environment based on the Eclipse IDE so that you can extend OpenSensorHub (OSH for short) with your own sensor drivers, web services and other components.  Don't forget to send us a Pull Request if you want to contribute your work back to this project. Other users may be interested by your modules and bug fixes!   Of course, contributing new modules to the community is optional as our license does not prevent proprietary and commercial derived work. However, keep in mind that  if you modify the source files we provide, you must make it available publicly in source form .   This page provides instructions for three possible options, depending on your level of involvement:   Exploring the code online  Downloading and building from source with Maven or Eclipse  Contributing software and fixes to the project   Exploring the Code  If you just want to explore the code, you can browse the source online directly on  Github . Alternatively, you can download it to your computer using the  Download ZIP  link on each GitHub repository or using the  git  program (please see the next section if you want to do just that).  To start with, the repositories of interest are  OpenSensorHub Core  and  Sensor Drivers .  Building from Source  Below are the steps to download and build the code using either command line tools or the Eclipse IDE.  Using Command-Line Tools  If you want to build the code and run it on your computer, you'll need  git  and  Maven 3 .\nTo clone the code repository locally, first create a directory called  opensensorhub  (or anything else you want really) and  cd  in this directory:  $ mkdir opensensorhub\n$ cd opensensorhub  Then and use the following commands to clone the two main repositories:  $ git clone --recursive https://github.com/opensensorhub/osh-core\n$ git clone https://github.com/opensensorhub/osh-sensors  This will create folders containing the code of the different Maven modules. You can also clone other repositories of the project to get other types of modules. The  services  and  security  repositories are probably of interest if you want to go further. There are also some Android specific modules in the  android  repository if you are interested in deploying on Android.  You can then build the project and install it to your local Maven repository by launching the following commands:  First build the core modules:  $ cd core\n$ mvn clean install   Then build the sensor drivers you are interested in. To start with, you can build the simulated sensor since they don't require you to connect any hardware.  $ cd ../osh-sensors/sensorhub-driver-fakegps\n$ mvn clean install\n$ cd ../sensorhub-driver-fakeweather\n$ mvn clean install  Note 1: The first time you launch Maven, the build process can take a while because Maven goes to fetch its own dependencies (i.e. Maven plugins) as well as OpenSensorHub's dependencies. Later builds will go faster because these dependencies are cached in a local Maven repository.  Note 2: Some of the JUnit tests automatically run during the 'test' phase of the OSH build process need to instantiate a server on port 8888. These tests will fail if something else is running on this port when you launch the commands above.  You can then run OpenSensorHub with an example configuration file. For instance, the following command launches OpenSensorHub configured with some simulated sensors, storage databases and an SOS service:  $ cd ../../osh-core/sensorhub-test\n$ mvn -N -e exec:java -Dexec.mainClass= org.sensorhub.impl.SensorHub  -Dexec.args= sensorhub-test/src/test/resources/config_fakesensors_with_storage.json db   Using Eclipse  We provide Eclipse project configuration directly from the repository so it is the easiest way to get started, especially if you're already familiar with Eclipse.   Pre-requisites  Make sure you have the following Eclipse components installed:   Eclipse Helios or newer (the exact steps described here are for Luna)  Egit plugin for Eclipse (included in \"Eclipse IDE for Java Developers\" release)  Maven plugin for Eclipse M2E (you can install it using the \"Help   Install New Software..\". You will find it under the \"Collaboration\" section of the Eclipse releases repository)    Clone the project in your Eclipse workspace   In the Package Explorer, right click and select \"Import\" from the popup menu  Open the \"Git\" category, select \"Projects from Git\" and click \"Next\"  Select \"Clone URI\" and click \"Next\"  In the \"URI\" text box, enter the URL of the OpenSensorHub Core repository  https://github.com/opensensorhub/osh-core.git  and click \"Next\"  Leave \"master\" selected and click \"Next\"  You can leave the Directory settings as-is on this page or change it to the location of your choice (Note that the Egit manual discourages cloning directly in the Eclipse workspace for performance reasons, however we haven't had any issue doing this with the opensensorhub code base. If you want to do like us, change the \"Directory\" to points directly to a sub-directory of your Eclipse workspace, for instance, \"/home/user/workspace/osh-core\")  Select \"Clone submodules\" and click \"Next\"  After the download is complete, leave \"Import existing projects\" selected and click \"Next\"  Leave all projects selected and click \"Finish\"  All projects should be imported successfully and visible in the \"Package Explorer\". Everything should compile without error.  If you like to keep your workspace tidy, you can group all the projects we just imported in a single Working Set   Repeat the steps above with the desired repositories of the opensensorhub github account. You'll need at least some sensor drivers to test the software. You can get these from the following repository:  https://github.com/opensensorhub/osh-sensors.git  There may be other repositories of interest for you:   Android:  https://github.com/opensensorhub/osh-android.git  Other Services :  https://github.com/opensensorhub/osh-services.git  Data-Processing :  https://github.com/opensensorhub/osh-processing.git  Security Stuff :  https://github.com/opensensorhub/osh-security.git   Contributing  If you want to contribute, we feel the best way is that you create your own fork on GitHub, work on it, and when you have something working and tested, send us a Pull Request. To set this up, please follow the steps below:  Fork one or more repository of the project  The first step is to fork a repo by clicking the  Fork  button on GitHub. This will clone the original code to your own GitHub account so you can then modify it and/or add to it as you wish. For this you'll need to have a GitHub account (it can be done in 30s using your email address) and log into it.  Forking the project this way will allow you to send us  Pull Requests  via GitHub which makes it much easier for us to incorporate your contribution to the master branch. In addition, it creates a community around the software and lets others see what contributors are up to even before a patch is submitted. This can help you get the proper guidance when necessary.  Clone your GitHub repository  Clone your new GitHub repository locally by following the steps in the  Building from Source  section except you'll be using your own fork URL (e.g. https://github.com/yourusername/osh-* ) instead of the  opensensorhub  version.  Work on something new!  You can then start modifying the code and/or add new modules/features. We don't have coding guidelines yet but try to mimic the code that is already there. Don't forget to include Javadoc, especially on public parts of your APIs, and also inline comments explaining the different steps of your code.  Whether you're trying to fix bugs or adding a brand new functionality, don't hesitate to tell us early-on what you're planning to work on. We may be able to point you in the right direction or maybe to somebody who has similar needs than you.  You can start by reading the instructions to  Create a New Module  and  Add a New Sensor Driver  for instance.  Also see the  Eclipse Tips  section if you encounter problems while creating a new module.  Get the latest updates from us  While you're working on your stuff, don't forget to pull changes from the main repository once in a while. This will greatly help us merge your changes into the main branch when we receive your Pull Request. You can either do that from command line git or within Eclipse:  Using the  git  command  First add a new remote pointing to the  opensensorhub  master branch (you only have to do that the first time). For example, for the osh-core repository:  $ git remote add upstream https://github.com/opensensorhub/osh-core  Then pull changes from the \"upstream\" remote:  $ git pull upstream master\n$ git submodule update  Note 1: The  submodule update  command is only required in the  osh-core  repo that has submodules.  Note 2: that you may have to manually merge things with your working copy if you have made conflicting changes.  Using Eclipse  First add a new remote pointing to the  opensensorhub  master branch (you only have to do that the first time):   Open the \"Git Repositories\" view (Window -  Show view -  Other -  Git)  Open the \"sensorhub\" repository, right click on \"Remotes\" and select \"Create Remote\"  Enter \"upstream\" as the remote name, select \"Configure fetch\" and click \"OK\"  Click the \"Change\" button next to the URI text box  Enter  https://github.com/opensensorhub/osh-core  as the URI and click \"Finish\"  Click \"Save\"   Then pull changes from the \"upstream\" remote:   Open the \"Git Repositories\" view (Window -  Show view -  Other -  Git)  Right click on the \"osh-core\" repository and select \"Remote -  Fetch\" in the popup menu  Select the \"opensensorhub\" remote in the \"Configured remote repository\" item and click \"Finish\"  Right click on the \"Submodules\" folder and select \"Update Submodule\" from the popup menu   You'll then eventually have to merge our changes with yours using the Egit merge command. Please see  Git Documentation  for more details  Note: Also don't forget to import new Eclipse projects that may have been added since your last update. For this, follow these steps:   Right click in your workspace and select \"Import...\" in the context menu  Select \"Existing project into workspace\" from the \"General\" section and click \"Next\"  Browse to the folder where you cloned our repo (usually called \"osh-core\" for the core software)  Select the missing projects in the list (all the projects that are not already in your workspace should already be selected) and click \"Finish\"      Push your changes to your own repo  You can push your changes to your own GitHub repo at any time, even if your code doesn't work yet. Remember this is your own sandbox so you won't mess up anybody else code base. We actually recommend that you do that often since it will provide you a good backup of your work, with full history.  You won't be able to push directly to the opensensorhub repos directly since you don't have write permissions (not until you become part of the team anyway).   Using the  git  command  To do this with git command line tool, first stage and commit your changes locally:  $ git commit -am  Your commit message   and then push them to your remote GitHub repository:  $ git push  (Please see the  git online documentation  for more details and other ways to use git)  Using Eclipse  Within Eclipse, follow these steps:  To commit your changes locally:   Right click on one of the Eclipse project with a name starting with \"sensorhub\"  Select \"Team -  Commit\" from the popup menu  Enter a commit message and select files you want to commit  Click \"Commit\" (or \"Commit and Push\" if you want to commit locally and push to your remote repository in a single step)  If you have just pressed \"Commit\" you will see a arrow with a number on the right of the project names in the package explorer. This indicates that you have N local changes that need to be pushed to the remote repository (i.e. in git terms, your local repository is N commits ahead of your remote).   If you only want to push your last committed changes to your remote repository:   Right click on one of the Eclipse project with a name starting with \"sensorhub\"  Select \"Team -  Push to Upstream\" from the popup menu  Click OK   (Please see  Egit online documentation  for more advanced functionality)  Contribute your code  When you feel you're ready to contribute all or some of your changes to the community, please send us a  Pull Request  via GitHub.  So that we can better evaluate your contribution, please describe your improvements in as much details as you can. We'll do our best to process  Pull Request  as fast as possible.  Thanks in advance for your contribution!  Eclipse Tips  Update Maven Settings  One problem we have encountered several times with Eclipse is that the POM files and Projects Settings get out of sync and it causes various Java and/or Maven related dependency errors (e.g. dependency YYY cannot be found, etc). If you get such errors even though everything seems fine in your POM and code, you may have to follow these steps to resync eveything:   Click one of the SensorHub module project  Select \"Maven   Update Project...\" from the context menu  Click the \"Select All\" button  Confirm by clicking \"OK\"", 
            "title": "Developer's Guide"
        }, 
        {
            "location": "/architecture/", 
            "text": "Architecture\n\n\nThis page describes some of the key architecture and design principles used within OpenSensorHub. These are important concepts to understand if you want to contribute to the core or develop your own SensorHub modules (e.g. sensor drivers, database bindings, etc.)\n\n\nThe Event Bus\n\n\nSensorHub is designed around a generic bus through which transits all events coming from and going to the connected sensors and processes. SensorHub drivers convert standard or proprietary sensor/actuators protocols to the SWE common format so that the data can be communicated through the bus and made available to all other SensorHub components.\n\n\n\n\nAll data sent through the bus is described using the \nSWE Common Data Model\n so that each message is auto-describing and can be decoded by any sub-function connected to it.\n\n\nThe persistence engine is also connected to the bus and can archive the desired messages (data, commands, status info, etc...).\n\n\nWeb services that use real-time data are also connected to the bus and can distribute any data through standard web interfaces such as the \nSensor Observation Service\n from OGC.\n\n\nSensor Drivers\n\n\nDrivers are responsible for converting data going to and from the sensors into \nSWE Common\n messages, as well as for building a \nSensorML\n description of the connected sensor. The sensor is then always represented by this description in the system.\n\n\nWhenever possible, this description is fully or partially generated automatically from information stored in the sensor device (i.e serial number, calibration tables, etc.). If the sensor does not contain any such information, the driver generates a very simple document containing only the sensor ID, type and measurement output structure. In any case, this SensorML description can be further completed by the user when installing the sensor (the user will have to input the sensor location for instance).\n\n\nSensor drivers can be programmed to send data to the bus in various manners :\n  * In 'push' mode, the sensor is programmed to make measurements at regular intervals or when certain conditions are met. In this case, the user does not request a reading explicitely.\n  * In 'poll' mode, the user requests a reading from the sensor everytime. If no requests are made, no data is read.\nBoth modes can be mixed.\n\n\nPersistence/Storage Modules\n\n\nThe persistence engine is able to store any data that transits on the bus in a persistent storage. A simple API and several storage implementations are provided as part of the SensorHub software :\n\n\n\n\n\n\nThe \nPERST\n based storage uses a pure Java embedded object database which allows very efficient storage of data with a very small footprint (typically for embedded devices). See the [DataPersistencePERST PERST persistence page] for more details.\n\n\n\n\n\n\nThe \nPostgreSQL/PostGIS\n storage allows storing of SWE Common data in a robust SQL database but requires more powerful hardware and a database server to run.\n\n\n\n\n\n\nIn both cases, the database schema used is generic and can be used to store any data structure described in SWE Common and allows indexes on the specified fields.\n\n\nThe administration console allows the user to select what messages are to be stored and how (i.e. table name, what indexes should be created, etc.).\n\n\nWeb Service Modules\n\n\nWeb services can be developed and connected to other SensorHub modules to provide remote access to the different functions. SensorHub software already contains useful OGC services designed to communicate bi-directionnally with the connected sensors:\n\n\n\n\n\n\nThe Sensor Observation Service (SOS)\n is connected to the bus and to the persistent storage and allows retrieval of historical data as well as real-time data measurements.\n\n\n\n\n\n\nThe Sensor Planning Service (SPS)\n is connected to the bus and allows to send commands to the connected sensor.\n\n\n\n\n\n\nA simple \nWeb Feature Service (WFS)\n is connected to the sensor registry and allows one to retrieve the full SensorML descriptions of all connected sensors as well as simplified features containing only the name and location of the sensors for display on a map.\n\n\n\n\n\n\nAll web services are configurable through the administration web interface but most of the configuration is extracted automatically from the SensorML description of the sensors. The user mainly selects what sensor outputs should be exposed through SOS and/or what sensor parameters should be able to receive commands from SPS.\n\n\nProcessing Modules\n\n\nThe processing module is connected to the bus and the persistent storage and allows deployment of several processing instances that can either process data transiting on the bus (aka event-based or streaming processing) or process data from the storage on-demand (aka on-demand processing).\n\n\nProcess chains can be configured using the SensorML language so that new algorithms can be easily created without writing any code simply by connecting basic functions in the diagram editor (not currently available). However, the use of SensorML is not required and one can also write a plain Java plugin compliant with the processing API for implementing a particular algorithm.\n\n\nExample Deployment\n\n\nThe diagram below shows an example OSH instance configured with one sensor, one processing module, one storage module, SOS and SPS web services :\n\n\n\n\n\n\n\n\nThe sensor is connected via a proper sensor driver that pushes data to the bus as soon as it's available. Full description of the data structure is made available to other module via the sensor API.\n\n\n\n\n\n\nThe processing module instance listens to new sensor data and processes it as soon as it's available. The result is pushed back to the bus. Inputs and outputs are fully described in SensorML.\n\n\n\n\n\n\nThe storage module instance listens to both raw sensor and processed data and archives it all in a file or database. The archived data is then indexed and made available via the persistence API.\n\n\n\n\n\n\nThe SOS service can subscribe to and stream real-time sensor data when a user requests direct connection to it. It can also fetch data from archive storage on demand. In this case, data can be filtered by time, location, etc.\n\n\n\n\n\n\nThe SPS service is used to send commands to the sensor, such as turning the sensor on/off, changing the sampling rate, programming measurement triggers, etc. \n\n\n\n\n\n\nOf course, this is just an example and there are many more ways of configuring SensorHub. In particular, it is possible to :\n\n\n\n\n\n\nConnect several instances of SensorHub via standard OGC services so that one can create a larger network.\n\n\n\n\n\n\nImplement feedback loops so that one sensor can be used to trigger different behavior of another sensor.\n\n\n\n\n\n\nImplement complex processing flows that fuse data from many different sensors", 
            "title": "Architecture"
        }, 
        {
            "location": "/architecture/#architecture", 
            "text": "This page describes some of the key architecture and design principles used within OpenSensorHub. These are important concepts to understand if you want to contribute to the core or develop your own SensorHub modules (e.g. sensor drivers, database bindings, etc.)  The Event Bus  SensorHub is designed around a generic bus through which transits all events coming from and going to the connected sensors and processes. SensorHub drivers convert standard or proprietary sensor/actuators protocols to the SWE common format so that the data can be communicated through the bus and made available to all other SensorHub components.   All data sent through the bus is described using the  SWE Common Data Model  so that each message is auto-describing and can be decoded by any sub-function connected to it.  The persistence engine is also connected to the bus and can archive the desired messages (data, commands, status info, etc...).  Web services that use real-time data are also connected to the bus and can distribute any data through standard web interfaces such as the  Sensor Observation Service  from OGC.  Sensor Drivers  Drivers are responsible for converting data going to and from the sensors into  SWE Common  messages, as well as for building a  SensorML  description of the connected sensor. The sensor is then always represented by this description in the system.  Whenever possible, this description is fully or partially generated automatically from information stored in the sensor device (i.e serial number, calibration tables, etc.). If the sensor does not contain any such information, the driver generates a very simple document containing only the sensor ID, type and measurement output structure. In any case, this SensorML description can be further completed by the user when installing the sensor (the user will have to input the sensor location for instance).  Sensor drivers can be programmed to send data to the bus in various manners :\n  * In 'push' mode, the sensor is programmed to make measurements at regular intervals or when certain conditions are met. In this case, the user does not request a reading explicitely.\n  * In 'poll' mode, the user requests a reading from the sensor everytime. If no requests are made, no data is read.\nBoth modes can be mixed.  Persistence/Storage Modules  The persistence engine is able to store any data that transits on the bus in a persistent storage. A simple API and several storage implementations are provided as part of the SensorHub software :    The  PERST  based storage uses a pure Java embedded object database which allows very efficient storage of data with a very small footprint (typically for embedded devices). See the [DataPersistencePERST PERST persistence page] for more details.    The  PostgreSQL/PostGIS  storage allows storing of SWE Common data in a robust SQL database but requires more powerful hardware and a database server to run.    In both cases, the database schema used is generic and can be used to store any data structure described in SWE Common and allows indexes on the specified fields.  The administration console allows the user to select what messages are to be stored and how (i.e. table name, what indexes should be created, etc.).  Web Service Modules  Web services can be developed and connected to other SensorHub modules to provide remote access to the different functions. SensorHub software already contains useful OGC services designed to communicate bi-directionnally with the connected sensors:    The Sensor Observation Service (SOS)  is connected to the bus and to the persistent storage and allows retrieval of historical data as well as real-time data measurements.    The Sensor Planning Service (SPS)  is connected to the bus and allows to send commands to the connected sensor.    A simple  Web Feature Service (WFS)  is connected to the sensor registry and allows one to retrieve the full SensorML descriptions of all connected sensors as well as simplified features containing only the name and location of the sensors for display on a map.    All web services are configurable through the administration web interface but most of the configuration is extracted automatically from the SensorML description of the sensors. The user mainly selects what sensor outputs should be exposed through SOS and/or what sensor parameters should be able to receive commands from SPS.  Processing Modules  The processing module is connected to the bus and the persistent storage and allows deployment of several processing instances that can either process data transiting on the bus (aka event-based or streaming processing) or process data from the storage on-demand (aka on-demand processing).  Process chains can be configured using the SensorML language so that new algorithms can be easily created without writing any code simply by connecting basic functions in the diagram editor (not currently available). However, the use of SensorML is not required and one can also write a plain Java plugin compliant with the processing API for implementing a particular algorithm.  Example Deployment  The diagram below shows an example OSH instance configured with one sensor, one processing module, one storage module, SOS and SPS web services :     The sensor is connected via a proper sensor driver that pushes data to the bus as soon as it's available. Full description of the data structure is made available to other module via the sensor API.    The processing module instance listens to new sensor data and processes it as soon as it's available. The result is pushed back to the bus. Inputs and outputs are fully described in SensorML.    The storage module instance listens to both raw sensor and processed data and archives it all in a file or database. The archived data is then indexed and made available via the persistence API.    The SOS service can subscribe to and stream real-time sensor data when a user requests direct connection to it. It can also fetch data from archive storage on demand. In this case, data can be filtered by time, location, etc.    The SPS service is used to send commands to the sensor, such as turning the sensor on/off, changing the sampling rate, programming measurement triggers, etc.     Of course, this is just an example and there are many more ways of configuring SensorHub. In particular, it is possible to :    Connect several instances of SensorHub via standard OGC services so that one can create a larger network.    Implement feedback loops so that one sensor can be used to trigger different behavior of another sensor.    Implement complex processing flows that fuse data from many different sensors", 
            "title": "Architecture"
        }, 
        {
            "location": "/apidocs/", 
            "text": "", 
            "title": "Javadoc"
        }, 
        {
            "location": "/tutos/adding-new-modules/", 
            "text": "Adding New Modules\n\n\nSo that it can be more easily integrated to OpenSensorHub build process, we advise you to package each OSH module (or set of similar modules) as a separate eclipse project and corresponding Maven module. \n\n\nIf you are using Eclipse with the M2E plugin as described in the \nDeveloper's Guide\n, you can create the new project by following the steps below:\n\n\nCreate a new Maven Eclipse project\n\n\n\n\nRight click in package explorer and select \n\"New \n Other\"\n\n\nGo down to the \n\"Maven\"\n section and select \n\"Maven Project\"\n then click \n\"Next\"\n\n\nCheck \n\"Create a simple project\"\n and click \n\"Next\"\n\n\nSet \nGroupId=\"org.sensorhub\"\n and \nArtifactId=\"sensorhub-{moduletype}-{modulename}\"\n (for instance \nsensorhub-driver-axis\n for an Axis camera driver)\n\n\nFill up the name and description fields with meaningful information\n\n\nSet Parent Project to \nGroupId=\"org.sensorhub\"\n, \nArtifactId=\"sensorhub-all\"\n, \nVersion=0.5\n and click \n\"Finish\"\n\n\n\n\nMove the project inside the sensorhub main folder\n\n\nBy default your project should have been created at the root of the workspace. To move it into the correct sub-folder, follow these steps:\n\n\n\n\nRight click on the newly created project\n\n\nSelect \n\"Refactor \n Move\"\n from the popup menu\n\n\nIn the location field, insert \"osh-xxx/\" before the project name in order to obtain the following path: \n\"path/to/your/workspace/osh-xxx/sensorhub-{moduletype}-{modulename}\"\n \n\n\n\n\nAdd dependency to SensorHub core software module\n\n\n\n\nOpen the \npom.xml\n that was created at the root of the project (It should open in a special editor if the M2E plugin was properly installed)\n\n\nGo to the \n\"Dependencies\"\n tab and click the \n\"Add\"\n button\n\n\nEnter \n\"sensorhub\"\n in the search box (above the Search Results section)\n\n\nWait for results to appear, select \n\"sensorhub-core\"\n in the list and click OK\n\n\nYou can also edit the pom.xml to override the organization and developer name that are inherited from the parent project by putting your own.\n\n\nSave the file and close it \n\n\nDepending on the type of module you develop, you may have to add depencendies to other modules as well, and even to external libraries that you module may depend on.\n\n\n\n\nEnable Git version control\n\n\nTo associate the new project with the Git repository within Eclipse, follow these steps:\n\n\n\n\nRight click on the project and select \n\"Team -\n Share\"\n from the context menu\n\n\nSelect \n\"Git\"\n en click \n\"Next\"\n\n\nCheck \n\"Use or create repository in parent folder of project\"\n so that your new project can be associated to the main sensorhub repository\n\n\nSelect you project in the list and click \n\"Finish\"", 
            "title": "Adding New Modules"
        }, 
        {
            "location": "/tutos/adding-new-modules/#adding-new-modules", 
            "text": "So that it can be more easily integrated to OpenSensorHub build process, we advise you to package each OSH module (or set of similar modules) as a separate eclipse project and corresponding Maven module.   If you are using Eclipse with the M2E plugin as described in the  Developer's Guide , you can create the new project by following the steps below:  Create a new Maven Eclipse project   Right click in package explorer and select  \"New   Other\"  Go down to the  \"Maven\"  section and select  \"Maven Project\"  then click  \"Next\"  Check  \"Create a simple project\"  and click  \"Next\"  Set  GroupId=\"org.sensorhub\"  and  ArtifactId=\"sensorhub-{moduletype}-{modulename}\"  (for instance  sensorhub-driver-axis  for an Axis camera driver)  Fill up the name and description fields with meaningful information  Set Parent Project to  GroupId=\"org.sensorhub\" ,  ArtifactId=\"sensorhub-all\" ,  Version=0.5  and click  \"Finish\"   Move the project inside the sensorhub main folder  By default your project should have been created at the root of the workspace. To move it into the correct sub-folder, follow these steps:   Right click on the newly created project  Select  \"Refactor   Move\"  from the popup menu  In the location field, insert \"osh-xxx/\" before the project name in order to obtain the following path:  \"path/to/your/workspace/osh-xxx/sensorhub-{moduletype}-{modulename}\"     Add dependency to SensorHub core software module   Open the  pom.xml  that was created at the root of the project (It should open in a special editor if the M2E plugin was properly installed)  Go to the  \"Dependencies\"  tab and click the  \"Add\"  button  Enter  \"sensorhub\"  in the search box (above the Search Results section)  Wait for results to appear, select  \"sensorhub-core\"  in the list and click OK  You can also edit the pom.xml to override the organization and developer name that are inherited from the parent project by putting your own.  Save the file and close it   Depending on the type of module you develop, you may have to add depencendies to other modules as well, and even to external libraries that you module may depend on.   Enable Git version control  To associate the new project with the Git repository within Eclipse, follow these steps:   Right click on the project and select  \"Team -  Share\"  from the context menu  Select  \"Git\"  en click  \"Next\"  Check  \"Use or create repository in parent folder of project\"  so that your new project can be associated to the main sensorhub repository  Select you project in the list and click  \"Finish\"", 
            "title": "Adding New Modules"
        }, 
        {
            "location": "/tutos/your-first-sensor/", 
            "text": "Your First Sensor Driver\n\n\nThis is a tutorial to help you write your first sensor driver, based on the \nFake Weather\n demo module that is provided with SensorHub source and binary releases. You may also find it easier to follow these steps in a \npresentation\n with screenshots that we made during a FOSS4G workshop in July 2015.\n\n\nMaven Project\n\n\nThe first step is to create a new Eclipse Maven project that will contain the new sensor module, as instructed on \nthis page\n. For the sake of coherency, you should name your driver project \nsensorhub-driver-{your_driver_name}\n. In the case of the Fake Weather module, we named it \nsensorhub-driver-fakeweather\n.\n\n\nYou then need to create at least 4 classes to add a new sensor module to the SensorHub system:\n\n\n\n\nThe module configuration class\n\n\nThe main sensor module class\n\n\nAt least one sensor output class\n\n\nThe module descriptor class\n\n\n\n\nThe Module Configuration Class\n\n\nThe sensor module configuration class must be derived from \nSensorConfig\n. You can add any other properties that your sensor needs to be properly configured. This class will be directly initialized by parsing equivalent JSON properties in the main SensorHub configuration file.\n\n\nThe configuration class for the Fake Weather module is \nFakeWeatherConfig\n, where we simply added fields to specify the station location:\n\n\npublic class FakeWeatherConfig extends SensorConfig\n{\n  public double centerLatitude = 34.8038; // in deg\n  public double centerLongitude = -86.7228; // in deg\n  public double centerAltitude = 0.000; // in meters\n}\n\n\n\n\nWe recommend that you use the \n@DisplayInfo\n annotation to provide rendering hints for UI classes. An example of this is shown below:\n\n\npublic class FakeWeatherConfig extends SensorConfig\n{\n  @DisplayInfo(label=\nLatitude\n, desc=\nLatitude of Weather Station\n)\n  public double centerLatitude = 34.8038; // in deg\n\n  @DisplayInfo(label=\nLongitude\n, desc=\nLongitude of Weather Station\n)\n  public double centerLongitude = -86.7228; // in deg\n\n  @DisplayInfo(label=\nAltitude\n, desc=\nAltitude of Weather Station\n)\n  public double centerAltitude = 150.000; // in meters\n}\n\n\n\n\nBelow is a JSON snippet to be included in the main SensorHub configuration file, giving a possible configuration for the Fake Weather module:\n\n\n{\n  \nobjClass\n: \norg.sensorhub.impl.sensor.fakeweather.FakeWeatherConfig\n,\n  \nid\n: \nd136b6ea-3950-4691-bf56-c84ec7d89d73\n,\n  \nname\n: \nFake Weather Sensor\n,\n  \nenabled\n: true,\n  \nmoduleClass\n: \norg.sensorhub.impl.sensor.fakeweather.FakeWeatherSensor\n,\n  \nsensorML\n: null,\n  \nautoActivate\n: true,\n  \nenableHistory\n: false,\n  \nhiddenIO\n: null,\n  \ncenterLatitude\n: 43.6182,\n  \ncenterLongitude\n: 1.4238,\n  \ncenterAltitude\n: 150.0\n}\n\n\n\n\nThe Sensor Module Class\n\n\nThe sensor module class is the main entry point to the sensor driver implementation and must implement the generic \nISensorModule\n interface. You can implement this interface directly but in most cases you should derive from the \nAbstractSensorModule\n class instead since it already provides some functionality common to most sensors. In both cases, your must further specify your class by setting the configuration class that you defined at the previous step as its generic parameter. \n\n\nThis is shown below for the Fake Weather example:\n\n\npublic class FakeWeatherSensor extends AbstractSensorModule\nFakeWeatherConfig\n\n\n\n\n\nThe sensor module class is responsible for creating an output interface object (implementation of \nISensorDataInterface\n) for each sensor ouput and preparing the SensorML description of the sensor.\n\n\nFor the Fake Weather example module, implementation is provided in \nFakeWeatherSensor\n. This module only defines a single output and no control input. The next snippet shows the constructor where the output interface is instantiated, initialized, and appended to the output list using the \naddOutput()\n method provided by \nAbstractSensorModule\n:\n\n\npublic FakeWeatherSensor()\n{\n  dataInterface = new FakeWeatherOutput(this);\n  addOutput(dataInterface, false);\n  dataInterface.init();\n}\n\n\n\n\nThe module \nstart()\n and \nstop()\n methods must also be implemented. They must do all processing needed when the sensor is enabled or disabled respectively. In the case of the Fake Weather module, these methods simply delegate to the output interface since it is this class that actually starts/stops the measurement thread.\n\n\npublic void start() throws SensorHubException\n{\n    dataInterface.start();        \n}\n\npublic void stop() throws SensorHubException\n{\n    dataInterface.stop();\n}\n\n\n\n\nThe Sensor Output Class\n\n\nEach output interface of a sensor must be defined by a class implementing \nISensorDataInterface\n. Just like for the main sensor module class, we provide the \nAbstractSensorOutput\n base class that already implements functionalities common to most sensors, so we highly recommend that you derive from it. For instance, the sole output of the Fake Weather example sensor is defined in the \nFakeWeatherOutput\n class.\n\n\nThe main functions of the sensor output class are to:\n\n\n\n\nDefine the output data structure and encoding\n\n\nProvide the approximate/average sampling time of this output\n\n\nStart/stop measurement collection thread\n\n\nProvide access to the latest measurement record and corresponding time stamp\n\n\n\n\nDefine the output data structure and encoding\n\n\nThe snippet below is extracted from the Fake Weather example and shows how to create the measurement record structure using the \nSWEHelper\n class:\n\n\nprotected void init()\n{\n    SWEHelper fac = new SWEHelper();\n\n    // build SWE Common record structure\n    weatherData = new DataRecordImpl(5);\n    weatherData.setName(getName());\n    weatherData.setDefinition(\nhttp://sensorml.com/ont/swe/property/Weather\n);\n\n    // add time, temperature, pressure, wind speed and wind direction fields\n    weatherData.addComponent(\ntime\n, fac.newTimeStampIsoUTC());\n    weatherData.addComponent(\ntemperature\n, fac.newQuantity(SWEHelper.getPropertyUri(\nAirTemperature\n), \nAir Temperature\n, null, \nCel\n));\n    weatherData.addComponent(\npressure\n, fac.newQuantity(SWEHelper.getPropertyUri(\nAtmosphericPressure\n), \nAir Pressure\n, null, \nhPa\n));\n    weatherData.addComponent(\nwindSpeed\n, fac.newQuantity(SWEHelper.getPropertyUri(\nWindSpeed\n), \nWind Speed\n, null, \nm/s\n));\n\n    // for wind direction, we also specify a reference frame\n    Quantity q = fac.newQuantity(SWEHelper.getPropertyUri(\nWindDirection\n), \nWind Direction\n, null, \ndeg\n);\n    q.setReferenceFrame(\nhttp://sensorml.com/ont/swe/property/NED\n);\n    q.setAxisID(\nz\n);\n    weatherData.addComponent(\nwindDirection\n, q);\n\n    // also generate encoding definition\n    weatherEncoding = fac.newTextEncoding(\n,\n, \n\\n\n);\n}\n\n\n\n\nIn this case, the sensor output is a record composed of the following values:\n\n\n\n\nTime stamp (ISO time stamp expressed in UTC time frame)\n\n\nAir temperature\n\n\nAtmospheric pressure\n\n\nWind speed\n\n\nWind direction (rotation about Z axis of NED frame)\n\n\n\n\nProvide the approximate/average sampling time of this output\n\n\nThis is achieved by implementing a simple method that must return the approximative sampling period (in seconds) of data generated by this output. If the rate is known and quasi constant, the method simply returns a fixed value, as in the Fake Weather example:\n\n\npublic double getAverageSamplingPeriod()\n{\n    // sample every 1 second\n    return 1.0;\n}\n\n\n\n\nWhen the rate is not known a-priori and/or can vary, an average can be computed online (This is what is done in the \nSOS-T Virtual Sensor\n for example since there is no way to know the rate of incoming data in advance).\n\n\nStart/stop measurement collection thread\n\n\nThe measurement thread gets readings from sensor hardware and package them in a \nDataBlock\n. The sensor output must thus provide methods to start/stop the measurement thread and implement the logic for connecting to the sensor and correctly generating the \nDataBlock\n.\n\n\nIn the Fake Weather example, the \nsendMeasurement()\n method is implemented and is called regularly using a Timer thread set to execute at the frequency specified by \ngetAverageSamplingPeriod()\n.\n\n\nprivate void sendMeasurement()\n{\n    // generate new weather values\n    double time = System.currentTimeMillis() / 1000.;\n\n    // temperature; value will increase or decrease by less than 1.0 deg\n    temp += 0.005 * (2.0 *Math.random() - 1.0);\n\n    // pressure; value will increase or decrease by less than 20 hPa\n    pressure += 20. * (2.0 * Math.random() - 1.0);\n\n    // wind speed; keep positive\n    // vary value between +/- 10 m/s\n    speed += 10.0 * (2.0 * Math.random() - 1.0);\n    speed = speed \n 0.0 ? 0.0 : speed;\n\n    // wind direction; keep between 0 and 360 degrees\n    direction += 4.0 * (2.0 * Math.random() - 1.0);\n    direction = direction \n 0.0 ? direction+360.0 : direction;\n    direction = direction \n 360.0 ? direction-360.0 : direction;\n\n    // build and publish datablock\n    DataBlock dataBlock = weatherData.createDataBlock();\n    dataBlock.setDoubleValue(0, time);\n    dataBlock.setDoubleValue(1, temp);\n    dataBlock.setDoubleValue(2, pressure);\n    dataBlock.setDoubleValue(3, speed);\n    dataBlock.setDoubleValue(4, direction);\n\n    // update latest record and send event\n    latestRecord = dataBlock;\n    eventHandler.publishEvent(new SensorDataEvent(time, FakeWeatherOutput.this, dataBlock));\n}\n\nprotected void start()\n{\n    if (timer != null)\n       return;\n    timer = new Timer();\n\n    // start main measurement generation thread\n    TimerTask task = new TimerTask() {\n       public void run()\n       {\n          sendMeasurement();\n       }\n    };\n    timer.scheduleAtFixedRate(task, 0, (long)(getAverageSamplingPeriod()*1000));\n}\n\nprotected void stop()\n{\n    if (timer != null)\n    {\n        timer.cancel();\n        timer = null;\n    }\n}\n\n\n\n\nThe Module Descriptor Class\n\n\nA module descriptor class must be provided to enable automatic discovery of your new module by the SensorHub module registry. By providing a class implementing the \nIModuleProvider\n interface, all SensorHub modules available on the classpath can indeed be discovered using the standard Java \nServiceLoader\n API.\n\n\nThe class provides metadata about the module such as a name, description and version. It also indicates which configuration class and module class make up the module. It should thus point to the classes you created in the first two steps of this tutorial.\n\n\nThe snippet below shows the module descriptor for the Fake Weather sensor module:\n\n\npublic class FakeWeatherModuleDescriptor implements IModuleProvider\n{\n  @Override\n  public String getModuleName()\n  {\n    return \nFake Weather Sensor\n;\n  }\n\n  @Override\n  public String getModuleDescription()\n  {\n    return \nFake weather station with randomly changing measurements\n;\n  }\n\n  @Override\n  public String getModuleVersion()\n  {\n    return \n0.1\n;\n  }\n\n  @Override\n  public String getProviderName()\n  {\n    return \nBotts Innovative Research Inc\n;\n  }\n\n  @Override\n  public Class\n? extends IModule\n?\n getModuleClass()\n  {\n    return FakeWeatherSensor.class;\n  }\n\n  @Override\n  public Class\n? extends ModuleConfig\n getModuleConfigClass()\n  {\n    return FakeWeatherConfig.class;\n  }\n}\n\n\n\n\nIn order to be discoverable by the \nServiceLoader\n API, the module descriptor class also needs to be advertised in a provider-configuration file called \norg.sensorhub.api.module.IModuleProvider\n in the resource directory \nMETA-INF/services\n (see \nServiceLoader\n documentation on Oracle website). For instance, the Fake Weather sensor module includes \nthis file\n file with the following line:\n\n\norg.sensorhub.impl.sensor.fakeweather.FakeWeatherModuleDescriptor", 
            "title": "Your First Sensor"
        }, 
        {
            "location": "/tutos/your-first-sensor/#your-first-sensor-driver", 
            "text": "This is a tutorial to help you write your first sensor driver, based on the  Fake Weather  demo module that is provided with SensorHub source and binary releases. You may also find it easier to follow these steps in a  presentation  with screenshots that we made during a FOSS4G workshop in July 2015.  Maven Project  The first step is to create a new Eclipse Maven project that will contain the new sensor module, as instructed on  this page . For the sake of coherency, you should name your driver project  sensorhub-driver-{your_driver_name} . In the case of the Fake Weather module, we named it  sensorhub-driver-fakeweather .  You then need to create at least 4 classes to add a new sensor module to the SensorHub system:   The module configuration class  The main sensor module class  At least one sensor output class  The module descriptor class   The Module Configuration Class  The sensor module configuration class must be derived from  SensorConfig . You can add any other properties that your sensor needs to be properly configured. This class will be directly initialized by parsing equivalent JSON properties in the main SensorHub configuration file.  The configuration class for the Fake Weather module is  FakeWeatherConfig , where we simply added fields to specify the station location:  public class FakeWeatherConfig extends SensorConfig\n{\n  public double centerLatitude = 34.8038; // in deg\n  public double centerLongitude = -86.7228; // in deg\n  public double centerAltitude = 0.000; // in meters\n}  We recommend that you use the  @DisplayInfo  annotation to provide rendering hints for UI classes. An example of this is shown below:  public class FakeWeatherConfig extends SensorConfig\n{\n  @DisplayInfo(label= Latitude , desc= Latitude of Weather Station )\n  public double centerLatitude = 34.8038; // in deg\n\n  @DisplayInfo(label= Longitude , desc= Longitude of Weather Station )\n  public double centerLongitude = -86.7228; // in deg\n\n  @DisplayInfo(label= Altitude , desc= Altitude of Weather Station )\n  public double centerAltitude = 150.000; // in meters\n}  Below is a JSON snippet to be included in the main SensorHub configuration file, giving a possible configuration for the Fake Weather module:  {\n   objClass :  org.sensorhub.impl.sensor.fakeweather.FakeWeatherConfig ,\n   id :  d136b6ea-3950-4691-bf56-c84ec7d89d73 ,\n   name :  Fake Weather Sensor ,\n   enabled : true,\n   moduleClass :  org.sensorhub.impl.sensor.fakeweather.FakeWeatherSensor ,\n   sensorML : null,\n   autoActivate : true,\n   enableHistory : false,\n   hiddenIO : null,\n   centerLatitude : 43.6182,\n   centerLongitude : 1.4238,\n   centerAltitude : 150.0\n}  The Sensor Module Class  The sensor module class is the main entry point to the sensor driver implementation and must implement the generic  ISensorModule  interface. You can implement this interface directly but in most cases you should derive from the  AbstractSensorModule  class instead since it already provides some functionality common to most sensors. In both cases, your must further specify your class by setting the configuration class that you defined at the previous step as its generic parameter.   This is shown below for the Fake Weather example:  public class FakeWeatherSensor extends AbstractSensorModule FakeWeatherConfig   The sensor module class is responsible for creating an output interface object (implementation of  ISensorDataInterface ) for each sensor ouput and preparing the SensorML description of the sensor.  For the Fake Weather example module, implementation is provided in  FakeWeatherSensor . This module only defines a single output and no control input. The next snippet shows the constructor where the output interface is instantiated, initialized, and appended to the output list using the  addOutput()  method provided by  AbstractSensorModule :  public FakeWeatherSensor()\n{\n  dataInterface = new FakeWeatherOutput(this);\n  addOutput(dataInterface, false);\n  dataInterface.init();\n}  The module  start()  and  stop()  methods must also be implemented. They must do all processing needed when the sensor is enabled or disabled respectively. In the case of the Fake Weather module, these methods simply delegate to the output interface since it is this class that actually starts/stops the measurement thread.  public void start() throws SensorHubException\n{\n    dataInterface.start();        \n}\n\npublic void stop() throws SensorHubException\n{\n    dataInterface.stop();\n}  The Sensor Output Class  Each output interface of a sensor must be defined by a class implementing  ISensorDataInterface . Just like for the main sensor module class, we provide the  AbstractSensorOutput  base class that already implements functionalities common to most sensors, so we highly recommend that you derive from it. For instance, the sole output of the Fake Weather example sensor is defined in the  FakeWeatherOutput  class.  The main functions of the sensor output class are to:   Define the output data structure and encoding  Provide the approximate/average sampling time of this output  Start/stop measurement collection thread  Provide access to the latest measurement record and corresponding time stamp   Define the output data structure and encoding  The snippet below is extracted from the Fake Weather example and shows how to create the measurement record structure using the  SWEHelper  class:  protected void init()\n{\n    SWEHelper fac = new SWEHelper();\n\n    // build SWE Common record structure\n    weatherData = new DataRecordImpl(5);\n    weatherData.setName(getName());\n    weatherData.setDefinition( http://sensorml.com/ont/swe/property/Weather );\n\n    // add time, temperature, pressure, wind speed and wind direction fields\n    weatherData.addComponent( time , fac.newTimeStampIsoUTC());\n    weatherData.addComponent( temperature , fac.newQuantity(SWEHelper.getPropertyUri( AirTemperature ),  Air Temperature , null,  Cel ));\n    weatherData.addComponent( pressure , fac.newQuantity(SWEHelper.getPropertyUri( AtmosphericPressure ),  Air Pressure , null,  hPa ));\n    weatherData.addComponent( windSpeed , fac.newQuantity(SWEHelper.getPropertyUri( WindSpeed ),  Wind Speed , null,  m/s ));\n\n    // for wind direction, we also specify a reference frame\n    Quantity q = fac.newQuantity(SWEHelper.getPropertyUri( WindDirection ),  Wind Direction , null,  deg );\n    q.setReferenceFrame( http://sensorml.com/ont/swe/property/NED );\n    q.setAxisID( z );\n    weatherData.addComponent( windDirection , q);\n\n    // also generate encoding definition\n    weatherEncoding = fac.newTextEncoding( , ,  \\n );\n}  In this case, the sensor output is a record composed of the following values:   Time stamp (ISO time stamp expressed in UTC time frame)  Air temperature  Atmospheric pressure  Wind speed  Wind direction (rotation about Z axis of NED frame)   Provide the approximate/average sampling time of this output  This is achieved by implementing a simple method that must return the approximative sampling period (in seconds) of data generated by this output. If the rate is known and quasi constant, the method simply returns a fixed value, as in the Fake Weather example:  public double getAverageSamplingPeriod()\n{\n    // sample every 1 second\n    return 1.0;\n}  When the rate is not known a-priori and/or can vary, an average can be computed online (This is what is done in the  SOS-T Virtual Sensor  for example since there is no way to know the rate of incoming data in advance).  Start/stop measurement collection thread  The measurement thread gets readings from sensor hardware and package them in a  DataBlock . The sensor output must thus provide methods to start/stop the measurement thread and implement the logic for connecting to the sensor and correctly generating the  DataBlock .  In the Fake Weather example, the  sendMeasurement()  method is implemented and is called regularly using a Timer thread set to execute at the frequency specified by  getAverageSamplingPeriod() .  private void sendMeasurement()\n{\n    // generate new weather values\n    double time = System.currentTimeMillis() / 1000.;\n\n    // temperature; value will increase or decrease by less than 1.0 deg\n    temp += 0.005 * (2.0 *Math.random() - 1.0);\n\n    // pressure; value will increase or decrease by less than 20 hPa\n    pressure += 20. * (2.0 * Math.random() - 1.0);\n\n    // wind speed; keep positive\n    // vary value between +/- 10 m/s\n    speed += 10.0 * (2.0 * Math.random() - 1.0);\n    speed = speed   0.0 ? 0.0 : speed;\n\n    // wind direction; keep between 0 and 360 degrees\n    direction += 4.0 * (2.0 * Math.random() - 1.0);\n    direction = direction   0.0 ? direction+360.0 : direction;\n    direction = direction   360.0 ? direction-360.0 : direction;\n\n    // build and publish datablock\n    DataBlock dataBlock = weatherData.createDataBlock();\n    dataBlock.setDoubleValue(0, time);\n    dataBlock.setDoubleValue(1, temp);\n    dataBlock.setDoubleValue(2, pressure);\n    dataBlock.setDoubleValue(3, speed);\n    dataBlock.setDoubleValue(4, direction);\n\n    // update latest record and send event\n    latestRecord = dataBlock;\n    eventHandler.publishEvent(new SensorDataEvent(time, FakeWeatherOutput.this, dataBlock));\n}\n\nprotected void start()\n{\n    if (timer != null)\n       return;\n    timer = new Timer();\n\n    // start main measurement generation thread\n    TimerTask task = new TimerTask() {\n       public void run()\n       {\n          sendMeasurement();\n       }\n    };\n    timer.scheduleAtFixedRate(task, 0, (long)(getAverageSamplingPeriod()*1000));\n}\n\nprotected void stop()\n{\n    if (timer != null)\n    {\n        timer.cancel();\n        timer = null;\n    }\n}  The Module Descriptor Class  A module descriptor class must be provided to enable automatic discovery of your new module by the SensorHub module registry. By providing a class implementing the  IModuleProvider  interface, all SensorHub modules available on the classpath can indeed be discovered using the standard Java  ServiceLoader  API.  The class provides metadata about the module such as a name, description and version. It also indicates which configuration class and module class make up the module. It should thus point to the classes you created in the first two steps of this tutorial.  The snippet below shows the module descriptor for the Fake Weather sensor module:  public class FakeWeatherModuleDescriptor implements IModuleProvider\n{\n  @Override\n  public String getModuleName()\n  {\n    return  Fake Weather Sensor ;\n  }\n\n  @Override\n  public String getModuleDescription()\n  {\n    return  Fake weather station with randomly changing measurements ;\n  }\n\n  @Override\n  public String getModuleVersion()\n  {\n    return  0.1 ;\n  }\n\n  @Override\n  public String getProviderName()\n  {\n    return  Botts Innovative Research Inc ;\n  }\n\n  @Override\n  public Class ? extends IModule ?  getModuleClass()\n  {\n    return FakeWeatherSensor.class;\n  }\n\n  @Override\n  public Class ? extends ModuleConfig  getModuleConfigClass()\n  {\n    return FakeWeatherConfig.class;\n  }\n}  In order to be discoverable by the  ServiceLoader  API, the module descriptor class also needs to be advertised in a provider-configuration file called  org.sensorhub.api.module.IModuleProvider  in the resource directory  META-INF/services  (see  ServiceLoader  documentation on Oracle website). For instance, the Fake Weather sensor module includes  this file  file with the following line:  org.sensorhub.impl.sensor.fakeweather.FakeWeatherModuleDescriptor", 
            "title": "Your First Sensor Driver"
        }, 
        {
            "location": "/core-apis/", 
            "text": "OpenSensorHub Core APIs\n\n\nSensorHub software is implemented on top of public APIs that make the system modular and allow one to change almost any part of the system by pluging in new implementations.\n\n\nThe core APIs are:\n\n\n\n\nSWE Common and SensorML Bindings\n to create/read/write SensorML documents\n\n\nSensor API\n to implement sensor and actuator drivers\n\n\nProcess API\n to implement processing chains\n\n\nPersistence API\n to implement bindings to any database system\n\n\nCommunication API\n to implement drivers for various communication buses (serial, USB, Bluetooth, I2C, SPI, etc.)\n\n\nEvent Manager API\n to implement queuing and dispatching of events between modules or even sensorhub instances \n\n\n\n\nBefore you start implementing SensorHub's modules using these APIs, we also strongly encourage you to take the time to read about SensorHub's \nArchitecture\n.", 
            "title": "Introduction"
        }, 
        {
            "location": "/core-apis/#opensensorhub-core-apis", 
            "text": "SensorHub software is implemented on top of public APIs that make the system modular and allow one to change almost any part of the system by pluging in new implementations.  The core APIs are:   SWE Common and SensorML Bindings  to create/read/write SensorML documents  Sensor API  to implement sensor and actuator drivers  Process API  to implement processing chains  Persistence API  to implement bindings to any database system  Communication API  to implement drivers for various communication buses (serial, USB, Bluetooth, I2C, SPI, etc.)  Event Manager API  to implement queuing and dispatching of events between modules or even sensorhub instances    Before you start implementing SensorHub's modules using these APIs, we also strongly encourage you to take the time to read about SensorHub's  Architecture .", 
            "title": "OpenSensorHub Core APIs"
        }, 
        {
            "location": "/core-apis/sensorml-api/", 
            "text": "SWE Common / SensorML API\n\n\nIn SensorHub, sensor descriptions (or sensor metadata) are in the \nSensorML 2.0\n format, an international open standard from the \nOpen Geospatial Consortium (OGC)\n. They are often generated (at least partly) from code using the java SensorML bindings included in \nlib-sensorml\n.\n\n\nThese bindings are automatically generated from the 2.0 XML schemas and thus are a direct reflection of the types and properties that are defined by it. The general rule is that each \nXML Schema Complex Type\n (except OGC Property Types) becomes a Java interface with appropriate methods to handle each property (get/set/isSet/unSet, getNum/add for multiplicity \n 1, etc.).\n\n\nThere is one subtle difference compared to other bindings that could be generated with commonly used tools such as JAXB or XML Beans: OGC Property Types are not generated as separate objects thus removing many unnecessary layers in the generated object tree. Instead, properties are handled as a generic \nOgcProperty\n object, containing all info carried by the property such as name, xlink attributes, etc., and accessible via \n'getProperty'\n methods. This means that calls to regular get methods would return the property value directly which makes constructing the object much more straight forward. This design allows for handling the entire content model from many OGC schemas without making the resulting object tree too complex.\n\n\nLet's look at examples of how to set different parts of a SensorML document using this API (All code in the following section assumes you have an instance of \nPhysicalComponent\n or \nPhysicalSystem\n called \n'system'\n on hand).\n\n\nNote: Most of the following examples are actually extracted from the 'testGenerateInstance()' method of this \nJUnit Test Class\n so you can look at the code directly\n\n\nHigh-Level Descriptive Info\n\n\nThe first thing you need to do to create or add to a SensorML description is to instantiate SML and SWE helperfactories:\n\n\nSMLHelper smlFac = new SMLHelper();\nSWEHelper sweFac = new SWEHelper();\n\n\n\n\nThen, if you don't already have one, create the top level process or system instance. For instance a \nPhysicalSystem\n entity is created like so:\n\n\nPhysicalSystem system = smlFac.newPhysicalSystem();\n\n\n\n\nYou can then set name and description of the system:\n\n\nsystem.setName(\nGarage Thermometer\n);\nsystem.setDescription(\nThermometer located next to the door inside my garage\n);\n\n\n\n\nYou can also set the parent type of this sensor (this is typically used to reference a SensorML description providing more details about the sensor such as the SensorML document/datasheet provided by the manufacturer):\n\n\nsystem.setTypeOf(new ReferenceImpl(\nhttp://manufacturer.org/datasheets/sensor1234.xml\n));\n\n\n\n\nAdvanced Metadata\n\n\nAdd contact information:\n\n\nContactList contacts = smlFac.newContactList();\nCIResponsibleParty contact = smlFac.newResponsibleParty();\ncontact.setIndividualName(\nG\u00e9rard Blanquet\n);\ncontact.setOrganisationName(\nTime Soft S.A.\n);\ncontact.getContactInfo().getAddress().addDeliveryPoint(\n10 rue du Nord\n);\ncontact.getContactInfo().getAddress().setPostalCode(\n75896\n);\ncontact.getContactInfo().getAddress().setCity(\nParis\n);\ncontact.getContactInfo().getAddress().setCountry(\nFRANCE\n);\ncontact.setRole(new CodeListValueImpl(\noperator\n));\ncontacts.addContact(contact);\nsystem.addContacts(contacts);\n\n\n\n\nAdd characteristics:\n\n\nCharacteristicList mechSpecs = smlFac.newCharacteristicList();\nQuantity weightSpec = sweFac.newQuantity(\nhttp://sweet.jpl.nasa.gov/2.3/propMass.owl#Mass\n, \nWeight\n, null, \nkg\n);\nweightSpec.setValue(12.3);\nmechSpecs.addCharacteristic(\nweight\n, weightSpec);\nsystem.addCharacteristics(\nmechanical\n, mechSpecs);\n\n\n\n\nLocation\n\n\nAdd location as GML point:\n\n\nGMLFactory gmlFac = new GMLFactory();\nPoint pos = gmlFac.newPoint();\npos.setId(\nP01\n);\npos.setSrsName(\nhttp://www.opengis.net/def/crs/EPSG/0/4979\n);\npos.setPos(new double[] {45.6, 2.3, 193.2});\nsystem.addPositionAsPoint(pos);\n\n\n\n\nInputs/Outputs/Parameters\n\n\nAll inputs, outputs and parameters in SensorML are described using the SWE Common Language so you can use the \nSWEHelper\n class to create these structures. \n\n\nAdd observable property as input:\n\n\nObservableProperty obs = new ObservablePropertyImpl();\nobs.setDefinition(\nhttp://mmisw.org/ont/cf/parameter/weather\n);\nsystem.addInput(\nweather_phenomena\n, obs);\n\n\n\n\nYou can also add an input as xlink reference:\n\n\nsystem.getInputList().add(\nrain\n, \nhttp://remotedef.xml\n, null);\n\n\n\n\nAdd output record (in this case we first create the record object and then add sub-components to it, before we add it as output):\n\n\n// create output record and set description\nDataRecord rec = sweFac.newDataRecord();\nrec.setLabel(\nWeather Data Record\n);\nrec.setDescription(\nRecord of synchronous weather measurements\n);\n\n// sampling time\nrec.addField(\ntime\n, sweFac.newTimeStampIsoUTC());\n\n// temperature measurement\nrec.addField(\ntemp\n, sweFac.newQuantity(\n                            \nhttp://mmisw.org/ont/cf/parameter/air_temperature\n, \n                            \nAir Temperature\n, null, \nCel\n));\n\n// pressure\nrec.addField(\npress\n, sweFac.newQuantity(\n                            \nhttp://mmisw.org/ont/cf/parameter/air_pressure_at_sea_level\n,\n                            \nAir Pressure\n, null, \nmbar\n));\n\n// wind speed\nrec.addField(\nwind_speed\n, sweFac.newQuantity(\n                            \nhttp://mmisw.org/ont/cf/parameter/wind_speed\n,\n                            \nWind Speed\n, null, \nkm/h\n));\n\n// wind direction\nrec.addField(\nwind_dir\n, sweFac.newQuantity(\n                            \nhttp://mmisw.org/ont/cf/parameter/wind_to_direction\n,\n                            \nWind Direction\n, null, \ndeg\n));\n\n// add as output\nsystem.addOutput(\nweather_data\n, rec);\n\n\n\n\nYou can also add accuracy info to some of the measured outputs:\n\n\n// add accuracy info to temp output\nQuantity acc = sweFac.newQuantity(\n                      \nhttp://mmisw.org/ont/cf/parameter/accuracy\n,\n                      \nAccuracy\n, null, \n%\n);\n(Quantity)rec.getField(\ntemp\n)).addQuality(acc);\n\n\n\n\nParameters can be added in a similar fashion:\n\n\nsystem.addParameter(\nsamplingPeriod\n, sweFac.newQuantity(\n                       \nhttp://sensorml.com/ont/swe/property/SamplingPeriod\n,\n                       \nSampling Period\n, null, \ns\n));\n\n\n\n\nReference Frames\n\n\nOne important information that can be added to a sensor or system description is documentation about the reference frame that is attached to it. This is useful for properly processing positioning information in advanced geolocation workflows. Below is an example spatial reference frame definition:\n\n\nSpatialFrame systemFrame = smlFac.newSpatialFrame();\nsystemFrame.setId(\nSYSTEM_FRAME\n);\nsystemFrame.setLabel(\nSystem Reference Frame\n);\nsystemFrame.setDescription(\nCartesian reference frame attached to system assembly\n);\nsystemFrame.setOrigin(\nOrigin is located on the red marking at the bottom of the aluminum chassis\n);\nsystemFrame.addAxis(\nx\n, \nX axis is aligned with the horizontal edge of the chassis (see marking)\n);\nsystemFrame.addAxis(\ny\n, \nY axis is orthogonal to both X and Y in order to form a direct orthogonal frame\n);\nsystemFrame.addAxis(\nz\n, \nZ axis is pointing toward the top of the assembly, aligned with the vertical edge of the aluminum frame\n);\nsystem.addLocalReferenceFrame(systemFrame);\n\n\n\n\nWrite-out as XML\n\n\nOnce you have the java object tree created, it is trivial to serialize it as XML that is compliant to the SensorML standard:\n\n\nnew SMLUtils().writeProcess(System.out, system, true);", 
            "title": "SensorML API"
        }, 
        {
            "location": "/core-apis/sensorml-api/#swe-common-sensorml-api", 
            "text": "In SensorHub, sensor descriptions (or sensor metadata) are in the  SensorML 2.0  format, an international open standard from the  Open Geospatial Consortium (OGC) . They are often generated (at least partly) from code using the java SensorML bindings included in  lib-sensorml .  These bindings are automatically generated from the 2.0 XML schemas and thus are a direct reflection of the types and properties that are defined by it. The general rule is that each  XML Schema Complex Type  (except OGC Property Types) becomes a Java interface with appropriate methods to handle each property (get/set/isSet/unSet, getNum/add for multiplicity   1, etc.).  There is one subtle difference compared to other bindings that could be generated with commonly used tools such as JAXB or XML Beans: OGC Property Types are not generated as separate objects thus removing many unnecessary layers in the generated object tree. Instead, properties are handled as a generic  OgcProperty  object, containing all info carried by the property such as name, xlink attributes, etc., and accessible via  'getProperty'  methods. This means that calls to regular get methods would return the property value directly which makes constructing the object much more straight forward. This design allows for handling the entire content model from many OGC schemas without making the resulting object tree too complex.  Let's look at examples of how to set different parts of a SensorML document using this API (All code in the following section assumes you have an instance of  PhysicalComponent  or  PhysicalSystem  called  'system'  on hand).  Note: Most of the following examples are actually extracted from the 'testGenerateInstance()' method of this  JUnit Test Class  so you can look at the code directly  High-Level Descriptive Info  The first thing you need to do to create or add to a SensorML description is to instantiate SML and SWE helperfactories:  SMLHelper smlFac = new SMLHelper();\nSWEHelper sweFac = new SWEHelper();  Then, if you don't already have one, create the top level process or system instance. For instance a  PhysicalSystem  entity is created like so:  PhysicalSystem system = smlFac.newPhysicalSystem();  You can then set name and description of the system:  system.setName( Garage Thermometer );\nsystem.setDescription( Thermometer located next to the door inside my garage );  You can also set the parent type of this sensor (this is typically used to reference a SensorML description providing more details about the sensor such as the SensorML document/datasheet provided by the manufacturer):  system.setTypeOf(new ReferenceImpl( http://manufacturer.org/datasheets/sensor1234.xml ));  Advanced Metadata  Add contact information:  ContactList contacts = smlFac.newContactList();\nCIResponsibleParty contact = smlFac.newResponsibleParty();\ncontact.setIndividualName( G\u00e9rard Blanquet );\ncontact.setOrganisationName( Time Soft S.A. );\ncontact.getContactInfo().getAddress().addDeliveryPoint( 10 rue du Nord );\ncontact.getContactInfo().getAddress().setPostalCode( 75896 );\ncontact.getContactInfo().getAddress().setCity( Paris );\ncontact.getContactInfo().getAddress().setCountry( FRANCE );\ncontact.setRole(new CodeListValueImpl( operator ));\ncontacts.addContact(contact);\nsystem.addContacts(contacts);  Add characteristics:  CharacteristicList mechSpecs = smlFac.newCharacteristicList();\nQuantity weightSpec = sweFac.newQuantity( http://sweet.jpl.nasa.gov/2.3/propMass.owl#Mass ,  Weight , null,  kg );\nweightSpec.setValue(12.3);\nmechSpecs.addCharacteristic( weight , weightSpec);\nsystem.addCharacteristics( mechanical , mechSpecs);  Location  Add location as GML point:  GMLFactory gmlFac = new GMLFactory();\nPoint pos = gmlFac.newPoint();\npos.setId( P01 );\npos.setSrsName( http://www.opengis.net/def/crs/EPSG/0/4979 );\npos.setPos(new double[] {45.6, 2.3, 193.2});\nsystem.addPositionAsPoint(pos);  Inputs/Outputs/Parameters  All inputs, outputs and parameters in SensorML are described using the SWE Common Language so you can use the  SWEHelper  class to create these structures.   Add observable property as input:  ObservableProperty obs = new ObservablePropertyImpl();\nobs.setDefinition( http://mmisw.org/ont/cf/parameter/weather );\nsystem.addInput( weather_phenomena , obs);  You can also add an input as xlink reference:  system.getInputList().add( rain ,  http://remotedef.xml , null);  Add output record (in this case we first create the record object and then add sub-components to it, before we add it as output):  // create output record and set description\nDataRecord rec = sweFac.newDataRecord();\nrec.setLabel( Weather Data Record );\nrec.setDescription( Record of synchronous weather measurements );\n\n// sampling time\nrec.addField( time , sweFac.newTimeStampIsoUTC());\n\n// temperature measurement\nrec.addField( temp , sweFac.newQuantity(\n                             http://mmisw.org/ont/cf/parameter/air_temperature , \n                             Air Temperature , null,  Cel ));\n\n// pressure\nrec.addField( press , sweFac.newQuantity(\n                             http://mmisw.org/ont/cf/parameter/air_pressure_at_sea_level ,\n                             Air Pressure , null,  mbar ));\n\n// wind speed\nrec.addField( wind_speed , sweFac.newQuantity(\n                             http://mmisw.org/ont/cf/parameter/wind_speed ,\n                             Wind Speed , null,  km/h ));\n\n// wind direction\nrec.addField( wind_dir , sweFac.newQuantity(\n                             http://mmisw.org/ont/cf/parameter/wind_to_direction ,\n                             Wind Direction , null,  deg ));\n\n// add as output\nsystem.addOutput( weather_data , rec);  You can also add accuracy info to some of the measured outputs:  // add accuracy info to temp output\nQuantity acc = sweFac.newQuantity(\n                       http://mmisw.org/ont/cf/parameter/accuracy ,\n                       Accuracy , null,  % );\n(Quantity)rec.getField( temp )).addQuality(acc);  Parameters can be added in a similar fashion:  system.addParameter( samplingPeriod , sweFac.newQuantity(\n                        http://sensorml.com/ont/swe/property/SamplingPeriod ,\n                        Sampling Period , null,  s ));  Reference Frames  One important information that can be added to a sensor or system description is documentation about the reference frame that is attached to it. This is useful for properly processing positioning information in advanced geolocation workflows. Below is an example spatial reference frame definition:  SpatialFrame systemFrame = smlFac.newSpatialFrame();\nsystemFrame.setId( SYSTEM_FRAME );\nsystemFrame.setLabel( System Reference Frame );\nsystemFrame.setDescription( Cartesian reference frame attached to system assembly );\nsystemFrame.setOrigin( Origin is located on the red marking at the bottom of the aluminum chassis );\nsystemFrame.addAxis( x ,  X axis is aligned with the horizontal edge of the chassis (see marking) );\nsystemFrame.addAxis( y ,  Y axis is orthogonal to both X and Y in order to form a direct orthogonal frame );\nsystemFrame.addAxis( z ,  Z axis is pointing toward the top of the assembly, aligned with the vertical edge of the aluminum frame );\nsystem.addLocalReferenceFrame(systemFrame);  Write-out as XML  Once you have the java object tree created, it is trivial to serialize it as XML that is compliant to the SensorML standard:  new SMLUtils().writeProcess(System.out, system, true);", 
            "title": "SWE Common / SensorML API"
        }, 
        {
            "location": "/core-apis/sensor-api/", 
            "text": "Sensor API\n\n\nThis page presents the base API that one needs to implement to add support for new sensors or actuators.\n\n\nThis API can only be used to implement drivers for single sensors (this limitation is due to the fact that the base API only allows the driver to define a single Feature of Interest (FOI) and a single sensor description). This means that a driver implementing only the base API would have to be instantiated N times to connect to a network of N sensors. Fortunately, SensorHub also defines an extension to the base sensor API allowing one to write drivers that can wrap sensor networks of any size within a single module. Please see the \nSensor Network API\n page for more details.\n\n\nWhen implementing the base sensor API, each new sensor (or actuator) driver is composed of at least 4 classes:\n\n\n\n\nAn implementation of the \nISensorModule\n interface\n\n\nZero or more implementations of \nISensorDataInterface\n (\nat least one for a sensor\n)\n\n\nZero or more implementations of \nISensorControlInterface\n (\nat least one for an actuator\n)\n\n\nAn extension of the \nSensorConfig\n class\n\n\nAn implementation of the \nIModuleDescriptor\n interface\n\n\n\n\nDetails about these different classes are given in the next sections.\n\n\nNote: Several sensor drivers can be packaged in a single Maven module, although we encourage this only if the drivers are very closely related and/or have tight inter-dependencies.\n\n\nISensorModule\n\n\nThe \nISensorModule\n interface is the top-level one to be implemented by sensor drivers. It provides methods for:\n\n\n\n\nGetting the SensorML description of an installed sensor or actuator\n\n\nGetting the feature of interest (FOI) currently observed by the sensor\n\n\nChecking for the presence of the device\n\n\nSubscribing for high level sensor events (activation, connection, etc.)\n\n\nGiving access to the sensor measurement outputs and control inputs\n\n\n\n\nThe main functions of the sensor module are shown on the figure below:\n\n\n\n\nEach data interface is an output that gives access to a stream of sensor measurements and is an implementation of \nISensorDataInterface\n. Data interfaces are asynchornous in the sense that each of them can produce data at a different rate.\n\n\nEach control interface is an input that can receive commands and is an implementation of \nISensorControlInterface\n. Each control input can receive different types of command messages.\n\n\nA sensor module implementation must also provide the description of the sensor as a SensorML process (any class derived from \nAbstractProcess\n is acceptable). Usually, this sensor description is a mix between information auto-generated by the driver and information provided as a SensorML file by the user. Versioning and updating the sensor description can be optionnally supported by the driver.\n\n\nIn order to help you implement the API, we provide the \nAbstractSensorModule\n class that is a simple partial implementation of \nISensorModule\n and can be used as the base for most sensor modules. It provides default implementations of most methods in the API.\n\n\nISensorDataInterface\n\n\nData produced by each output must be made available by an implementation of \nISensorDataInterface\n that provides methods for:\n\n\n\n\nDescribing the data structure of each measurement record\n\n\nReading data produced by a sensor (poll mode)\n\n\nSubscribing for data produced by a sensor (push mode)\n\n\nDiscovery methods allowing to advertise if push and storage are supported\n\n\n\n\nThe measurement record description must be provided as a tree of SWE Common data components (DataRecord, DataArray, Quantity, Time, Count, etc.). This structure will automatically be used to populate the output section of the SensorML description.\n\n\nA recommended encoding must also be defined which is usually text for simple measurements and some binary flavor for imagery, video and other multi-dimensionnal datasets. \n\n\nThese components and encodings are provided by the \nlib-swe-common\n module.\n\n\nAll data streamed through the same data interface must be synchronous and time-tagged together.\n\n\nThe \nAbstractSensorOutput\n class is provided to reduce redundant code and help you get started. It is a basic partial implementation of \nISensorDataInterface\n that can be used as the base for most sensor modules.\n\n\nISensorControlInterface\n\n\nCommands can be sent to the sensor via implementations of \nISensorControlInterface\n that provides methods for:\n\n\n\n\nSending commands to the sensor/actuator (synchronous or asynchronous)\n\n\nScheduling commands to be sent asynchronously and/or at specific times\n\n\nSubscribing to events related to a command that is executed asynchronously\n\n\n\n\nThe \nAbstractSensorControl\n class is provided to reduce redundant code and help you get started. It is a basic partial implementation of \nISensorControlInterface\n that can be used as the base for most sensor modules.\n\n\nSensorConfig\n\n\nA configuration class derived from SensorConfig must be provided with the new driver. This class is used as a \nstruct\n that contain public fields carrying the configuration of the sensor module.\n\n\nAll public fields in this class are used to automatically generate the administration user interface of this particular driver. Nesting configuration classes is supported.\n\n\nYou can use the \nDisplayInfo\n annotation to give hints to the UI renderer, by providing:\n\n\n\n\nA more readable label (if non is provided, the label is automatically derived from the field name)\n\n\nA description that will show up in a popup\n\n\n\n\nAbstractSensorModule\n\n\nThe \nAbstractSensorModule\n class can serve as a base to develop most sensor drivers. It provides default implementation for the following aspects:\n\n\n\n\nKeeping maps of outputs and command inputs. Derived classes should thus call the \naddOutput()\n and \naddControlInput()\n methods\n\n\nGeneration of SensorML description (more details are given below)\n\n\n\n\nHowever, there is no default support for:\n\n\n\n\nUpdating the sensor description from outside the driver (except by changing the base SensorML file)\n\n\nMaintaining a history of sensor descriptions (this is because, by default, this feature is better handled by the persistence layer in SensorHub).\n\n\n\n\nConsequently, the \nAbstractSensorModule\n class returns \nfalse\n in the two methods reporting support of these functionalities.\n\n\nDefault workflow for generating the SensorML description\n\n\nThe default workflow shown on the figure below illustrates the way the current sensor decription is generated when you derive a concrete driver implementation from \nAbstractSensorModule\n:\n\n\n\n\n\n\n\n\nOutput, control inputs and configuration parameter descriptions are actually defined by concrete driver implementation but appending to SensorML is done in \nAbstractSensorModule\n\n\n\n\n\n\nAutogenerated content is usually info obtained directly from sensor hardware\n(e.g. serial number, etc.) and/or internal driver state (e.g. depending on commands received)\n\n\n\n\n\n\nIModuleDescriptor\n\n\nLike any SensorHub module, a sensor driver must implement a class derived from this interface to become discoverable.", 
            "title": "Sensor API"
        }, 
        {
            "location": "/core-apis/sensor-api/#sensor-api", 
            "text": "This page presents the base API that one needs to implement to add support for new sensors or actuators.  This API can only be used to implement drivers for single sensors (this limitation is due to the fact that the base API only allows the driver to define a single Feature of Interest (FOI) and a single sensor description). This means that a driver implementing only the base API would have to be instantiated N times to connect to a network of N sensors. Fortunately, SensorHub also defines an extension to the base sensor API allowing one to write drivers that can wrap sensor networks of any size within a single module. Please see the  Sensor Network API  page for more details.  When implementing the base sensor API, each new sensor (or actuator) driver is composed of at least 4 classes:   An implementation of the  ISensorModule  interface  Zero or more implementations of  ISensorDataInterface  ( at least one for a sensor )  Zero or more implementations of  ISensorControlInterface  ( at least one for an actuator )  An extension of the  SensorConfig  class  An implementation of the  IModuleDescriptor  interface   Details about these different classes are given in the next sections.  Note: Several sensor drivers can be packaged in a single Maven module, although we encourage this only if the drivers are very closely related and/or have tight inter-dependencies.  ISensorModule  The  ISensorModule  interface is the top-level one to be implemented by sensor drivers. It provides methods for:   Getting the SensorML description of an installed sensor or actuator  Getting the feature of interest (FOI) currently observed by the sensor  Checking for the presence of the device  Subscribing for high level sensor events (activation, connection, etc.)  Giving access to the sensor measurement outputs and control inputs   The main functions of the sensor module are shown on the figure below:   Each data interface is an output that gives access to a stream of sensor measurements and is an implementation of  ISensorDataInterface . Data interfaces are asynchornous in the sense that each of them can produce data at a different rate.  Each control interface is an input that can receive commands and is an implementation of  ISensorControlInterface . Each control input can receive different types of command messages.  A sensor module implementation must also provide the description of the sensor as a SensorML process (any class derived from  AbstractProcess  is acceptable). Usually, this sensor description is a mix between information auto-generated by the driver and information provided as a SensorML file by the user. Versioning and updating the sensor description can be optionnally supported by the driver.  In order to help you implement the API, we provide the  AbstractSensorModule  class that is a simple partial implementation of  ISensorModule  and can be used as the base for most sensor modules. It provides default implementations of most methods in the API.  ISensorDataInterface  Data produced by each output must be made available by an implementation of  ISensorDataInterface  that provides methods for:   Describing the data structure of each measurement record  Reading data produced by a sensor (poll mode)  Subscribing for data produced by a sensor (push mode)  Discovery methods allowing to advertise if push and storage are supported   The measurement record description must be provided as a tree of SWE Common data components (DataRecord, DataArray, Quantity, Time, Count, etc.). This structure will automatically be used to populate the output section of the SensorML description.  A recommended encoding must also be defined which is usually text for simple measurements and some binary flavor for imagery, video and other multi-dimensionnal datasets.   These components and encodings are provided by the  lib-swe-common  module.  All data streamed through the same data interface must be synchronous and time-tagged together.  The  AbstractSensorOutput  class is provided to reduce redundant code and help you get started. It is a basic partial implementation of  ISensorDataInterface  that can be used as the base for most sensor modules.  ISensorControlInterface  Commands can be sent to the sensor via implementations of  ISensorControlInterface  that provides methods for:   Sending commands to the sensor/actuator (synchronous or asynchronous)  Scheduling commands to be sent asynchronously and/or at specific times  Subscribing to events related to a command that is executed asynchronously   The  AbstractSensorControl  class is provided to reduce redundant code and help you get started. It is a basic partial implementation of  ISensorControlInterface  that can be used as the base for most sensor modules.  SensorConfig  A configuration class derived from SensorConfig must be provided with the new driver. This class is used as a  struct  that contain public fields carrying the configuration of the sensor module.  All public fields in this class are used to automatically generate the administration user interface of this particular driver. Nesting configuration classes is supported.  You can use the  DisplayInfo  annotation to give hints to the UI renderer, by providing:   A more readable label (if non is provided, the label is automatically derived from the field name)  A description that will show up in a popup   AbstractSensorModule  The  AbstractSensorModule  class can serve as a base to develop most sensor drivers. It provides default implementation for the following aspects:   Keeping maps of outputs and command inputs. Derived classes should thus call the  addOutput()  and  addControlInput()  methods  Generation of SensorML description (more details are given below)   However, there is no default support for:   Updating the sensor description from outside the driver (except by changing the base SensorML file)  Maintaining a history of sensor descriptions (this is because, by default, this feature is better handled by the persistence layer in SensorHub).   Consequently, the  AbstractSensorModule  class returns  false  in the two methods reporting support of these functionalities.  Default workflow for generating the SensorML description  The default workflow shown on the figure below illustrates the way the current sensor decription is generated when you derive a concrete driver implementation from  AbstractSensorModule :     Output, control inputs and configuration parameter descriptions are actually defined by concrete driver implementation but appending to SensorML is done in  AbstractSensorModule    Autogenerated content is usually info obtained directly from sensor hardware\n(e.g. serial number, etc.) and/or internal driver state (e.g. depending on commands received)    IModuleDescriptor  Like any SensorHub module, a sensor driver must implement a class derived from this interface to become discoverable.", 
            "title": "Sensor API"
        }, 
        {
            "location": "/core-apis/sensornet-api/", 
            "text": "Sensor Network API\n\n\nThis page presents an extension of the base \nSensor API\n that allows one to implement drivers for sensor networks of any size as a single SensorHub module. This API is used in addition to the base sensor API when one needs to wrap such a sensor network instead of just a single sensor.\n\n\nIn addition to the base sensor API methods, a sensor network module would have to implement the \n'IMultiSourceDataProducer'\n interface which allows providing \nSensor Descriptions\n and \nFeatures of Interest\n (FOI) for multiple \nEntities\n:\n\n\nEntities\n\n\nThe 'IMultiSourceDataProducer' interface is based on the concept of \nEntity\n: An entity represents one member of the network. We use the term entity because this interface can also be used for other things than sensor networks, such as process grids.\n\n\nFor sensor networks, each entity usually corresponds to one sensor (or one measurement system such as a weather station) in the network. Although sensors in a network often measure the same quantities, it is not always the case, so SensorHub allows for completely heterogeneous sensors to be part of the same network.\n\n\nSensor Descriptions\n\n\nThe sensor network driver is responsible for providing sensor descriptions for each entity via the \ngetCurrentDescription(String entityId)\n method. This description can contain information specific to that entity such as its location (when fixed) and calibration tables for example.\n\n\nSince the driver also inherits the original methods from the base \nSensor API\n, the \ngetCurrentDescription()\n method shall be used to provide a description of the network as a whole. This description usually contains the list of sensors that are part of the network as SensorML components (for large networks, this will be preferably done by reference). It is also important to include discovery related information in this description since it is the only one directly referenced by the capabilities document of SWE services.\n\n\nChanges in the network or in a given entity configuration are notified using a \nSensorEvent\n. In the case of an entity change, use the constructor with the sensorID.\n\n\nNote: As for single sensors, the driver is only required to provide the most current sensor descriptions. Maintenance of the history of descriptions is done by storage modules in SensorHub.\n\n\nFeatures of Interest\n\n\nIn a sensor network, there can be as many features of interest (FOI) as there are entities in the network at any given point in time (e.g. for a network of weather station, there is one static sampling point per station). The FOI associated with each entity is provided via the \ngetCurrentFeatureOfInterest(String entityID)\n method.\n\n\nSince the driver also inherits the original methods from the base \nSensor API\n, the \ngetCurrentFeatureOfInterest()\n method shall be used to provide a FOI for the network as a whole (e.g. The FOI for a river monitoring sensor network is the river itself, while the FOI for each station/entity would be a sampling point at the station location). This corresponds to the sampled feature in the O\nM model.\n\n\nWhen one of the features of interest changes (as usually happens in networks of mobile sensors), this can be notified using an \nFoiEvent\n. If the FOI observed by one of the sensor changes (e.g. the sensor was moved to a new location), use the constructor with the entityID.\n\n\nNote: As for single sensors, the driver is only required to provide the feature of interest currently being observed. Maintenance of the history of FOIs is done by storage modules in SensorHub.\n\n\nNetwork Output\n\n\nFor sensor networks, the observation output(s) should include a field indicating the ID of the entity that generated the data record. For instance, the record description for weather measurements coming from a network of weather station could be such as:\n\n\nswe:DataRecord definition=\nhttp://sensorml.com/ont/swe/property/WeatherData\n\n    \nswe:field name=\ntime\n\n        \nswe:Time\n            definition=\nhttp://www.opengis.net/def/property/OGC/0/SamplingTime\n referenceFrame=\nhttp://www.opengis.net/def/trs/BIPM/0/UTC\n\n            \nswe:label\nSampling Time\n/swe:label\n\n            \nswe:uom xlink:href=\nhttp://www.opengis.net/def/uom/ISO-8601/0/Gregorian\n/\n\n        \n/swe:Time\n\n    \n/swe:field\n\n    \nswe:field name=\nstationID\n\n        \nswe:Text definition=\nhttp://sensorml.com/ont/swe/property/StationID\n\n            \nswe:label\nStation ID\n/swe:label\n\n        \n/swe:Text\n\n    \n/swe:field\n\n    \nswe:field name=\ntemp\n\n        \nswe:Quantity definition=\nhttp://sensorml.com/ont/swe/property/Temperature\n\n            \nswe:label\nAir Temperature\n/swe:label\n\n            \nswe:uom code=\ndegF\n/\n\n        \n/swe:Quantity\n\n    \n/swe:field\n\n    \nswe:field name=\nhumidity\n\n        \nswe:Quantity definition=\nhttp://sensorml.com/ont/swe/property/HumidityValue\n\n            \nswe:label\nRelative Humidity\n/swe:label\n\n            \nswe:uom code=\n%\n/\n\n        \n/swe:Quantity\n\n    \n/swe:field\n\n    \nswe:field name=\npress\n\n        \nswe:Quantity definition=\nhttp://sensorml.com/ont/swe/property/AirPressureValue\n\n            \nswe:label\nAtmospheric Pressure\n/swe:label\n\n            \nswe:uom code=\n[in_i]Hg\n/\n\n        \n/swe:Quantity\n\n    \n/swe:field\n\n\n/swe:DataRecord\n\n\n\n\n\nNotice the field `stationID' whose value would be the ID of the entity/station that generated the record.", 
            "title": "Sensor Net API"
        }, 
        {
            "location": "/core-apis/sensornet-api/#sensor-network-api", 
            "text": "This page presents an extension of the base  Sensor API  that allows one to implement drivers for sensor networks of any size as a single SensorHub module. This API is used in addition to the base sensor API when one needs to wrap such a sensor network instead of just a single sensor.  In addition to the base sensor API methods, a sensor network module would have to implement the  'IMultiSourceDataProducer'  interface which allows providing  Sensor Descriptions  and  Features of Interest  (FOI) for multiple  Entities :  Entities  The 'IMultiSourceDataProducer' interface is based on the concept of  Entity : An entity represents one member of the network. We use the term entity because this interface can also be used for other things than sensor networks, such as process grids.  For sensor networks, each entity usually corresponds to one sensor (or one measurement system such as a weather station) in the network. Although sensors in a network often measure the same quantities, it is not always the case, so SensorHub allows for completely heterogeneous sensors to be part of the same network.  Sensor Descriptions  The sensor network driver is responsible for providing sensor descriptions for each entity via the  getCurrentDescription(String entityId)  method. This description can contain information specific to that entity such as its location (when fixed) and calibration tables for example.  Since the driver also inherits the original methods from the base  Sensor API , the  getCurrentDescription()  method shall be used to provide a description of the network as a whole. This description usually contains the list of sensors that are part of the network as SensorML components (for large networks, this will be preferably done by reference). It is also important to include discovery related information in this description since it is the only one directly referenced by the capabilities document of SWE services.  Changes in the network or in a given entity configuration are notified using a  SensorEvent . In the case of an entity change, use the constructor with the sensorID.  Note: As for single sensors, the driver is only required to provide the most current sensor descriptions. Maintenance of the history of descriptions is done by storage modules in SensorHub.  Features of Interest  In a sensor network, there can be as many features of interest (FOI) as there are entities in the network at any given point in time (e.g. for a network of weather station, there is one static sampling point per station). The FOI associated with each entity is provided via the  getCurrentFeatureOfInterest(String entityID)  method.  Since the driver also inherits the original methods from the base  Sensor API , the  getCurrentFeatureOfInterest()  method shall be used to provide a FOI for the network as a whole (e.g. The FOI for a river monitoring sensor network is the river itself, while the FOI for each station/entity would be a sampling point at the station location). This corresponds to the sampled feature in the O M model.  When one of the features of interest changes (as usually happens in networks of mobile sensors), this can be notified using an  FoiEvent . If the FOI observed by one of the sensor changes (e.g. the sensor was moved to a new location), use the constructor with the entityID.  Note: As for single sensors, the driver is only required to provide the feature of interest currently being observed. Maintenance of the history of FOIs is done by storage modules in SensorHub.  Network Output  For sensor networks, the observation output(s) should include a field indicating the ID of the entity that generated the data record. For instance, the record description for weather measurements coming from a network of weather station could be such as:  swe:DataRecord definition= http://sensorml.com/ont/swe/property/WeatherData \n     swe:field name= time \n         swe:Time\n            definition= http://www.opengis.net/def/property/OGC/0/SamplingTime  referenceFrame= http://www.opengis.net/def/trs/BIPM/0/UTC \n             swe:label Sampling Time /swe:label \n             swe:uom xlink:href= http://www.opengis.net/def/uom/ISO-8601/0/Gregorian / \n         /swe:Time \n     /swe:field \n     swe:field name= stationID \n         swe:Text definition= http://sensorml.com/ont/swe/property/StationID \n             swe:label Station ID /swe:label \n         /swe:Text \n     /swe:field \n     swe:field name= temp \n         swe:Quantity definition= http://sensorml.com/ont/swe/property/Temperature \n             swe:label Air Temperature /swe:label \n             swe:uom code= degF / \n         /swe:Quantity \n     /swe:field \n     swe:field name= humidity \n         swe:Quantity definition= http://sensorml.com/ont/swe/property/HumidityValue \n             swe:label Relative Humidity /swe:label \n             swe:uom code= % / \n         /swe:Quantity \n     /swe:field \n     swe:field name= press \n         swe:Quantity definition= http://sensorml.com/ont/swe/property/AirPressureValue \n             swe:label Atmospheric Pressure /swe:label \n             swe:uom code= [in_i]Hg / \n         /swe:Quantity \n     /swe:field  /swe:DataRecord   Notice the field `stationID' whose value would be the ID of the entity/station that generated the record.", 
            "title": "Sensor Network API"
        }, 
        {
            "location": "/license/", 
            "text": "License\n\n\nOpenSensorHub is licensed under the Mozilla Public License, version 2.0, whose terms are as follows:\n\n\n\nMozilla Public License, version 2.0\n\n1. Definitions\n\n1.1. \"Contributor\"\n\n     means each individual or legal entity that creates, contributes to the\n     creation of, or owns Covered Software.\n\n1.2. \"Contributor Version\"\n\n     means the combination of the Contributions of others (if any) used by a\n     Contributor and that particular Contributor's Contribution.\n\n1.3. \"Contribution\"\n\n     means Covered Software of a particular Contributor.\n\n1.4. \"Covered Software\"\n\n     means Source Code Form to which the initial Contributor has attached the\n     notice in Exhibit A, the Executable Form of such Source Code Form, and\n     Modifications of such Source Code Form, in each case including portions\n     thereof.\n\n1.5. \"Incompatible With Secondary Licenses\"\n     means\n\n     a. that the initial Contributor has attached the notice described in\n        Exhibit B to the Covered Software; or\n\n     b. that the Covered Software was made available under the terms of\n        version 1.1 or earlier of the License, but not also under the terms of\n        a Secondary License.\n\n1.6. \"Executable Form\"\n\n     means any form of the work other than Source Code Form.\n\n1.7. \"Larger Work\"\n\n     means a work that combines Covered Software with other material, in a\n     separate file or files, that is not Covered Software.\n\n1.8. \"License\"\n\n     means this document.\n\n1.9. \"Licensable\"\n\n     means having the right to grant, to the maximum extent possible, whether\n     at the time of the initial grant or subsequently, any and all of the\n     rights conveyed by this License.\n\n1.10. \"Modifications\"\n\n     means any of the following:\n\n     a. any file in Source Code Form that results from an addition to,\n        deletion from, or modification of the contents of Covered Software; or\n\n     b. any new file in Source Code Form that contains any Covered Software.\n\n1.11. \"Patent Claims\" of a Contributor\n\n      means any patent claim(s), including without limitation, method,\n      process, and apparatus claims, in any patent Licensable by such\n      Contributor that would be infringed, but for the grant of the License,\n      by the making, using, selling, offering for sale, having made, import,\n      or transfer of either its Contributions or its Contributor Version.\n\n1.12. \"Secondary License\"\n\n      means either the GNU General Public License, Version 2.0, the GNU Lesser\n      General Public License, Version 2.1, the GNU Affero General Public\n      License, Version 3.0, or any later versions of those licenses.\n\n1.13. \"Source Code Form\"\n\n      means the form of the work preferred for making modifications.\n\n1.14. \"You\" (or \"Your\")\n\n      means an individual or a legal entity exercising rights under this\n      License. For legal entities, \"You\" includes any entity that controls, is\n      controlled by, or is under common control with You. For purposes of this\n      definition, \"control\" means (a) the power, direct or indirect, to cause\n      the direction or management of such entity, whether by contract or\n      otherwise, or (b) ownership of more than fifty percent (50%) of the\n      outstanding shares or beneficial ownership of such entity.\n\n\n2. License Grants and Conditions\n\n2.1. Grants\n\n     Each Contributor hereby grants You a world-wide, royalty-free,\n     non-exclusive license:\n\n     a. under intellectual property rights (other than patent or trademark)\n        Licensable by such Contributor to use, reproduce, make available,\n        modify, display, perform, distribute, and otherwise exploit its\n        Contributions, either on an unmodified basis, with Modifications, or\n        as part of a Larger Work; and\n\n     b. under Patent Claims of such Contributor to make, use, sell, offer for\n        sale, have made, import, and otherwise transfer either its\n        Contributions or its Contributor Version.\n\n2.2. Effective Date\n\n     The licenses granted in Section 2.1 with respect to any Contribution\n     become effective for each Contribution on the date the Contributor first\n     distributes such Contribution.\n\n2.3. Limitations on Grant Scope\n\n     The licenses granted in this Section 2 are the only rights granted under\n     this License. No additional rights or licenses will be implied from the\n     distribution or licensing of Covered Software under this License.\n     Notwithstanding Section 2.1(b) above, no patent license is granted by a\n     Contributor:\n\n     a. for any code that a Contributor has removed from Covered Software; or\n\n     b. for infringements caused by: (i) Your and any other third party's\n        modifications of Covered Software, or (ii) the combination of its\n        Contributions with other software (except as part of its Contributor\n        Version); or\n\n     c. under Patent Claims infringed by Covered Software in the absence of\n        its Contributions.\n\n     This License does not grant any rights in the trademarks, service marks,\n     or logos of any Contributor (except as may be necessary to comply with\n     the notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\n     No Contributor makes additional grants as a result of Your choice to\n     distribute the Covered Software under a subsequent version of this\n     License (see Section 10.2) or under the terms of a Secondary License (if\n     permitted under the terms of Section 3.3).\n\n2.5. Representation\n\n     Each Contributor represents that the Contributor believes its\n     Contributions are its original creation(s) or it has sufficient rights to\n     grant the rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\n     This License is not intended to limit any rights You have under\n     applicable copyright doctrines of fair use, fair dealing, or other\n     equivalents.\n\n2.7. Conditions\n\n     Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in\n     Section 2.1.\n\n\n3. Responsibilities\n\n3.1. Distribution of Source Form\n\n     All distribution of Covered Software in Source Code Form, including any\n     Modifications that You create or to which You contribute, must be under\n     the terms of this License. You must inform recipients that the Source\n     Code Form of the Covered Software is governed by the terms of this\n     License, and how they can obtain a copy of this License. You may not\n     attempt to alter or restrict the recipients' rights in the Source Code\n     Form.\n\n3.2. Distribution of Executable Form\n\n     If You distribute Covered Software in Executable Form then:\n\n     a. such Covered Software must also be made available in Source Code Form,\n        as described in Section 3.1, and You must inform recipients of the\n        Executable Form how they can obtain a copy of such Source Code Form by\n        reasonable means in a timely manner, at a charge no more than the cost\n        of distribution to the recipient; and\n\n     b. You may distribute such Executable Form under the terms of this\n        License, or sublicense it under different terms, provided that the\n        license for the Executable Form does not attempt to limit or alter the\n        recipients' rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\n     You may create and distribute a Larger Work under terms of Your choice,\n     provided that You also comply with the requirements of this License for\n     the Covered Software. If the Larger Work is a combination of Covered\n     Software with a work governed by one or more Secondary Licenses, and the\n     Covered Software is not Incompatible With Secondary Licenses, this\n     License permits You to additionally distribute such Covered Software\n     under the terms of such Secondary License(s), so that the recipient of\n     the Larger Work may, at their option, further distribute the Covered\n     Software under the terms of either this License or such Secondary\n     License(s).\n\n3.4. Notices\n\n     You may not remove or alter the substance of any license notices\n     (including copyright notices, patent notices, disclaimers of warranty, or\n     limitations of liability) contained within the Source Code Form of the\n     Covered Software, except that You may alter any license notices to the\n     extent required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\n     You may choose to offer, and to charge a fee for, warranty, support,\n     indemnity or liability obligations to one or more recipients of Covered\n     Software. However, You may do so only on Your own behalf, and not on\n     behalf of any Contributor. You must make it absolutely clear that any\n     such warranty, support, indemnity, or liability obligation is offered by\n     You alone, and You hereby agree to indemnify every Contributor for any\n     liability incurred by such Contributor as a result of warranty, support,\n     indemnity or liability terms You offer. You may include additional\n     disclaimers of warranty and limitations of liability specific to any\n     jurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n\n   If it is impossible for You to comply with any of the terms of this License\n   with respect to some or all of the Covered Software due to statute,\n   judicial order, or regulation then You must: (a) comply with the terms of\n   this License to the maximum extent possible; and (b) describe the\n   limitations and the code they affect. Such description must be placed in a\n   text file included with all distributions of the Covered Software under\n   this License. Except to the extent prohibited by statute or regulation,\n   such description must be sufficiently detailed for a recipient of ordinary\n   skill to be able to understand it.\n\n5. Termination\n\n5.1. The rights granted under this License will terminate automatically if You\n     fail to comply with any of its terms. However, if You become compliant,\n     then the rights granted under this License from a particular Contributor\n     are reinstated (a) provisionally, unless and until such Contributor\n     explicitly and finally terminates Your grants, and (b) on an ongoing\n     basis, if such Contributor fails to notify You of the non-compliance by\n     some reasonable means prior to 60 days after You have come back into\n     compliance. Moreover, Your grants from a particular Contributor are\n     reinstated on an ongoing basis if such Contributor notifies You of the\n     non-compliance by some reasonable means, this is the first time You have\n     received notice of non-compliance with this License from such\n     Contributor, and You become compliant prior to 30 days after Your receipt\n     of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\n     infringement claim (excluding declaratory judgment actions,\n     counter-claims, and cross-claims) alleging that a Contributor Version\n     directly or indirectly infringes any patent, then the rights granted to\n     You by any and all Contributors for the Covered Software under Section\n     2.1 of this License shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user\n     license agreements (excluding distributors and resellers) which have been\n     validly granted by You or Your distributors under this License prior to\n     termination shall survive termination.\n\n6. Disclaimer of Warranty\n\n   Covered Software is provided under this License on an \"as is\" basis,\n   without warranty of any kind, either expressed, implied, or statutory,\n   including, without limitation, warranties that the Covered Software is free\n   of defects, merchantable, fit for a particular purpose or non-infringing.\n   The entire risk as to the quality and performance of the Covered Software\n   is with You. Should any Covered Software prove defective in any respect,\n   You (not any Contributor) assume the cost of any necessary servicing,\n   repair, or correction. This disclaimer of warranty constitutes an essential\n   part of this License. No use of  any Covered Software is authorized under\n   this License except under this disclaimer.\n\n7. Limitation of Liability\n\n   Under no circumstances and under no legal theory, whether tort (including\n   negligence), contract, or otherwise, shall any Contributor, or anyone who\n   distributes Covered Software as permitted above, be liable to You for any\n   direct, indirect, special, incidental, or consequential damages of any\n   character including, without limitation, damages for lost profits, loss of\n   goodwill, work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses, even if such party shall have been\n   informed of the possibility of such damages. This limitation of liability\n   shall not apply to liability for death or personal injury resulting from\n   such party's negligence to the extent applicable law prohibits such\n   limitation. Some jurisdictions do not allow the exclusion or limitation of\n   incidental or consequential damages, so this exclusion and limitation may\n   not apply to You.\n\n8. Litigation\n\n   Any litigation relating to this License may be brought only in the courts\n   of a jurisdiction where the defendant maintains its principal place of\n   business and such litigation shall be governed by laws of that\n   jurisdiction, without reference to its conflict-of-law provisions. Nothing\n   in this Section shall prevent a party's ability to bring cross-claims or\n   counter-claims.\n\n9. Miscellaneous\n\n   This License represents the complete agreement concerning the subject\n   matter hereof. If any provision of this License is held to be\n   unenforceable, such provision shall be reformed only to the extent\n   necessary to make it enforceable. Any law or regulation which provides that\n   the language of a contract shall be construed against the drafter shall not\n   be used to construe this License against a Contributor.\n\n\n10. Versions of the License\n\n10.1. New Versions\n\n      Mozilla Foundation is the license steward. Except as provided in Section\n      10.3, no one other than the license steward has the right to modify or\n      publish new versions of this License. Each version will be given a\n      distinguishing version number.\n\n10.2. Effect of New Versions\n\n      You may distribute the Covered Software under the terms of the version\n      of the License under which You originally received the Covered Software,\n      or under the terms of any subsequent version published by the license\n      steward.\n\n10.3. Modified Versions\n\n      If you create software not governed by this License, and you want to\n      create a new license for such software, you may create and use a\n      modified version of this License if you rename the license and remove\n      any references to the name of the license steward (except to note that\n      such modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary\n      Licenses If You choose to distribute Source Code Form that is\n      Incompatible With Secondary Licenses under the terms of this version of\n      the License, the notice described in Exhibit B of this License must be\n      attached.\n\nExhibit A - Source Code Form License Notice\n\n      This Source Code Form is subject to the\n      terms of the Mozilla Public License, v.\n      2.0. If a copy of the MPL was not\n      distributed with this file, You can\n      obtain one at\n      http://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular file,\nthen You may include the notice in a location (such as a LICENSE file in a\nrelevant directory) where a recipient would be likely to look for such a\nnotice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - \"Incompatible With Secondary Licenses\" Notice\n\n      This Source Code Form is \"Incompatible\n      With Secondary Licenses\", as defined by\n      the Mozilla Public License, v. 2.0.", 
            "title": "License"
        }, 
        {
            "location": "/license/#license", 
            "text": "OpenSensorHub is licensed under the Mozilla Public License, version 2.0, whose terms are as follows:  \nMozilla Public License, version 2.0\n\n1. Definitions\n\n1.1. \"Contributor\"\n\n     means each individual or legal entity that creates, contributes to the\n     creation of, or owns Covered Software.\n\n1.2. \"Contributor Version\"\n\n     means the combination of the Contributions of others (if any) used by a\n     Contributor and that particular Contributor's Contribution.\n\n1.3. \"Contribution\"\n\n     means Covered Software of a particular Contributor.\n\n1.4. \"Covered Software\"\n\n     means Source Code Form to which the initial Contributor has attached the\n     notice in Exhibit A, the Executable Form of such Source Code Form, and\n     Modifications of such Source Code Form, in each case including portions\n     thereof.\n\n1.5. \"Incompatible With Secondary Licenses\"\n     means\n\n     a. that the initial Contributor has attached the notice described in\n        Exhibit B to the Covered Software; or\n\n     b. that the Covered Software was made available under the terms of\n        version 1.1 or earlier of the License, but not also under the terms of\n        a Secondary License.\n\n1.6. \"Executable Form\"\n\n     means any form of the work other than Source Code Form.\n\n1.7. \"Larger Work\"\n\n     means a work that combines Covered Software with other material, in a\n     separate file or files, that is not Covered Software.\n\n1.8. \"License\"\n\n     means this document.\n\n1.9. \"Licensable\"\n\n     means having the right to grant, to the maximum extent possible, whether\n     at the time of the initial grant or subsequently, any and all of the\n     rights conveyed by this License.\n\n1.10. \"Modifications\"\n\n     means any of the following:\n\n     a. any file in Source Code Form that results from an addition to,\n        deletion from, or modification of the contents of Covered Software; or\n\n     b. any new file in Source Code Form that contains any Covered Software.\n\n1.11. \"Patent Claims\" of a Contributor\n\n      means any patent claim(s), including without limitation, method,\n      process, and apparatus claims, in any patent Licensable by such\n      Contributor that would be infringed, but for the grant of the License,\n      by the making, using, selling, offering for sale, having made, import,\n      or transfer of either its Contributions or its Contributor Version.\n\n1.12. \"Secondary License\"\n\n      means either the GNU General Public License, Version 2.0, the GNU Lesser\n      General Public License, Version 2.1, the GNU Affero General Public\n      License, Version 3.0, or any later versions of those licenses.\n\n1.13. \"Source Code Form\"\n\n      means the form of the work preferred for making modifications.\n\n1.14. \"You\" (or \"Your\")\n\n      means an individual or a legal entity exercising rights under this\n      License. For legal entities, \"You\" includes any entity that controls, is\n      controlled by, or is under common control with You. For purposes of this\n      definition, \"control\" means (a) the power, direct or indirect, to cause\n      the direction or management of such entity, whether by contract or\n      otherwise, or (b) ownership of more than fifty percent (50%) of the\n      outstanding shares or beneficial ownership of such entity.\n\n\n2. License Grants and Conditions\n\n2.1. Grants\n\n     Each Contributor hereby grants You a world-wide, royalty-free,\n     non-exclusive license:\n\n     a. under intellectual property rights (other than patent or trademark)\n        Licensable by such Contributor to use, reproduce, make available,\n        modify, display, perform, distribute, and otherwise exploit its\n        Contributions, either on an unmodified basis, with Modifications, or\n        as part of a Larger Work; and\n\n     b. under Patent Claims of such Contributor to make, use, sell, offer for\n        sale, have made, import, and otherwise transfer either its\n        Contributions or its Contributor Version.\n\n2.2. Effective Date\n\n     The licenses granted in Section 2.1 with respect to any Contribution\n     become effective for each Contribution on the date the Contributor first\n     distributes such Contribution.\n\n2.3. Limitations on Grant Scope\n\n     The licenses granted in this Section 2 are the only rights granted under\n     this License. No additional rights or licenses will be implied from the\n     distribution or licensing of Covered Software under this License.\n     Notwithstanding Section 2.1(b) above, no patent license is granted by a\n     Contributor:\n\n     a. for any code that a Contributor has removed from Covered Software; or\n\n     b. for infringements caused by: (i) Your and any other third party's\n        modifications of Covered Software, or (ii) the combination of its\n        Contributions with other software (except as part of its Contributor\n        Version); or\n\n     c. under Patent Claims infringed by Covered Software in the absence of\n        its Contributions.\n\n     This License does not grant any rights in the trademarks, service marks,\n     or logos of any Contributor (except as may be necessary to comply with\n     the notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\n     No Contributor makes additional grants as a result of Your choice to\n     distribute the Covered Software under a subsequent version of this\n     License (see Section 10.2) or under the terms of a Secondary License (if\n     permitted under the terms of Section 3.3).\n\n2.5. Representation\n\n     Each Contributor represents that the Contributor believes its\n     Contributions are its original creation(s) or it has sufficient rights to\n     grant the rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\n     This License is not intended to limit any rights You have under\n     applicable copyright doctrines of fair use, fair dealing, or other\n     equivalents.\n\n2.7. Conditions\n\n     Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in\n     Section 2.1.\n\n\n3. Responsibilities\n\n3.1. Distribution of Source Form\n\n     All distribution of Covered Software in Source Code Form, including any\n     Modifications that You create or to which You contribute, must be under\n     the terms of this License. You must inform recipients that the Source\n     Code Form of the Covered Software is governed by the terms of this\n     License, and how they can obtain a copy of this License. You may not\n     attempt to alter or restrict the recipients' rights in the Source Code\n     Form.\n\n3.2. Distribution of Executable Form\n\n     If You distribute Covered Software in Executable Form then:\n\n     a. such Covered Software must also be made available in Source Code Form,\n        as described in Section 3.1, and You must inform recipients of the\n        Executable Form how they can obtain a copy of such Source Code Form by\n        reasonable means in a timely manner, at a charge no more than the cost\n        of distribution to the recipient; and\n\n     b. You may distribute such Executable Form under the terms of this\n        License, or sublicense it under different terms, provided that the\n        license for the Executable Form does not attempt to limit or alter the\n        recipients' rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\n     You may create and distribute a Larger Work under terms of Your choice,\n     provided that You also comply with the requirements of this License for\n     the Covered Software. If the Larger Work is a combination of Covered\n     Software with a work governed by one or more Secondary Licenses, and the\n     Covered Software is not Incompatible With Secondary Licenses, this\n     License permits You to additionally distribute such Covered Software\n     under the terms of such Secondary License(s), so that the recipient of\n     the Larger Work may, at their option, further distribute the Covered\n     Software under the terms of either this License or such Secondary\n     License(s).\n\n3.4. Notices\n\n     You may not remove or alter the substance of any license notices\n     (including copyright notices, patent notices, disclaimers of warranty, or\n     limitations of liability) contained within the Source Code Form of the\n     Covered Software, except that You may alter any license notices to the\n     extent required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\n     You may choose to offer, and to charge a fee for, warranty, support,\n     indemnity or liability obligations to one or more recipients of Covered\n     Software. However, You may do so only on Your own behalf, and not on\n     behalf of any Contributor. You must make it absolutely clear that any\n     such warranty, support, indemnity, or liability obligation is offered by\n     You alone, and You hereby agree to indemnify every Contributor for any\n     liability incurred by such Contributor as a result of warranty, support,\n     indemnity or liability terms You offer. You may include additional\n     disclaimers of warranty and limitations of liability specific to any\n     jurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n\n   If it is impossible for You to comply with any of the terms of this License\n   with respect to some or all of the Covered Software due to statute,\n   judicial order, or regulation then You must: (a) comply with the terms of\n   this License to the maximum extent possible; and (b) describe the\n   limitations and the code they affect. Such description must be placed in a\n   text file included with all distributions of the Covered Software under\n   this License. Except to the extent prohibited by statute or regulation,\n   such description must be sufficiently detailed for a recipient of ordinary\n   skill to be able to understand it.\n\n5. Termination\n\n5.1. The rights granted under this License will terminate automatically if You\n     fail to comply with any of its terms. However, if You become compliant,\n     then the rights granted under this License from a particular Contributor\n     are reinstated (a) provisionally, unless and until such Contributor\n     explicitly and finally terminates Your grants, and (b) on an ongoing\n     basis, if such Contributor fails to notify You of the non-compliance by\n     some reasonable means prior to 60 days after You have come back into\n     compliance. Moreover, Your grants from a particular Contributor are\n     reinstated on an ongoing basis if such Contributor notifies You of the\n     non-compliance by some reasonable means, this is the first time You have\n     received notice of non-compliance with this License from such\n     Contributor, and You become compliant prior to 30 days after Your receipt\n     of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\n     infringement claim (excluding declaratory judgment actions,\n     counter-claims, and cross-claims) alleging that a Contributor Version\n     directly or indirectly infringes any patent, then the rights granted to\n     You by any and all Contributors for the Covered Software under Section\n     2.1 of this License shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user\n     license agreements (excluding distributors and resellers) which have been\n     validly granted by You or Your distributors under this License prior to\n     termination shall survive termination.\n\n6. Disclaimer of Warranty\n\n   Covered Software is provided under this License on an \"as is\" basis,\n   without warranty of any kind, either expressed, implied, or statutory,\n   including, without limitation, warranties that the Covered Software is free\n   of defects, merchantable, fit for a particular purpose or non-infringing.\n   The entire risk as to the quality and performance of the Covered Software\n   is with You. Should any Covered Software prove defective in any respect,\n   You (not any Contributor) assume the cost of any necessary servicing,\n   repair, or correction. This disclaimer of warranty constitutes an essential\n   part of this License. No use of  any Covered Software is authorized under\n   this License except under this disclaimer.\n\n7. Limitation of Liability\n\n   Under no circumstances and under no legal theory, whether tort (including\n   negligence), contract, or otherwise, shall any Contributor, or anyone who\n   distributes Covered Software as permitted above, be liable to You for any\n   direct, indirect, special, incidental, or consequential damages of any\n   character including, without limitation, damages for lost profits, loss of\n   goodwill, work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses, even if such party shall have been\n   informed of the possibility of such damages. This limitation of liability\n   shall not apply to liability for death or personal injury resulting from\n   such party's negligence to the extent applicable law prohibits such\n   limitation. Some jurisdictions do not allow the exclusion or limitation of\n   incidental or consequential damages, so this exclusion and limitation may\n   not apply to You.\n\n8. Litigation\n\n   Any litigation relating to this License may be brought only in the courts\n   of a jurisdiction where the defendant maintains its principal place of\n   business and such litigation shall be governed by laws of that\n   jurisdiction, without reference to its conflict-of-law provisions. Nothing\n   in this Section shall prevent a party's ability to bring cross-claims or\n   counter-claims.\n\n9. Miscellaneous\n\n   This License represents the complete agreement concerning the subject\n   matter hereof. If any provision of this License is held to be\n   unenforceable, such provision shall be reformed only to the extent\n   necessary to make it enforceable. Any law or regulation which provides that\n   the language of a contract shall be construed against the drafter shall not\n   be used to construe this License against a Contributor.\n\n\n10. Versions of the License\n\n10.1. New Versions\n\n      Mozilla Foundation is the license steward. Except as provided in Section\n      10.3, no one other than the license steward has the right to modify or\n      publish new versions of this License. Each version will be given a\n      distinguishing version number.\n\n10.2. Effect of New Versions\n\n      You may distribute the Covered Software under the terms of the version\n      of the License under which You originally received the Covered Software,\n      or under the terms of any subsequent version published by the license\n      steward.\n\n10.3. Modified Versions\n\n      If you create software not governed by this License, and you want to\n      create a new license for such software, you may create and use a\n      modified version of this License if you rename the license and remove\n      any references to the name of the license steward (except to note that\n      such modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary\n      Licenses If You choose to distribute Source Code Form that is\n      Incompatible With Secondary Licenses under the terms of this version of\n      the License, the notice described in Exhibit B of this License must be\n      attached.\n\nExhibit A - Source Code Form License Notice\n\n      This Source Code Form is subject to the\n      terms of the Mozilla Public License, v.\n      2.0. If a copy of the MPL was not\n      distributed with this file, You can\n      obtain one at\n      http://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular file,\nthen You may include the notice in a location (such as a LICENSE file in a\nrelevant directory) where a recipient would be likely to look for such a\nnotice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - \"Incompatible With Secondary Licenses\" Notice\n\n      This Source Code Form is \"Incompatible\n      With Secondary Licenses\", as defined by\n      the Mozilla Public License, v. 2.0.", 
            "title": "License"
        }
    ]
}