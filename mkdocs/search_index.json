{
    "docs": [
        {
            "location": "/", 
            "text": "OpenSensorHub Documentation\n\n\nOpenSensorHub (OSH) allows one to easily build interoperable and evolutive sensor networks, based on open-standards for all data exchanges, and providing advanced processing capabilities. The open-standards used are mostly \nOGC\n standards from the \nSensor Web Enablement\n (SWE) initiative and are key to design sensor networks that can largely evolve with time (addition of new types of sensors, reconfigurations, etc.).\n\n\nThe Java framework allows one to connect any kind of sensors and actuators to a common bus via a simple yet generic driver API. Sensors can be connected through any available hardware interface such as \nRS232/422\n, \nSPI\n, \nI2C\n, \nUSB\n, \nEthernet\n, \nWifi\n, \nBluetooth\n, \nZigBee\n, \nHTTP\n, etc... Once drivers are available for a specific sensor, it is automatically connected to the bus and it is then trivial to send commands and read data from it. An intuitive user interface allows the user to configure the network to suit its needs and more advanced processing capabilities are available via a plugin system.\n\n\nSensorHub embeds the full power of OGC web services (\nSensor Observation Service\n or SOS, \nSensor Planning Service\n or SPS) to communicate with all connected sensors in the network and provide robust metadata (owner, location and orientation, calibration, etc.). Through these standards, several SensorHub instances can also communicate with each other to form larger networks.\n\n\nLow level functions of SensorHub (send commands and read data from sensor) are coded efficiently and can be used on embedded hardware running \nJava SE\u00ae\n, \nJava ME\u00ae\n or \nAndroid\u00ae\n while more advanced data processing capabilities are fully multi-threaded and can thus benefit from a more powerful hardware platform (e.g. multi-processor servers or even clusters).\n\n\nSensorHub is pure java software but we have plans to release parts of this software in other languages (Arduino, C++) to be used on low power micro-controllers (note that some more powerful ARM micro-controllers can also run the Java version directly using \nJava ME\u00ae\n).\n\n\nIf you're interested in knowing more, this \nFOSS4G Presentation\n gives an overview of SensorHub's architecture and APIs. We also encourage you to read through the technical documentation available on this website.\n\n\nPlease report all problems related to the SensorHub software including documentation errors via the \nGitHub Issue Tracker\n of the corresponding repository.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#opensensorhub-documentation", 
            "text": "OpenSensorHub (OSH) allows one to easily build interoperable and evolutive sensor networks, based on open-standards for all data exchanges, and providing advanced processing capabilities. The open-standards used are mostly  OGC  standards from the  Sensor Web Enablement  (SWE) initiative and are key to design sensor networks that can largely evolve with time (addition of new types of sensors, reconfigurations, etc.).  The Java framework allows one to connect any kind of sensors and actuators to a common bus via a simple yet generic driver API. Sensors can be connected through any available hardware interface such as  RS232/422 ,  SPI ,  I2C ,  USB ,  Ethernet ,  Wifi ,  Bluetooth ,  ZigBee ,  HTTP , etc... Once drivers are available for a specific sensor, it is automatically connected to the bus and it is then trivial to send commands and read data from it. An intuitive user interface allows the user to configure the network to suit its needs and more advanced processing capabilities are available via a plugin system.  SensorHub embeds the full power of OGC web services ( Sensor Observation Service  or SOS,  Sensor Planning Service  or SPS) to communicate with all connected sensors in the network and provide robust metadata (owner, location and orientation, calibration, etc.). Through these standards, several SensorHub instances can also communicate with each other to form larger networks.  Low level functions of SensorHub (send commands and read data from sensor) are coded efficiently and can be used on embedded hardware running  Java SE\u00ae ,  Java ME\u00ae  or  Android\u00ae  while more advanced data processing capabilities are fully multi-threaded and can thus benefit from a more powerful hardware platform (e.g. multi-processor servers or even clusters).  SensorHub is pure java software but we have plans to release parts of this software in other languages (Arduino, C++) to be used on low power micro-controllers (note that some more powerful ARM micro-controllers can also run the Java version directly using  Java ME\u00ae ).  If you're interested in knowing more, this  FOSS4G Presentation  gives an overview of SensorHub's architecture and APIs. We also encourage you to read through the technical documentation available on this website.  Please report all problems related to the SensorHub software including documentation errors via the  GitHub Issue Tracker  of the corresponding repository.", 
            "title": "OpenSensorHub Documentation"
        }, 
        {
            "location": "/download/", 
            "text": "How To Download\n\n\nReleases\n\n\nBinary and Source distributions archives can be downloaded directly from the \nReleases Section\n of our GitHub account.\n\n\nYou'll soon find there pre-configured distributions for the most common devices such as:\n\n\n\n\nAndroid\n\n\nRaspberry Pi\n\n\nDesktop Linux\n\n\nWindows\n\n\n\n\nSee the \nInstall Section\n for instructions on how to set it up on your device.\n\n\nMaven\n\n\nYou can also use Maven to include OSH in your own project. \nFor instance, if you want to develop a new sensor driver, you can simply add a dependency to the OpenSensorHub Core module in your POM:\n\n\ndependency\n\n   \ngroupId\norg.sensorhub\n/groupId\n\n   \nartifactId\nsensorhub-core\n/artifactId\n\n   \nversion\n1.0\n/version\n\n   \ntype\nbundle\n/type\n\n\n/dependency\n \n\n\n\n\nHowever, OpenSensorHub is not available from Maven Central yet, so you'll also have to include the following repository in your POM:\n\n\nrepositories\n\n   \nrepository\n\n      \nid\nsensiasoft\n/id\n\n      \nurl\nhttp://sensiasoft.net/maven-repo\n/url\n\n   \n/repository\n\n\n/repositories\n   \n\n\n\n\nOur Maven repository is also an OSGI Bundle Repository, so you can also use any OSGI implementation to download Bundles dynamically.", 
            "title": "Download"
        }, 
        {
            "location": "/download/#how-to-download", 
            "text": "", 
            "title": "How To Download"
        }, 
        {
            "location": "/download/#releases", 
            "text": "Binary and Source distributions archives can be downloaded directly from the  Releases Section  of our GitHub account.  You'll soon find there pre-configured distributions for the most common devices such as:   Android  Raspberry Pi  Desktop Linux  Windows   See the  Install Section  for instructions on how to set it up on your device.", 
            "title": "Releases"
        }, 
        {
            "location": "/download/#maven", 
            "text": "You can also use Maven to include OSH in your own project. \nFor instance, if you want to develop a new sensor driver, you can simply add a dependency to the OpenSensorHub Core module in your POM:  dependency \n    groupId org.sensorhub /groupId \n    artifactId sensorhub-core /artifactId \n    version 1.0 /version \n    type bundle /type  /dependency    However, OpenSensorHub is not available from Maven Central yet, so you'll also have to include the following repository in your POM:  repositories \n    repository \n       id sensiasoft /id \n       url http://sensiasoft.net/maven-repo /url \n    /repository  /repositories      Our Maven repository is also an OSGI Bundle Repository, so you can also use any OSGI implementation to download Bundles dynamically.", 
            "title": "Maven"
        }, 
        {
            "location": "/install/", 
            "text": "How To Install\n\n\nThis page describes how to install OpenSensorHub (OSH for short) binary release so you can test it on your own platform. The process is actually really easy thanks to the use of embedded Jetty, so it should not take you more than 5 minutes to get a running OSH instance on your machine. (\nNOTE: Installation on Android phones and tablets is through a separate APK file\n).\n\n\nPrerequisistes\n\n\nIn order for OSH to run, you will need a working installation of Java JDK 7.\n\n\nOn Linux, we have successfully tested SensorHub with both OpenJDK and Oracle JDK.\n\n\nSetup\n\n\n\n\nFirst download the latest OSH binary release (both 'core' and 'sensors' zip files) from our \nGitHub Release Page\n\n\nUnzip both files to a directory of your choice\n\n\nExecute the \nlaunch.sh\n script (on Linux or MacOS) or \nlaunch.bat\n (on Windows)\n\n\nYou should now be able to connect to \nhttp://localhost:8181/sensorhub/test\n and get the message \nSensorHub web server is up\n\n\n\n\nNote: This release has been tested on Ubuntu Linux, MacOS X and Windows 7.\n\n\nDemo Configuration\n\n\nThe demo configuration provided with the binary release instructs OSH to start the following components:\n\n\n\n\nThe embedded Jetty server\n\n\nThe web admin UI\n\n\nThe simulated GPS example sensor\n\n\nThe simulated weather example sensor\n\n\nEmbedded storage instances for data produced by the 2 sensors\n\n\nAn SOS service connected to the real-time feeds and storages\n\n\n\n\nConnect to the Sensor Observation Service (SOS)\n\n\nYou can connect right away to the SOS endpoint to get sensor data and metadata. Here are some examples that work with the installed simulated sensors:\n\n\n\n\nGetCapabilities\n\n\nGet Weather Result Template\n\n\nGet Latest Weather Measurement\n\n\nGet Historical Weather Measurements\n\n\n\n\nAlso take a look at this simple \ndemo client\n that connects to the fake GPS live feed through websockets to display it on a map using OpenLayers. You can easily reproduce this locally.\n\n\nMore example data feed are also available \nHere\n.\n\n\nConnect to the Admin Console\n\n\nYou can connect to the \nAdmin Console\n at \nhttp://localhost:8181/sensorhub/admin\n.\n\n\nWhen active, the console allows you to manage all OSH modules including sensors, processing chains, storage units, as well as service interfaces such as Sensor Observation Services (SOS) or Sensor Planning Services (SPS).\n\n\nLogging Configuration\n\n\nAll logging is made via logback and the configuration is done via the \nlogback.xml\n file included in the distribution.\nFor instance, you can enable SensorHub debug logs by changing the following line in this file:\n\n\nlogger name=\"org.sensorhub\" level=\"info\"/\n\n\n\n\nto\n\n\nlogger name=\"org.sensorhub\" level=\"debug\"/\n\n\n\n\nSee the \nLogback Documentation\n for more details.", 
            "title": "Installation"
        }, 
        {
            "location": "/install/#how-to-install", 
            "text": "This page describes how to install OpenSensorHub (OSH for short) binary release so you can test it on your own platform. The process is actually really easy thanks to the use of embedded Jetty, so it should not take you more than 5 minutes to get a running OSH instance on your machine. ( NOTE: Installation on Android phones and tablets is through a separate APK file ).", 
            "title": "How To Install"
        }, 
        {
            "location": "/install/#prerequisistes", 
            "text": "In order for OSH to run, you will need a working installation of Java JDK 7.  On Linux, we have successfully tested SensorHub with both OpenJDK and Oracle JDK.", 
            "title": "Prerequisistes"
        }, 
        {
            "location": "/install/#setup", 
            "text": "First download the latest OSH binary release (both 'core' and 'sensors' zip files) from our  GitHub Release Page  Unzip both files to a directory of your choice  Execute the  launch.sh  script (on Linux or MacOS) or  launch.bat  (on Windows)  You should now be able to connect to  http://localhost:8181/sensorhub/test  and get the message  SensorHub web server is up   Note: This release has been tested on Ubuntu Linux, MacOS X and Windows 7.", 
            "title": "Setup"
        }, 
        {
            "location": "/install/#demo-configuration", 
            "text": "The demo configuration provided with the binary release instructs OSH to start the following components:   The embedded Jetty server  The web admin UI  The simulated GPS example sensor  The simulated weather example sensor  Embedded storage instances for data produced by the 2 sensors  An SOS service connected to the real-time feeds and storages", 
            "title": "Demo Configuration"
        }, 
        {
            "location": "/install/#connect-to-the-sensor-observation-service-sos", 
            "text": "You can connect right away to the SOS endpoint to get sensor data and metadata. Here are some examples that work with the installed simulated sensors:   GetCapabilities  Get Weather Result Template  Get Latest Weather Measurement  Get Historical Weather Measurements   Also take a look at this simple  demo client  that connects to the fake GPS live feed through websockets to display it on a map using OpenLayers. You can easily reproduce this locally.  More example data feed are also available  Here .", 
            "title": "Connect to the Sensor Observation Service (SOS)"
        }, 
        {
            "location": "/install/#connect-to-the-admin-console", 
            "text": "You can connect to the  Admin Console  at  http://localhost:8181/sensorhub/admin .  When active, the console allows you to manage all OSH modules including sensors, processing chains, storage units, as well as service interfaces such as Sensor Observation Services (SOS) or Sensor Planning Services (SPS).", 
            "title": "Connect to the Admin Console"
        }, 
        {
            "location": "/install/#logging-configuration", 
            "text": "All logging is made via logback and the configuration is done via the  logback.xml  file included in the distribution.\nFor instance, you can enable SensorHub debug logs by changing the following line in this file:  logger name=\"org.sensorhub\" level=\"info\"/   to  logger name=\"org.sensorhub\" level=\"debug\"/   See the  Logback Documentation  for more details.", 
            "title": "Logging Configuration"
        }, 
        {
            "location": "/user/user-guide/", 
            "text": "User's Guide\n\n\nThis guide will walk you through basics of using OpenSensorHub. I you haven't installed it on your platform yet, please do so first by following instructions on the \nDownload\n and \nInstall\n pages.\n\n\nWeb-based Admin Interface\n\n\nThe easiest way to use SensorHub is via the web-based interface. However, if something is not available from the UI, you can always edit the configuration file manually (See section \nConfiguration File\n). \n\n\nWhen SensorHub is running, you can connect to the following URL to access the administration page:\n\n\nhttp://localhost:8181/sensorhub/admin\n\n\n\nThis admin page allows you to do the following actions:\n\n\n\n\nAdd and configure new sensors (when proper driver was previously installed)\n\n\nAdd and configure sensor data storage\n\n\nAdd and configure SOS and SPS service instances\n\n\nExpose data streams and/or storage through SOS\n\n\nExpose sensor commands through SPS\n\n\n\n\nFor more details, see the \nWeb Admin Interface Manual\n.\n\n\nExample Javascript Clients\n\n\nAn example Javascript client that connects to OSH SOS service is included in the core distribution. This client displays GPS position on the map and receives real-time data via websockets.\nYou can access it \nHere\n.\n\n\nYou can also look at our other demo clients that are running online directly from our \nGitHub Demo Site\n\n\nConfiguration File\n\n\nOpenSensorHub's configuration is centralized in a single file. It is in JSON format so it can be easily viewed or modified in any text editor.\n\n\nThis file contains a list of module's configuration that are loaded in order when starting SensorHub. \n\n\nSWE Services\n\n\nOpenSensorHub includes implementations of standard web service interfaces from the OGC \nSensor Web Enablement\n (SWE) initiative.\n\n\nBelow are topics giving more information about these SWE services:\n\n\n\n\nSensor Observation Service (SOS)\n\n\nSensor Planning Service (SPS)\n\n\n\n\n(*) Modules are loaded in order except if a module needs another module to start. In this case, the dependent module is loaded as needed by the calling module. \n\n\nModule State\n\n\nThe internal state of each module is saved in a subfolder of the \nmodules\n folder whose name is the module's local ID. This folder can contain:\n\n\n\n\nA \nstate.txt\n file containing a list of key/value pairs corresponding to state properties that the module has saved\n\n\nZero or more \n.dat\n files that contain arbitrary data saved by the module", 
            "title": "Introduction"
        }, 
        {
            "location": "/user/user-guide/#users-guide", 
            "text": "This guide will walk you through basics of using OpenSensorHub. I you haven't installed it on your platform yet, please do so first by following instructions on the  Download  and  Install  pages.", 
            "title": "User's Guide"
        }, 
        {
            "location": "/user/user-guide/#web-based-admin-interface", 
            "text": "The easiest way to use SensorHub is via the web-based interface. However, if something is not available from the UI, you can always edit the configuration file manually (See section  Configuration File ).   When SensorHub is running, you can connect to the following URL to access the administration page:  http://localhost:8181/sensorhub/admin  This admin page allows you to do the following actions:   Add and configure new sensors (when proper driver was previously installed)  Add and configure sensor data storage  Add and configure SOS and SPS service instances  Expose data streams and/or storage through SOS  Expose sensor commands through SPS   For more details, see the  Web Admin Interface Manual .", 
            "title": "Web-based Admin Interface"
        }, 
        {
            "location": "/user/user-guide/#example-javascript-clients", 
            "text": "An example Javascript client that connects to OSH SOS service is included in the core distribution. This client displays GPS position on the map and receives real-time data via websockets.\nYou can access it  Here .  You can also look at our other demo clients that are running online directly from our  GitHub Demo Site", 
            "title": "Example Javascript Clients"
        }, 
        {
            "location": "/user/user-guide/#configuration-file", 
            "text": "OpenSensorHub's configuration is centralized in a single file. It is in JSON format so it can be easily viewed or modified in any text editor.  This file contains a list of module's configuration that are loaded in order when starting SensorHub.", 
            "title": "Configuration File"
        }, 
        {
            "location": "/user/user-guide/#swe-services", 
            "text": "OpenSensorHub includes implementations of standard web service interfaces from the OGC  Sensor Web Enablement  (SWE) initiative.  Below are topics giving more information about these SWE services:   Sensor Observation Service (SOS)  Sensor Planning Service (SPS)   (*) Modules are loaded in order except if a module needs another module to start. In this case, the dependent module is loaded as needed by the calling module.", 
            "title": "SWE Services"
        }, 
        {
            "location": "/user/user-guide/#module-state", 
            "text": "The internal state of each module is saved in a subfolder of the  modules  folder whose name is the module's local ID. This folder can contain:   A  state.txt  file containing a list of key/value pairs corresponding to state properties that the module has saved  Zero or more  .dat  files that contain arbitrary data saved by the module", 
            "title": "Module State"
        }, 
        {
            "location": "/user/protocols/", 
            "text": "Supported Protocols\n\n\nOpenSensorHub (OSH) has built-in support (via modules) for various procotols that sensor adapters and other modules can be built onto.\n\n\nNetwork Protocols\n\n\nHardware protocols modules are mainly used within a sensor adapter and provide the heavy lifting to support a particular type of hardware communication:\n\n\n\n\nSerial / RS232\n\n\nUSB Serial\n\n\nBluetooth Serial\n\n\nBluetooth LE + GATT\n\n\nWiFi / Ethernet with ZeroConf Discovery\n\n\n\n\nComing soon:\n\n\n\n\nZigbee\n\n\nZwave (via USB adapter)\n\n\nSigFox (via serial modem)\n\n\nLoRaWAN\n\n\n\n\nYou'll find the code supporting these different protocols in the \nosh-comm\n repo.\n\n\nIoT Protocols\n\n\nIoT protocols provide more advanced Plug \n Play capabilities as well as communication with other IoT systems such as the AWS IoT cloud platform:\n\n\n\n\nMQTT\n\n\n\n\nComing soon:\n\n\n\n\nBLE \"Generic Measurement Profile\"\n\n\nAdafruit Unified Sensor Driver\n\n\nCoAP\n\n\n\n\nWeb Protocols\n\n\nWe also support OGC web services and RESTFul interfaces that can be used to access, task and discover sensors connected to a Sensor Hub:\n\n\n\n\nSensor Observation Service (SOS + SOS-T)\n\n\nSensor Planning Service (SPS) \n\n\n\n\nComing soon:\n\n\n\n\nSensor Things API\n\n\nP2P Discovery Layer", 
            "title": "Supported Protocols"
        }, 
        {
            "location": "/user/protocols/#supported-protocols", 
            "text": "OpenSensorHub (OSH) has built-in support (via modules) for various procotols that sensor adapters and other modules can be built onto.", 
            "title": "Supported Protocols"
        }, 
        {
            "location": "/user/protocols/#network-protocols", 
            "text": "Hardware protocols modules are mainly used within a sensor adapter and provide the heavy lifting to support a particular type of hardware communication:   Serial / RS232  USB Serial  Bluetooth Serial  Bluetooth LE + GATT  WiFi / Ethernet with ZeroConf Discovery   Coming soon:   Zigbee  Zwave (via USB adapter)  SigFox (via serial modem)  LoRaWAN   You'll find the code supporting these different protocols in the  osh-comm  repo.", 
            "title": "Network Protocols"
        }, 
        {
            "location": "/user/protocols/#iot-protocols", 
            "text": "IoT protocols provide more advanced Plug   Play capabilities as well as communication with other IoT systems such as the AWS IoT cloud platform:   MQTT   Coming soon:   BLE \"Generic Measurement Profile\"  Adafruit Unified Sensor Driver  CoAP", 
            "title": "IoT Protocols"
        }, 
        {
            "location": "/user/protocols/#web-protocols", 
            "text": "We also support OGC web services and RESTFul interfaces that can be used to access, task and discover sensors connected to a Sensor Hub:   Sensor Observation Service (SOS + SOS-T)  Sensor Planning Service (SPS)    Coming soon:   Sensor Things API  P2P Discovery Layer", 
            "title": "Web Protocols"
        }, 
        {
            "location": "/user/sensors/", 
            "text": "Supported Sensors\n\n\nOpenSensorHub (OSH) is designed to connect to any sensor or actuator thanks to its very flexible data model.\n\n\nSensor Types\n\n\n\n\nVideo Cameras\n\n\nWeather Stations\n\n\nSimple Mono-variable Insitu Sensors (thermometers, barometers, )\n\n\n\n\nSensor Drivers\n\n\nPositioning\n\n\n\n\nNMEA GPS\n\n\nMTi IMU\n\n\nAdafruit Orientation Sensor (BNO055)\n\n\n\n\nVideo Cameras\n\n\n\n\nAxis PTZ Camera XXX Series\n\n\nDahua PTZ XXX Series\n\n\nVideo4Linux Cameras\n\n\nH264 RTP Cams\n\n\nFLIR One Thermal Camera\n\n\n\n\nWeather Sensors\n\n\n\n\nNOAA Nexrad Doppler Radars (continental US)\n\n\nVaisala Weather Station XXX Series\n\n\n\n\nUAV / Drones\n\n\n\n\nMAVLink Telemetry and Tasking (compatible with Ardupilot)\n\n\n\n\nOthers\n\n\n\n\nTruPulse Range Finder\n\n\nAdafruit Sensors via Unified Sensor Driver", 
            "title": "Supported Devices"
        }, 
        {
            "location": "/user/sensors/#supported-sensors", 
            "text": "OpenSensorHub (OSH) is designed to connect to any sensor or actuator thanks to its very flexible data model.", 
            "title": "Supported Sensors"
        }, 
        {
            "location": "/user/sensors/#sensor-types", 
            "text": "Video Cameras  Weather Stations  Simple Mono-variable Insitu Sensors (thermometers, barometers, )", 
            "title": "Sensor Types"
        }, 
        {
            "location": "/user/sensors/#sensor-drivers", 
            "text": "", 
            "title": "Sensor Drivers"
        }, 
        {
            "location": "/user/sensors/#positioning", 
            "text": "NMEA GPS  MTi IMU  Adafruit Orientation Sensor (BNO055)", 
            "title": "Positioning"
        }, 
        {
            "location": "/user/sensors/#video-cameras", 
            "text": "Axis PTZ Camera XXX Series  Dahua PTZ XXX Series  Video4Linux Cameras  H264 RTP Cams  FLIR One Thermal Camera", 
            "title": "Video Cameras"
        }, 
        {
            "location": "/user/sensors/#weather-sensors", 
            "text": "NOAA Nexrad Doppler Radars (continental US)  Vaisala Weather Station XXX Series", 
            "title": "Weather Sensors"
        }, 
        {
            "location": "/user/sensors/#uav-drones", 
            "text": "MAVLink Telemetry and Tasking (compatible with Ardupilot)", 
            "title": "UAV / Drones"
        }, 
        {
            "location": "/user/sensors/#others", 
            "text": "TruPulse Range Finder  Adafruit Sensors via Unified Sensor Driver", 
            "title": "Others"
        }, 
        {
            "location": "/user/web-admin/", 
            "text": "Web-Admin User Interface\n\n\nThe web based administration interface allows to change the configuration of all modules in OpenSensorHub. It can be secured or even completely disabled in the configuration file manually. If enabled, it is accessible on the local node at the following URL:\n\n\nhttp://localhost:8181/sensorhub/admin\n\n\nBelow is a screenshot of the user interface showing configuration settings for the simulated GPS sensor (used for testing).\n\n\n\n\nAdding Modules\n\n\nMost installed modules for which code has been installed can be instantiated using the interface. This is done by simply right clicking in one of the appropriate section (i.e. one of the panels in the accordion on the left), and selecting \"Add Module\". For example, let's add a new sensor driver module:\n\n\n\n\nYou will then be presented with a choice of installed modules that can be instantiated on the current node. The list will only show the modules whose type can be added in the current section. In our example, we see all sensor drivers currently available on our node since we clicked in the \"Sensors\" section.\n\n\n\n\nOnce the module is added, it's configuration form is automatically shown on the right and you can start changing its parameters.\n\n\nConfiguring Modules\n\n\nTo configure a module, simply select it on the left panel (after opening one of the main sections), and make the desired changes in the form that is displayed on the right. Once you're done, apply your changes, click the \"Apply Changes\" button. This makes the changes in the actual module configuration and, if the module handles configuration updates properly, the new configuration should be immediately reflected by the running module.\n\n\nStarting and Stopping Modules\n\n\nModules are started and stopped by right clicking on the module in the left panel and selecting \"Enable\" or \"Disable\" respectively.\n\n\nSecuring Access\n\n\nTODO", 
            "title": "Web Admin"
        }, 
        {
            "location": "/user/web-admin/#web-admin-user-interface", 
            "text": "The web based administration interface allows to change the configuration of all modules in OpenSensorHub. It can be secured or even completely disabled in the configuration file manually. If enabled, it is accessible on the local node at the following URL:  http://localhost:8181/sensorhub/admin  Below is a screenshot of the user interface showing configuration settings for the simulated GPS sensor (used for testing).", 
            "title": "Web-Admin User Interface"
        }, 
        {
            "location": "/user/web-admin/#adding-modules", 
            "text": "Most installed modules for which code has been installed can be instantiated using the interface. This is done by simply right clicking in one of the appropriate section (i.e. one of the panels in the accordion on the left), and selecting \"Add Module\". For example, let's add a new sensor driver module:   You will then be presented with a choice of installed modules that can be instantiated on the current node. The list will only show the modules whose type can be added in the current section. In our example, we see all sensor drivers currently available on our node since we clicked in the \"Sensors\" section.   Once the module is added, it's configuration form is automatically shown on the right and you can start changing its parameters.", 
            "title": "Adding Modules"
        }, 
        {
            "location": "/user/web-admin/#configuring-modules", 
            "text": "To configure a module, simply select it on the left panel (after opening one of the main sections), and make the desired changes in the form that is displayed on the right. Once you're done, apply your changes, click the \"Apply Changes\" button. This makes the changes in the actual module configuration and, if the module handles configuration updates properly, the new configuration should be immediately reflected by the running module.", 
            "title": "Configuring Modules"
        }, 
        {
            "location": "/user/web-admin/#starting-and-stopping-modules", 
            "text": "Modules are started and stopped by right clicking on the module in the left panel and selecting \"Enable\" or \"Disable\" respectively.", 
            "title": "Starting and Stopping Modules"
        }, 
        {
            "location": "/user/web-admin/#securing-access", 
            "text": "TODO", 
            "title": "Securing Access"
        }, 
        {
            "location": "/user/sos/intro/", 
            "text": "Sensor Observation Service (SOS)\n\n\nThe \nSensor Observation Service (SOS)\n is an OGC standard allowing to retrieve sensor observations as well as associated metadata, such as the full sensor description in \nSensorML\n format.\n\n\nThis service is a core component of OpenSensorHub and can be configured to expose any live data stream (i.e. output of sensor or process) as well as content of any data storage available within an OSH node. It can be instantiated several times on a single node, and the user can choose which sensor data is exposed via each of these instances.\n\n\nThe main operations for data retrieval are:\n\n\n\n\nGetCapabilities\n: to retrieve general server capabilities and the list of data offerings\n\n\nGetObservation\n: to retrieve full Observation objects in XML format\n\n\nGetResult\n: to retrieve a compact data stream\n\n\nGetResultTemplate\n: to get the description of the compact data stream\n\n\nDescribeSensor\n: to get the sensor description\n\n\nGetFeatureOfInterest\n: to get the list of features observed by a given sensor\n\n\n\n\nThe \nSOS Interface\n can also be used in a transactional mode to send new observations to an OSH node. The following operations are used for insertion:\n\n\n\n\nInsertSensor\n: to insert sensor metadata and create the corresponding offering\n\n\nInsertObservation\n: to insert complete observation objects with all the related metadata\n\n\nInsertResult\n: to insert compact measurement records (previously described with InsertResultTemplate)\n\n\nInsertResultTemplate\n: to insert the description of compact measurement records\n\n\n\n\nPlease see the \nOGC\u00ae Sensor Observation Service Interface Standard v2.0\n for more details.\n\n\nSetting up with the Web Admin\n\n\nAdding one or more SOS endpoints is very easy through the \nWeb Admin\n. \n\n\nRight click in the \nServices\n section and select \nSOS Service\n in the popup window\n\n\n\n\nProceed to configuring SOS options\n\n\nYou must set the end point, and can add offerings at the bottom\n\n\n\n\nFor each offering, one can publish data for a sensor with or without its associated storage by using a \nSensor Data Source\n. If a storage is attached, both live and historical data from that sensor are made available through the SOS interface; if not, only live data is made available.\n\n\nIt is also possible to create an offering that serves historical data only. In this case, a \nStorage Data Source\n must be used. \n\n\nSetting up in config file\n\n\nAn SOS module can also be added by adding the proper JSON configuration in the main config file.\n\n\nBelow is an example JSON configuration of the SOS module with two offerings serving both real-time and historical data from two different sensors and their associated data storage:\n\n\n{\n    \nobjClass\n: \norg.sensorhub.impl.service.sos.SOSServiceConfig\n,\n    \nid\n: \n5cb05c9c-9e08-4fa1-8731-ff41e246bdc1\n,\n    \nname\n: \nSOS Service\n,\n    \nmoduleClass\n: \norg.sensorhub.impl.service.sos.SOSService\n,\n    \nenabled\n: true,\n    \nendPoint\n: \n/sos\n,\n    \nenableHttpGET\n: true,\n    \nenableHttpPOST\n: true,\n    \nenableSOAP\n: true,\n    \ndataProviders\n : [\n       {\n           \nobjClass\n: \norg.sensorhub.impl.service.sos.SensorDataProviderConfig\n,\n           \nenabled\n: true,\n           \nname\n: \nSimulated GPS\n,\n           \ndescription\n: \nSimulated GPS sensor\n,\n           \nuri\n: \nurn:mysos:offering02\n,\n           \nsensorID\n: \nd136b6ea-3950-4691-bf56-c84ec7d89d72\n,\n           \nstorageID\n: \n5cb05c9c-9e08-4fa1-8731-ff4ff948bdc1\n\n       },\n       {\n           \nobjClass\n: \norg.sensorhub.impl.service.sos.SensorDataProviderConfig\n,\n           \nenabled\n: true,\n           \nname\n: \nSimulated Weather\n,\n           \ndescription\n: \nSimulated Weather sensor\n,\n           \nuri\n: \nurn:mysos:offering03\n,\n           \nsensorID\n: \nd136b6ea-3950-4691-bf56-c84ec7d89d73\n,           \n           \nstorageID\n: \n5cb05c9c-9e08-4fa1-8731-ff4ff948bdc2\n\n       }\n    ],\n    \nogcCapabilitiesInfo\n: {\n      \ntitle\n: \nTest SOS Service\n,\n      \ndescription\n: \nAn SOS service automatically deployed by SensorHub\n,\n      \nkeywords\n: [\nSensorHub\n, \nVideo\n],\n      \nfees\n: \nNONE\n,\n      \naccessConstraints\n: \nNONE\n,\n      \nserviceProvider\n: {\n        \nindividualName\n: \nAlex Robin\n,\n        \norganizationName\n: \nSensia Software LLC\n,\n        \npositionName\n: \nEngineer\n,\n        \nvoiceNumbers\n: [\n+33 5 23 56 89 78\n],\n        \nfaxNumbers\n: [\n+33 5 23 56 89 77\n],\n        \ndeliveryPoints\n: [\n12 rue Voltaire\n],\n        \ncity\n: \nToulouse\n,\n        \nadministrativeArea\n: null,\n        \npostalCode\n: \n30000\n,\n        \ncountry\n: \nFrance\n,\n        \nemails\n: [\nadmin@mydomain.com\n],\n        \nwebsite\n: null,\n        \nhoursOfService\n: null,\n        \ncontactInstructions\n: null\n      }\n    }\n  }", 
            "title": "Introduction"
        }, 
        {
            "location": "/user/sos/intro/#sensor-observation-service-sos", 
            "text": "The  Sensor Observation Service (SOS)  is an OGC standard allowing to retrieve sensor observations as well as associated metadata, such as the full sensor description in  SensorML  format.  This service is a core component of OpenSensorHub and can be configured to expose any live data stream (i.e. output of sensor or process) as well as content of any data storage available within an OSH node. It can be instantiated several times on a single node, and the user can choose which sensor data is exposed via each of these instances.  The main operations for data retrieval are:   GetCapabilities : to retrieve general server capabilities and the list of data offerings  GetObservation : to retrieve full Observation objects in XML format  GetResult : to retrieve a compact data stream  GetResultTemplate : to get the description of the compact data stream  DescribeSensor : to get the sensor description  GetFeatureOfInterest : to get the list of features observed by a given sensor   The  SOS Interface  can also be used in a transactional mode to send new observations to an OSH node. The following operations are used for insertion:   InsertSensor : to insert sensor metadata and create the corresponding offering  InsertObservation : to insert complete observation objects with all the related metadata  InsertResult : to insert compact measurement records (previously described with InsertResultTemplate)  InsertResultTemplate : to insert the description of compact measurement records   Please see the  OGC\u00ae Sensor Observation Service Interface Standard v2.0  for more details.", 
            "title": "Sensor Observation Service (SOS)"
        }, 
        {
            "location": "/user/sos/intro/#setting-up-with-the-web-admin", 
            "text": "Adding one or more SOS endpoints is very easy through the  Web Admin .", 
            "title": "Setting up with the Web Admin"
        }, 
        {
            "location": "/user/sos/intro/#right-click-in-the-services-section-and-select-sos-service-in-the-popup-window", 
            "text": "", 
            "title": "Right click in the Services section and select SOS Service in the popup window"
        }, 
        {
            "location": "/user/sos/intro/#proceed-to-configuring-sos-options", 
            "text": "You must set the end point, and can add offerings at the bottom   For each offering, one can publish data for a sensor with or without its associated storage by using a  Sensor Data Source . If a storage is attached, both live and historical data from that sensor are made available through the SOS interface; if not, only live data is made available.  It is also possible to create an offering that serves historical data only. In this case, a  Storage Data Source  must be used.", 
            "title": "Proceed to configuring SOS options"
        }, 
        {
            "location": "/user/sos/intro/#setting-up-in-config-file", 
            "text": "An SOS module can also be added by adding the proper JSON configuration in the main config file.  Below is an example JSON configuration of the SOS module with two offerings serving both real-time and historical data from two different sensors and their associated data storage:  {\n     objClass :  org.sensorhub.impl.service.sos.SOSServiceConfig ,\n     id :  5cb05c9c-9e08-4fa1-8731-ff41e246bdc1 ,\n     name :  SOS Service ,\n     moduleClass :  org.sensorhub.impl.service.sos.SOSService ,\n     enabled : true,\n     endPoint :  /sos ,\n     enableHttpGET : true,\n     enableHttpPOST : true,\n     enableSOAP : true,\n     dataProviders  : [\n       {\n            objClass :  org.sensorhub.impl.service.sos.SensorDataProviderConfig ,\n            enabled : true,\n            name :  Simulated GPS ,\n            description :  Simulated GPS sensor ,\n            uri :  urn:mysos:offering02 ,\n            sensorID :  d136b6ea-3950-4691-bf56-c84ec7d89d72 ,\n            storageID :  5cb05c9c-9e08-4fa1-8731-ff4ff948bdc1 \n       },\n       {\n            objClass :  org.sensorhub.impl.service.sos.SensorDataProviderConfig ,\n            enabled : true,\n            name :  Simulated Weather ,\n            description :  Simulated Weather sensor ,\n            uri :  urn:mysos:offering03 ,\n            sensorID :  d136b6ea-3950-4691-bf56-c84ec7d89d73 ,           \n            storageID :  5cb05c9c-9e08-4fa1-8731-ff4ff948bdc2 \n       }\n    ],\n     ogcCapabilitiesInfo : {\n       title :  Test SOS Service ,\n       description :  An SOS service automatically deployed by SensorHub ,\n       keywords : [ SensorHub ,  Video ],\n       fees :  NONE ,\n       accessConstraints :  NONE ,\n       serviceProvider : {\n         individualName :  Alex Robin ,\n         organizationName :  Sensia Software LLC ,\n         positionName :  Engineer ,\n         voiceNumbers : [ +33 5 23 56 89 78 ],\n         faxNumbers : [ +33 5 23 56 89 77 ],\n         deliveryPoints : [ 12 rue Voltaire ],\n         city :  Toulouse ,\n         administrativeArea : null,\n         postalCode :  30000 ,\n         country :  France ,\n         emails : [ admin@mydomain.com ],\n         website : null,\n         hoursOfService : null,\n         contactInstructions : null\n      }\n    }\n  }", 
            "title": "Setting up in config file"
        }, 
        {
            "location": "/user/sos/get-data/", 
            "text": "Retrieving Observation Data\n\n\nThe SOS specification is based on the \nO\nM Model\n which allows one to provide robust metadata associated with any kind of measurement. With OpenSensorHub's implementation, it is possible to retrieve measurements as full observation objects as well as compact result streams.\n\n\nAll examples given in this section use HTTP GET but remember that OpenSensorHub also supports POST and SOAP requests natively. Please see the \nSOS v2.0 Specification\n for more details.\n\n\nResult Streams\n\n\nFortunately, SOS v2.0 provides a way to request only observation results in an efficient ASCII or binary encoding instead of verbose XML. This is clearly our preferred way to use SOS (especially with high rate sensors) and can be achieved by using the \nGetResult\n request as shown in the following example:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nrequest\n\n\nGetResult\n\n\n\n\n\n\noffering\n\n\nurn:mysos:offering03\n\n\n\n\n\n\nobservedProperty\n\n\nhttp://sensorml.com/ont/swe/property/Weather\n\n\n\n\n\n\n\n\nOn Demo Server:\n\n\nhttp://sensiasoft.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetResult\noffering=urn:mysos:offering03\nobservedProperty=http://sensorml.com/ont/swe/property/Weather\ntemporalFilter=phenomenonTime,2016-08-11T19:58:00Z/2016-08-11T19:59:00Z\n\n\nAs you can see, the response only includes the measurement values themselves and no metadata. The actual choice of encoding depends on the server settings, which usually depends on the type of dataset: for instance a video stream will always be served as compressed binary, while low rate weather of GPS data is usually provided as ASCII tuples.\n\n\nThe description of tuples and their encoding can be retrieved using the \nGetResultTemplate\n request shown below:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nrequest\n\n\nGetResultTemplate\n\n\n\n\n\n\noffering\n\n\nurn:mysos:offering03\n\n\n\n\n\n\nobservedProperty\n\n\nhttp://sensorml.com/ont/swe/property/Weather\n\n\n\n\n\n\ntemporalFilter\n\n\nphenomenonTime,2016-08-11T19:58:00Z/2016-08-11T19:59:00Z\n\n\n\n\n\n\n\n\nOn Demo Server:\n\n\nhttp://sensiasoft.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetResultTemplate\noffering=urn:mysos:offering03\nobservedProperty=http://sensorml.com/ont/swe/property/Weather\n\n\nThe response contains detailed information about each field for which a value is given in the response to the \nGetResult\n call. This can be used to automatically configure a client for parsing the data, for automatically generating parser code or even for manually coding a parser.\n\n\nNote: For faster response times, OSH generates the response in a streaming fashion so that the client doesn't have to wait until all observations are fetched from database before it can start parsing. This behavior is also needed for streaming real-time data (See the \nTemporal Filtering\n page to learn how to request a real-time stream).\n\n\nObservations\n\n\nThe traditional way of requesting data from SOS is through the \nGetObservation\n request which provides the full XML encoded view of each observation. Although it can be useful in some contexts, it is not appropriate nor recommended for requesting large numbers observations because the amount of data returned is quite large and redundant. The following table shows example parameters for such request with only a temporal filter:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nrequest\n\n\nGetObservation\n\n\n\n\n\n\noffering\n\n\nurn:mysos:offering03\n\n\n\n\n\n\nobservedProperty\n\n\nhttp://sensorml.com/ont/swe/property/Weather\n\n\n\n\n\n\ntemporalFilter\n\n\nphenomenonTime,2016-08-11T19:58:00Z/2016-08-11T19:59:00Z\n\n\n\n\n\n\n\n\nOn Demo Server:\n\n\nhttp://sensiasoft.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetObservation\noffering=urn:mysos:offering03\nobservedProperty=http://sensorml.com/ont/swe/property/Weather\ntemporalFilter=phenomenonTime,2016-08-11T19:58:00Z/2016-08-11T19:59:00Z\n\n\nNote: For faster response times and to limit server memory usage, OSH generates the XML in a streaming fashion so that the client doesn't have to wait until all observations are fetched from database before it can start parsing. Despite this efficient implementation, OSH imposes a limit on the number of observations that can be returned with this method", 
            "title": "Retrieving Data"
        }, 
        {
            "location": "/user/sos/get-data/#retrieving-observation-data", 
            "text": "The SOS specification is based on the  O M Model  which allows one to provide robust metadata associated with any kind of measurement. With OpenSensorHub's implementation, it is possible to retrieve measurements as full observation objects as well as compact result streams.  All examples given in this section use HTTP GET but remember that OpenSensorHub also supports POST and SOAP requests natively. Please see the  SOS v2.0 Specification  for more details.", 
            "title": "Retrieving Observation Data"
        }, 
        {
            "location": "/user/sos/get-data/#result-streams", 
            "text": "Fortunately, SOS v2.0 provides a way to request only observation results in an efficient ASCII or binary encoding instead of verbose XML. This is clearly our preferred way to use SOS (especially with high rate sensors) and can be achieved by using the  GetResult  request as shown in the following example:     Parameter  Value      request  GetResult    offering  urn:mysos:offering03    observedProperty  http://sensorml.com/ont/swe/property/Weather     On Demo Server:  http://sensiasoft.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetResult offering=urn:mysos:offering03 observedProperty=http://sensorml.com/ont/swe/property/Weather temporalFilter=phenomenonTime,2016-08-11T19:58:00Z/2016-08-11T19:59:00Z  As you can see, the response only includes the measurement values themselves and no metadata. The actual choice of encoding depends on the server settings, which usually depends on the type of dataset: for instance a video stream will always be served as compressed binary, while low rate weather of GPS data is usually provided as ASCII tuples.  The description of tuples and their encoding can be retrieved using the  GetResultTemplate  request shown below:     Parameter  Value      request  GetResultTemplate    offering  urn:mysos:offering03    observedProperty  http://sensorml.com/ont/swe/property/Weather    temporalFilter  phenomenonTime,2016-08-11T19:58:00Z/2016-08-11T19:59:00Z     On Demo Server:  http://sensiasoft.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetResultTemplate offering=urn:mysos:offering03 observedProperty=http://sensorml.com/ont/swe/property/Weather  The response contains detailed information about each field for which a value is given in the response to the  GetResult  call. This can be used to automatically configure a client for parsing the data, for automatically generating parser code or even for manually coding a parser.  Note: For faster response times, OSH generates the response in a streaming fashion so that the client doesn't have to wait until all observations are fetched from database before it can start parsing. This behavior is also needed for streaming real-time data (See the  Temporal Filtering  page to learn how to request a real-time stream).", 
            "title": "Result Streams"
        }, 
        {
            "location": "/user/sos/get-data/#observations", 
            "text": "The traditional way of requesting data from SOS is through the  GetObservation  request which provides the full XML encoded view of each observation. Although it can be useful in some contexts, it is not appropriate nor recommended for requesting large numbers observations because the amount of data returned is quite large and redundant. The following table shows example parameters for such request with only a temporal filter:     Parameter  Value      request  GetObservation    offering  urn:mysos:offering03    observedProperty  http://sensorml.com/ont/swe/property/Weather    temporalFilter  phenomenonTime,2016-08-11T19:58:00Z/2016-08-11T19:59:00Z     On Demo Server:  http://sensiasoft.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetObservation offering=urn:mysos:offering03 observedProperty=http://sensorml.com/ont/swe/property/Weather temporalFilter=phenomenonTime,2016-08-11T19:58:00Z/2016-08-11T19:59:00Z  Note: For faster response times and to limit server memory usage, OSH generates the XML in a streaming fashion so that the client doesn't have to wait until all observations are fetched from database before it can start parsing. Despite this efficient implementation, OSH imposes a limit on the number of observations that can be returned with this method", 
            "title": "Observations"
        }, 
        {
            "location": "/user/sos/time-filter/", 
            "text": "Temporal Filtering\n\n\nOpenSensorHub's SOS implementation supports both \nhistorical\n and \nreal-time\n requests for sensor data.\n\n\nHistorical requests are automatically enabled (and properly advertised in the capabilities) when a storage is configured and associated to a sensor. Likewise, real-time requests are automatically enabled when a sensor is directly connected to the SOS (and the sensor module is itself enabled and reports the sensor as connected).\n\n\nRegarding temporal filtering, SensorHub's implementation only supports the \nTEquals\n operator for time instants and \nDuring\n operator for time periods and, currently, filtering can only be done on the 'phenomenonTime' property. The special value 'now' represents the limit between historical and real-time data.\n\n\nThe following tables explain how the server responds to different temporal filter settings:\n\n\nTime Instants\n\n\n\n\n\n\n\n\nBehavior\n\n\nRequest\n\n\n\n\n\n\n\n\n\n\nGet observation at exact time\n\n\ntemporalFilter=phenomenonTime,2014-04-01T00:00:00Z\n\n\n\n\n\n\nGet latest observation\n\n\ntemporalFilter=phenomenonTime,now\n\n\n\n\n\n\n\n\nTime Periods\n\n\nIn all the examples below, 'now' is considered to be at 2014-02-20 and we assume storage contains data until this date.\n\n\n\n\n\n\n\n\nBehavior\n\n\nRequest\n\n\n\n\n\n\n\n\n\n\nGet observations for a historical time range\n\n\ntemporalFilter=phenomenonTime,2014-01-01/2014-02-01\n\n\n\n\n\n\nGet historical data up to the latest observation\n\n\ntemporalFilter=phenomenonTime,2014-01-01/now\n\n\n\n\n\n\nGet real-time stream ending at specific time (1,2)\n\n\ntemporalFilter=phenomenonTime,now/2014-03-01\n\n\n\n\n\n\nGet observations for a time range overlapping past and future (1,3) (\nnot supported for now\n)\n\n\ntemporalFilter=phenomenonTime,2014-01-01/2014-03-01\n\n\n\n\n\n\n\n\n(1) A real-time stream is only available through a persistent connection if sampling period is lower than a certain threshold (usually a few seconds). For lower rate data producers, the \nWebSocket\n protocol can be used instead.\n\n\n(2) The stream will be closed as soon as an observation more recent than the end date is produced. A date very far in the future can be used to get a virtually never ending data stream.\n\n\n(3) If real-time streaming is available, the stream will be closed as in (2). Otherwise it will be closed right after the latest available observation has been sent, even if it is much earlier than the end date (i.e. the request will be treated as \ntemporalFilter=phenomenonTime,2014-01-01/now\n).\n\n\nNote: Dates used are in the ISO8601 format and can include the time part or not (e.g. both 2014-01-01Z and 2013-05-06T12:05:00.111Z are valid). When no time is specified, midnight (00:00:00) is assumed.\n\n\nReplay Extension\n\n\nThe SOS implementation also supports replaying historical observations at arbitrary speed (i.e. at real-time speed, or slower/faster than real-time). This is supported by adding the \nreplaySpeed\n parameter to a historical GetResult KVP request, such as in \ntemporalFilter=phenomenonTime,2014-01-01/2014-02-01\nreplaySpeed=2\n. The parameter has no effect for a live stream request (i.e. if the requested period starts at 'now')\n\n\nObservations are replayed at exactly real-time speed (according to observations time tags) with \nreplaySpeed=1\n. The replay value is in fact a factor relative to real-time so that 10 means replaying 10x faster than real-time (if bandwidth permits!) and 0.1 means replaying 10x slower than real-time.\n\n\nSensorHub implements this functionality by pausing the SOS data provider thread just the right amount of time to match the period infered by two successive measurement time stamps.", 
            "title": "Temporal Filtering"
        }, 
        {
            "location": "/user/sos/time-filter/#temporal-filtering", 
            "text": "OpenSensorHub's SOS implementation supports both  historical  and  real-time  requests for sensor data.  Historical requests are automatically enabled (and properly advertised in the capabilities) when a storage is configured and associated to a sensor. Likewise, real-time requests are automatically enabled when a sensor is directly connected to the SOS (and the sensor module is itself enabled and reports the sensor as connected).  Regarding temporal filtering, SensorHub's implementation only supports the  TEquals  operator for time instants and  During  operator for time periods and, currently, filtering can only be done on the 'phenomenonTime' property. The special value 'now' represents the limit between historical and real-time data.  The following tables explain how the server responds to different temporal filter settings:", 
            "title": "Temporal Filtering"
        }, 
        {
            "location": "/user/sos/time-filter/#time-instants", 
            "text": "Behavior  Request      Get observation at exact time  temporalFilter=phenomenonTime,2014-04-01T00:00:00Z    Get latest observation  temporalFilter=phenomenonTime,now", 
            "title": "Time Instants"
        }, 
        {
            "location": "/user/sos/time-filter/#time-periods", 
            "text": "In all the examples below, 'now' is considered to be at 2014-02-20 and we assume storage contains data until this date.     Behavior  Request      Get observations for a historical time range  temporalFilter=phenomenonTime,2014-01-01/2014-02-01    Get historical data up to the latest observation  temporalFilter=phenomenonTime,2014-01-01/now    Get real-time stream ending at specific time (1,2)  temporalFilter=phenomenonTime,now/2014-03-01    Get observations for a time range overlapping past and future (1,3) ( not supported for now )  temporalFilter=phenomenonTime,2014-01-01/2014-03-01     (1) A real-time stream is only available through a persistent connection if sampling period is lower than a certain threshold (usually a few seconds). For lower rate data producers, the  WebSocket  protocol can be used instead.  (2) The stream will be closed as soon as an observation more recent than the end date is produced. A date very far in the future can be used to get a virtually never ending data stream.  (3) If real-time streaming is available, the stream will be closed as in (2). Otherwise it will be closed right after the latest available observation has been sent, even if it is much earlier than the end date (i.e. the request will be treated as  temporalFilter=phenomenonTime,2014-01-01/now ).  Note: Dates used are in the ISO8601 format and can include the time part or not (e.g. both 2014-01-01Z and 2013-05-06T12:05:00.111Z are valid). When no time is specified, midnight (00:00:00) is assumed.", 
            "title": "Time Periods"
        }, 
        {
            "location": "/user/sos/time-filter/#replay-extension", 
            "text": "The SOS implementation also supports replaying historical observations at arbitrary speed (i.e. at real-time speed, or slower/faster than real-time). This is supported by adding the  replaySpeed  parameter to a historical GetResult KVP request, such as in  temporalFilter=phenomenonTime,2014-01-01/2014-02-01 replaySpeed=2 . The parameter has no effect for a live stream request (i.e. if the requested period starts at 'now')  Observations are replayed at exactly real-time speed (according to observations time tags) with  replaySpeed=1 . The replay value is in fact a factor relative to real-time so that 10 means replaying 10x faster than real-time (if bandwidth permits!) and 0.1 means replaying 10x slower than real-time.  SensorHub implements this functionality by pausing the SOS data provider thread just the right amount of time to match the period infered by two successive measurement time stamps.", 
            "title": "Replay Extension"
        }, 
        {
            "location": "/user/sos/spatial-filter/", 
            "text": "Spatial Filtering\n\n\nOpenSensorHub's SOS implementation supports simple spatial filtering of observations using either a BBOX or Polygon. As per the SOS v2.0 Only BBOX\n\n\nFiltering by BBOX\n\n\nThe table below lists parameter of a \nGetResult\n request used to retrieve data only from the weather stations located within the given region:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nrequest\n\n\nGetResult\n\n\n\n\n\n\noffering\n\n\nurn:mysos:metar01\n\n\n\n\n\n\nobservedProperty\n\n\nhttp://sensorml.com/ont/swe/property/Temperature\n\n\n\n\n\n\nspatialFilter\n\n\nfeatureOfInterest/*/shape,22.32,11.2,32.32,22.2,urn:ogc:def:crs:EPSG::4326\n\n\n\n\n\n\ntemporalFilter\n\n\nphenomenonTime,2014-03-29T06:16:12Z/2014-03-29T14:26:12Z\n\n\n\n\n\n\n\n\nOn Demo Server\n:\n\n\nhttp://sensiasoft.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetResult\noffering=urn:mysos:metar01\nobservedProperty=http://sensorml.com/ont/swe/property/Temperature\nspatialFilter=featureOfInterest/*/shape,22.32,11.2,32.32,22.2,urn:ogc:def:crs:EPSG::4326\ntemporalFilter=phenomenonTime,2014-03-29T06:16:12Z/2014-03-29T14:26:12Z\n\n\nFiltering by Polygon\n\n\nTODO\n Show example POST request", 
            "title": "Spatial Filtering"
        }, 
        {
            "location": "/user/sos/spatial-filter/#spatial-filtering", 
            "text": "OpenSensorHub's SOS implementation supports simple spatial filtering of observations using either a BBOX or Polygon. As per the SOS v2.0 Only BBOX", 
            "title": "Spatial Filtering"
        }, 
        {
            "location": "/user/sos/spatial-filter/#filtering-by-bbox", 
            "text": "The table below lists parameter of a  GetResult  request used to retrieve data only from the weather stations located within the given region:     Parameter  Value      request  GetResult    offering  urn:mysos:metar01    observedProperty  http://sensorml.com/ont/swe/property/Temperature    spatialFilter  featureOfInterest/*/shape,22.32,11.2,32.32,22.2,urn:ogc:def:crs:EPSG::4326    temporalFilter  phenomenonTime,2014-03-29T06:16:12Z/2014-03-29T14:26:12Z     On Demo Server :  http://sensiasoft.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetResult offering=urn:mysos:metar01 observedProperty=http://sensorml.com/ont/swe/property/Temperature spatialFilter=featureOfInterest/*/shape,22.32,11.2,32.32,22.2,urn:ogc:def:crs:EPSG::4326 temporalFilter=phenomenonTime,2014-03-29T06:16:12Z/2014-03-29T14:26:12Z", 
            "title": "Filtering by BBOX"
        }, 
        {
            "location": "/user/sos/spatial-filter/#filtering-by-polygon", 
            "text": "TODO  Show example POST request", 
            "title": "Filtering by Polygon"
        }, 
        {
            "location": "/user/sos/foi-filter/", 
            "text": "Filtering by Feature of Interest\n\n\nA Feature of Interest (FOI) is the feature that a sensor is observing at a given instant. It can refer to an actual object, or something more abstract like an area, a given acquisition run, etc.\n\n\nOpenSensorHub's SOS implementation supports filtering observations by specifying the ID of a feature of interest. This is what is used to obtain observations from a single node in a large sensor network for instance, or to retrieve observations of a particular object by a mobile sensor.\n\n\nBelow are example \nHTTP GET\n requests for filtering by \nFOI\n identifier.\n\n\nGetResult Example\n\n\nThe table below lists parameter of a \nGetResult\n request used to retrieve location data from a given time period only for emergency vehicle with ID \nFE4\n:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nrequest\n\n\nGetResult\n\n\n\n\n\n\noffering\n\n\nurn:mysos:avl\n\n\n\n\n\n\nobservedProperty\n\n\nhttp://www.opengis.net/def/property/OGC/0/SensorLocation\n\n\n\n\n\n\nfeatureOfInterest\n\n\nurn:osh:sensor:avl:911:fleet:FE4\n\n\n\n\n\n\ntemporalFilter\n\n\nphenomenonTime,2014-03-29T06:16:12Z/2014-03-29T14:26:12Z\n\n\n\n\n\n\n\n\nOn Demo Server\n:\n\n\nhttp://sensiasoft.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetResult\noffering=urn:mysos:avl\nobservedProperty=http://www.opengis.net/def/property/OGC/0/SensorLocation\nfeatureOfInterest=urn:osh:sensor:avl:911:fleet:FE4\ntemporalFilter=phenomenonTime,2014-03-29T06:16:12Z/2014-03-29T14:26:12Z\n\n\nGetObservation Example\n\n\nThe table below lists parameter of a \nGetObservation\n request used to retrieve location data from a given time period only for the same emergency vehicle with ID \nFE4\n:\n\n\n\n\n\n\n\n\nParameter\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nrequest\n\n\nGetObservation\n\n\n\n\n\n\noffering\n\n\nurn:mysos:avl\n\n\n\n\n\n\nobservedProperty\n\n\nhttp://www.opengis.net/def/property/OGC/0/SensorLocation\n\n\n\n\n\n\nfeatureOfInterest\n\n\nurn:osh:sensor:avl:911:fleet:FE4\n\n\n\n\n\n\ntemporalFilter\n\n\nphenomenonTime,2014-03-29T06:16:12Z/2014-03-29T06:26:12Z\n\n\n\n\n\n\n\n\nOn Demo Server\n:\n\n\nhttp://sensiasoft.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetObservation\noffering=urn:mysos:avl\nobservedProperty=http://www.opengis.net/def/property/OGC/0/SensorLocation\nfeatureOfInterest=urn:osh:sensor:avl:911:fleet:FE4\ntemporalFilter=phenomenonTime,2014-03-29T06:16:12Z/2014-03-29T06:26:12Z\n\n\nNotice that in this case we requested much less data because the response is much more verbose.\n\n\nGetFeatureOfInterest Example\n\n\nIn order to know which ID to use, one needs to know the list of all \nFOIs\n observed by a particular sensor. This can be done by issuing a \nGetFeatureOfInterest\n request such as below:\n\n\nhttp://sensiasoft.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetFeatureOfInterest\nprocedure=urn:osh:sensor:avl:911:fleet", 
            "title": "Filtering by Feature"
        }, 
        {
            "location": "/user/sos/foi-filter/#filtering-by-feature-of-interest", 
            "text": "A Feature of Interest (FOI) is the feature that a sensor is observing at a given instant. It can refer to an actual object, or something more abstract like an area, a given acquisition run, etc.  OpenSensorHub's SOS implementation supports filtering observations by specifying the ID of a feature of interest. This is what is used to obtain observations from a single node in a large sensor network for instance, or to retrieve observations of a particular object by a mobile sensor.  Below are example  HTTP GET  requests for filtering by  FOI  identifier.", 
            "title": "Filtering by Feature of Interest"
        }, 
        {
            "location": "/user/sos/foi-filter/#getresult-example", 
            "text": "The table below lists parameter of a  GetResult  request used to retrieve location data from a given time period only for emergency vehicle with ID  FE4 :     Parameter  Value      request  GetResult    offering  urn:mysos:avl    observedProperty  http://www.opengis.net/def/property/OGC/0/SensorLocation    featureOfInterest  urn:osh:sensor:avl:911:fleet:FE4    temporalFilter  phenomenonTime,2014-03-29T06:16:12Z/2014-03-29T14:26:12Z     On Demo Server :  http://sensiasoft.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetResult offering=urn:mysos:avl observedProperty=http://www.opengis.net/def/property/OGC/0/SensorLocation featureOfInterest=urn:osh:sensor:avl:911:fleet:FE4 temporalFilter=phenomenonTime,2014-03-29T06:16:12Z/2014-03-29T14:26:12Z", 
            "title": "GetResult Example"
        }, 
        {
            "location": "/user/sos/foi-filter/#getobservation-example", 
            "text": "The table below lists parameter of a  GetObservation  request used to retrieve location data from a given time period only for the same emergency vehicle with ID  FE4 :     Parameter  Value      request  GetObservation    offering  urn:mysos:avl    observedProperty  http://www.opengis.net/def/property/OGC/0/SensorLocation    featureOfInterest  urn:osh:sensor:avl:911:fleet:FE4    temporalFilter  phenomenonTime,2014-03-29T06:16:12Z/2014-03-29T06:26:12Z     On Demo Server :  http://sensiasoft.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetObservation offering=urn:mysos:avl observedProperty=http://www.opengis.net/def/property/OGC/0/SensorLocation featureOfInterest=urn:osh:sensor:avl:911:fleet:FE4 temporalFilter=phenomenonTime,2014-03-29T06:16:12Z/2014-03-29T06:26:12Z  Notice that in this case we requested much less data because the response is much more verbose.", 
            "title": "GetObservation Example"
        }, 
        {
            "location": "/user/sos/foi-filter/#getfeatureofinterest-example", 
            "text": "In order to know which ID to use, one needs to know the list of all  FOIs  observed by a particular sensor. This can be done by issuing a  GetFeatureOfInterest  request such as below:  http://sensiasoft.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetFeatureOfInterest procedure=urn:osh:sensor:avl:911:fleet", 
            "title": "GetFeatureOfInterest Example"
        }, 
        {
            "location": "/user/sos/websocket/", 
            "text": "WebSocket Extension\n\n\nAlthough it is possible to request a real-time data stream from OpenSensorHub's SOS using the \"persistent HTTP\" approach, this technique is hard to use within web browsers because the asynchronous \nXMLHttpRequest\n API is not designed for it and won't allow you to manage memory correctly (typically an ever growing buffer will be allocated to contain the endless stream of data).\n\n\nTo circumvent this issue, OpenSensorHub introduced the \nWebSocket\n extension to SOS very early-on. It is super easy to use since \nWebSocket\n requests are identical to \nHTTP GET\n requests (only the protocol part of the URL changes).\n\n\nNote that the \nWebSocket\n protocol is only available for \nGetResult\n requests for now but we have plans to implement support for \nInsertResult\n as well.\n\n\nPrinciple\n\n\nThe \nWebSocket\n is constructed in the same way an \nHTTP GET\n URL would be except the \nws://\n protocol is used instead of \nhttp://\n, as in the following example:\n\n\nws://sensiasoft.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetResult\noffering=urn:mysos:offering02\nobservedProperty=http://www.opengis.net/def/property/OGC/0/SensorLocation\ntemporalFilter=phenomenonTime,now/2055-01-01\n\n\n\n\nOnce you connect with this URL, the SOS server will send one \nWebSocket\n message for each record of measurement (i.e. corresponding to the record described in \nGetResultTemplate\n). With most \nWebSocket\n APIs, you will typically receive these messages via a callback function so that data can be processed in an event-based fashion.\n\n\nJavaScript Example\n\n\nThe following JavaScript example shows how to issue a real-time \nGetResult\n request using \nWebSocket\n:\n\n\nws = new WebSocket(\nws://sensiasoft.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetResult\noffering=urn:mysos:offering02\nobservedProperty=http://www.opengis.net/def/property/OGC/0/SensorLocation\ntemporalFilter=phenomenonTime,now/2055-01-01\n);\nws.binaryType = 'arraybuffer';\nws.onmessage = function (event) {\n\n  var rec = String.fromCharCode.apply(null, new Uint8Array(event.data));\n  //console.log(rec);\n\n  var tokens = rec.trim().split(\n,\n);\n  var lat = parseFloat(tokens[1]);\n  var lon = parseFloat(tokens[2]);\n  var alt = parseFloat(tokens[3]);\n\n  // do what you need with the data, like draw marker on a map\n}\nws.onerror = function (event) {\n  // error handling code\n  ws.close();\n}", 
            "title": "WebSocket Support"
        }, 
        {
            "location": "/user/sos/websocket/#websocket-extension", 
            "text": "Although it is possible to request a real-time data stream from OpenSensorHub's SOS using the \"persistent HTTP\" approach, this technique is hard to use within web browsers because the asynchronous  XMLHttpRequest  API is not designed for it and won't allow you to manage memory correctly (typically an ever growing buffer will be allocated to contain the endless stream of data).  To circumvent this issue, OpenSensorHub introduced the  WebSocket  extension to SOS very early-on. It is super easy to use since  WebSocket  requests are identical to  HTTP GET  requests (only the protocol part of the URL changes).  Note that the  WebSocket  protocol is only available for  GetResult  requests for now but we have plans to implement support for  InsertResult  as well.", 
            "title": "WebSocket Extension"
        }, 
        {
            "location": "/user/sos/websocket/#principle", 
            "text": "The  WebSocket  is constructed in the same way an  HTTP GET  URL would be except the  ws://  protocol is used instead of  http:// , as in the following example:  ws://sensiasoft.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetResult offering=urn:mysos:offering02 observedProperty=http://www.opengis.net/def/property/OGC/0/SensorLocation temporalFilter=phenomenonTime,now/2055-01-01  Once you connect with this URL, the SOS server will send one  WebSocket  message for each record of measurement (i.e. corresponding to the record described in  GetResultTemplate ). With most  WebSocket  APIs, you will typically receive these messages via a callback function so that data can be processed in an event-based fashion.", 
            "title": "Principle"
        }, 
        {
            "location": "/user/sos/websocket/#javascript-example", 
            "text": "The following JavaScript example shows how to issue a real-time  GetResult  request using  WebSocket :  ws = new WebSocket( ws://sensiasoft.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetResult offering=urn:mysos:offering02 observedProperty=http://www.opengis.net/def/property/OGC/0/SensorLocation temporalFilter=phenomenonTime,now/2055-01-01 );\nws.binaryType = 'arraybuffer';\nws.onmessage = function (event) {\n\n  var rec = String.fromCharCode.apply(null, new Uint8Array(event.data));\n  //console.log(rec);\n\n  var tokens = rec.trim().split( , );\n  var lat = parseFloat(tokens[1]);\n  var lon = parseFloat(tokens[2]);\n  var alt = parseFloat(tokens[3]);\n\n  // do what you need with the data, like draw marker on a map\n}\nws.onerror = function (event) {\n  // error handling code\n  ws.close();\n}", 
            "title": "JavaScript Example"
        }, 
        {
            "location": "/user/sos/interconnect/", 
            "text": "Interconnecting SensorHubs\n\n\nInstances of OpenSensorHub at various levels of your sensor network can be interconnected using the SOS protocol. This is often used to implement sub-networks, local measurement aggregators or gateways to pass from the private side to the public side of a network. It can also be used to send your data to an OSH instance in the cloud to do CPU intensive processing or broadcast to a large number of users. Possibilities are endless.\n\n\nThis transfer can be done in two ways; using either a push or pull approach.\n\n\nPull Approach\n\n\nWe call this approach \"pull\" but it is in fact implemented as a persistent connection between the two nodes, either through \nHTTP\n or \nWebSocket\n.\n\n\nTo pull data from \nNode A\n to \nNode B\n, you need:\n\n\n\n\nAn \nSOS Interface\n accessible on \nNode A\n\n\nAn instance of the \nSWE Virtual Sensor\n driver on \nNode B\n\n\n\n\nYou then have to properly configure the virtual sensor on \nNode B\n to connect to your SOS endpoint on \nNode A\n, and specify the ID of the sensor and observed properties that you want to be fetched.\n\n\nPush Approach\n\n\nIn this case, we make use of the transactional interface of the SOS server.\n\n\nTo push data from \nNode A\n to \nNode B\n, you need:\n\n\n\n\nAn \nSOS Interface\n accessible on \nNode B\n, with the option \"Enable Transactional\" set to true\n\n\nAn \nSOS-T Client\n on \nNode A\n\n\n\n\nYou then have to properly configure the SOS-T client on \nNode A\n to connect to the SOS endoint on \nNodeB\n.\n\n\nThe SOS-T client will listen to one of the sensor streams (i.e. output of sensor drivers) on \nNode A\n and forwards it to the remote SOS server using \nInsertResult\n.", 
            "title": "Interconnecting SensorHubs"
        }, 
        {
            "location": "/user/sos/interconnect/#interconnecting-sensorhubs", 
            "text": "Instances of OpenSensorHub at various levels of your sensor network can be interconnected using the SOS protocol. This is often used to implement sub-networks, local measurement aggregators or gateways to pass from the private side to the public side of a network. It can also be used to send your data to an OSH instance in the cloud to do CPU intensive processing or broadcast to a large number of users. Possibilities are endless.  This transfer can be done in two ways; using either a push or pull approach.", 
            "title": "Interconnecting SensorHubs"
        }, 
        {
            "location": "/user/sos/interconnect/#pull-approach", 
            "text": "We call this approach \"pull\" but it is in fact implemented as a persistent connection between the two nodes, either through  HTTP  or  WebSocket .  To pull data from  Node A  to  Node B , you need:   An  SOS Interface  accessible on  Node A  An instance of the  SWE Virtual Sensor  driver on  Node B   You then have to properly configure the virtual sensor on  Node B  to connect to your SOS endpoint on  Node A , and specify the ID of the sensor and observed properties that you want to be fetched.", 
            "title": "Pull Approach"
        }, 
        {
            "location": "/user/sos/interconnect/#push-approach", 
            "text": "In this case, we make use of the transactional interface of the SOS server.  To push data from  Node A  to  Node B , you need:   An  SOS Interface  accessible on  Node B , with the option \"Enable Transactional\" set to true  An  SOS-T Client  on  Node A   You then have to properly configure the SOS-T client on  Node A  to connect to the SOS endoint on  NodeB .  The SOS-T client will listen to one of the sensor streams (i.e. output of sensor drivers) on  Node A  and forwards it to the remote SOS server using  InsertResult .", 
            "title": "Push Approach"
        }, 
        {
            "location": "/user/sps/intro/", 
            "text": "Sensor Planning Service (SPS)\n\n\nTODO", 
            "title": "SPS Interface"
        }, 
        {
            "location": "/user/sps/intro/#sensor-planning-service-sps", 
            "text": "TODO", 
            "title": "Sensor Planning Service (SPS)"
        }, 
        {
            "location": "/user/android-app/", 
            "text": "OpenSensorHub on Android\n\n\nThe core modules of OpenSensorHub (OSH) can run natively on Android 5.0 (Lollipop) and later versions (We are working on a working version for Android 4.4 (KitKat).\n\n\nAndroid support is still experimental at this stage although it is already functional to send phone sensor data to a remote OSH node.\n\n\nThe Android specific part is composed of a Service component that wraps the OSH engine and an demo application that can be configured to send data from one or more phone sensors to the SOS server of a remote OSH node. \n\n\nAndroid Service\n\n\nAndroid distribution for OpenSensorHub will come as an Android service that any app can connect to and configure with the desired modules.\n\n\nAn app will then be able to connect directly to OpenSensorHub object model and access any part of it (e.g. sensors, processes, services, communication networks, etc.). Thus apps provide view and control over the OSH engine and can be highly customized to the user need.\n\n\nWe intend on making the service accessible by several apps concurrently.\n\n\nDemo Android App\n\n\nThe demo android app is an example of how to connect to the service, configure it and display information from it. This particular app allows uploading data collected by the phone to a remote SOS-T endpoint, and can be configured to enable/disable what sensors are used. Below are some screenshots of the app in action.\n\n\nYou first access the main menu (left) and configure your device name and the SOS endpoint (right):\n\n\n\n\n\n\n\n\n\n\nYou then select sensors you want to enable (left), and after you start SensorHub from the main menu, their data is streamed to the SOS (right):", 
            "title": "Demo Android App"
        }, 
        {
            "location": "/user/android-app/#opensensorhub-on-android", 
            "text": "The core modules of OpenSensorHub (OSH) can run natively on Android 5.0 (Lollipop) and later versions (We are working on a working version for Android 4.4 (KitKat).  Android support is still experimental at this stage although it is already functional to send phone sensor data to a remote OSH node.  The Android specific part is composed of a Service component that wraps the OSH engine and an demo application that can be configured to send data from one or more phone sensors to the SOS server of a remote OSH node.", 
            "title": "OpenSensorHub on Android"
        }, 
        {
            "location": "/user/android-app/#android-service", 
            "text": "Android distribution for OpenSensorHub will come as an Android service that any app can connect to and configure with the desired modules.  An app will then be able to connect directly to OpenSensorHub object model and access any part of it (e.g. sensors, processes, services, communication networks, etc.). Thus apps provide view and control over the OSH engine and can be highly customized to the user need.  We intend on making the service accessible by several apps concurrently.", 
            "title": "Android Service"
        }, 
        {
            "location": "/user/android-app/#demo-android-app", 
            "text": "The demo android app is an example of how to connect to the service, configure it and display information from it. This particular app allows uploading data collected by the phone to a remote SOS-T endpoint, and can be configured to enable/disable what sensors are used. Below are some screenshots of the app in action.  You first access the main menu (left) and configure your device name and the SOS endpoint (right):      You then select sensors you want to enable (left), and after you start SensorHub from the main menu, their data is streamed to the SOS (right):", 
            "title": "Demo Android App"
        }, 
        {
            "location": "/dev/dev-guide/", 
            "text": "Developer's Guide\n\n\nThis guide is meant to help you setup a development environment based on the Eclipse IDE so that you can extend OpenSensorHub (OSH for short) with your own sensor drivers, web services and other components.\n\n\nDon't forget to send us a Pull Request if you want to contribute your work back to this project. Other users may be interested by your modules and bug fixes! \n\n\nOf course, contributing new modules to the community is optional as our license does not prevent proprietary and commercial derived work. However, keep in mind that \nif you modify the source files we provide, you must make it available publicly in source form\n. \n\n\nThis page provides instructions for three possible options, depending on your level of involvement:\n\n\n\n\n\n\nExploring the code online\n\n\n\n\n\n\nDownloading and building from source using Gradle from command-line or Eclipse\n\n\n\n\n\n\nContributing software and fixes to the project\n\n\n\n\n\n\nExploring the Code\n\n\nIf you just want to explore the code, you can browse the source online directly on \nGithub\n. Alternatively, you can download it to your computer using the \nDownload ZIP\n link on each GitHub repository or using the \ngit\n program (please see the next section if you want to do just that).\n\n\nTo start with, the repositories of interest are OpenSensorHub \nCore\n and \nSensor Drivers\n.\n\n\nBuilding from Source\n\n\nBelow are the steps to download and build the code using either command line tools or the Eclipse IDE.\n\n\nUsing Command-Line Tools\n\n\nIf you want to build the code and run it on your computer, you'll need \ngit 2.7\n and \ngradle 3.1\n or later versions. Beware that a recent version of Gradle may not be provided with your Linux distribution but can be downloaded \nhere\n.\n\n\nBuild the core\n\n\nUse the following command to clone the \nosh-core\n repository:\n\n\n$ git clone --recursive https://github.com/opensensorhub/osh-core\n\n\n\n\nYou can then build the code with:\n\n\n$ cd osh-core\n$ gradle build\n\n\n\n\nThis command will build a JAR file for each module in the corresponding subfolder \n{module-name}/build/libs\n as well as a ZIP file containing all built module JARs in \nbuild/distributions\n.\n\n\nYou can optionally the artifacts to your local Maven repository with:\n\n\n$ gradle install\n\n\n\n\nNote 1: The first time you launch Gradle, the build process can take a while because Gradle fetches its own dependencies (i.e. Gradle plugins) as well as OpenSensorHub's dependencies. Later builds will go faster because these dependencies are cached locally.\n\n\nNote 2: Some of the JUnit tests automatically run during the 'test' phase of the OSH build process need to instantiate a server on port 8888. These tests will fail if something else is running on this port.\n\n\nBuild sensor modules\n\n\nSensor drivers are provided in various \nosh-sensors-***\n repositories. First clone one of these repos in the same folder as osh-core (i.e. \nosh-core\n and \nosh-sensors\n must be sibbling directories):\n\n\n$ git clone https://github.com/opensensorhub/osh-sensors\n\n\n\n\nSome sensor drivers need specific communication modules to work (e.g. RXTX serial comm or Bluetooth LE). If you're building a dev version, you'll also have to build these modules from source code. For this, clone the \nosh-comm\n repository at the same level as the other repos:\n\n\n$ git clone https://github.com/opensensorhub/osh-comm\n\n\n\n\nSensor drivers can be built individually depending which one you are interested in. To start with, you can build the simulated sensors since they don't require you to connect any hardware.\n\n\n$ cd osh-sensors\n$ gradle sensorhub-driver-fakegps:build\n$ gradle sensorhub-driver-fakeweather:build\n\n\n\n\nYou can also build all of them at once by running the following command in the \nosh-sensors\n folder:\n\n\n$ gradle build\n\n\n\n\nThis will build ZIP files (one for stable modules, one for dev) containing all sensor drivers in the \nbuild/distributions\n folder.\n\n\nBuild other modules\n\n\nYou can also clone other repositories of the project to build other types of modules.\n\n\nThe \nosh-services\n, \nosh-persistence\n and \nosh-security\n repositories are probably of interest if you want to go further.\n\n\nThere are also some Android specific modules and a demo app in the \nosh-android\n repository if you are interested in deploying on Android.\n\n\nBuild ZIP distributions\n\n\nDistribution build scripts are located in the \nosh-distros\n repository:\n\n\n$ git clone https://github.com/opensensorhub/osh-distros\n\n\n\n\nYou can build an installable ZIP package, complete with startup scripts by running:\n\n\n$ cd osh-distros/osh-base\n$ gradle build\n\n\n\n\nThe distribution is built in the \nbuild/distributions\n folder. You can unzip it and run OpenSensorHub using the launch script (it will run with the provided example configuration file, including some simulated sensors, storage databases and an SOS service). Please see the \nInstallation Guide\n for more details.\n\n\nUsing Eclipse\n\n\nWe provide Eclipse project configuration directly from the repository so it is the easiest way to get started, especially if you're already familiar with Eclipse. \n\n\nPre-requisites\n\n\nMake sure you have the following Eclipse components installed:\n\n\n\n\nEclipse Neon or newer (the exact steps described here are for Neon)\n\n\nEgit plugin for Eclipse (included in \"Eclipse IDE for Java Developers\" release)\n\n\nBuildship plugin for Eclipse v2.0.0 or newer (Buildship is included in the \"Eclipse IDE for Java Developers\" release but you'll need to upgrade it to a newer version. See below for instructions)\n\n\n\n\nHow to Upgrade the Buildship plugin\n\n\n\n\nGo to \"Help \n Install New Software\" in the main menu\n\n\nAdd a new \nUpdate Site\n by clicking \"Add...\" at the top right\n\n\nSet name to \"Buildship Snapshots\" and location to the following URL: https://builds.gradle.org/repository/download/Tooling_Master_IntegrationTests_Linux_Eclipse46Build/.lastSuccessful/update-site\n\n\nSelect the newly created update site in the list\n\n\nEnter \"guest\" for login and password\n\n\nSelect \"Buildship: Eclipse Plug-ins for Gradle\" in the tree\n\n\nClick \"Next\" to start the upgrade process to v2.0.0\n\n\n\n\nClone the project in your Eclipse workspace\n\n\n\n\nIn the Package Explorer, right click and select \"Import\" from the popup menu\n\n\nOpen the \"Git\" category, select \"Projects from Git\" and click \"Next\"\n\n\nSelect \"Clone URI\" and click \"Next\"\n\n\nIn the \"URI\" text box, enter the URL of the OpenSensorHub Core repository \nhttps://github.com/opensensorhub/osh-core.git\n and click \"Next\"\n\n\nLeave \"master\" selected and click \"Next\"\n\n\nYou can leave the Directory settings as-is on this page or change it to the location of your choice (Note that the Egit manual discourages cloning directly in the Eclipse workspace for performance reasons, however we haven't had any issue doing this with the opensensorhub code base. If you want to do like us, change the \"Directory\" to points directly to a sub-directory of your Eclipse workspace, for instance, \"/home/user/workspace/osh-core\")\n\n\nSelect \"Clone submodules\" and click \"Next\"\n\n\nAfter the download is complete, leave \"Import existing projects\" selected and click \"Next\"\n\n\nLeave all projects selected and click \"Finish\"\n\n\nAll projects should be imported successfully and visible in the \"Package Explorer\". Everything should compile without error.\n\n\nIf you like to keep your workspace tidy, you can group all the projects we just imported in a single Working Set\n\n\n\n\nYou'll probably need sensor drivers to fully test the software. To get more sensor drivers as well as other types of modules, repeat the steps above with the desired repositories of the opensensorhub github account. \n\n\n\n\nSensor Drivers: \nhttps://github.com/opensensorhub/osh-sensors.git\n \n\n\nNetwork Protocols: \nhttps://github.com/opensensorhub/osh-comm.git\n\n\nOther Services : \nhttps://github.com/opensensorhub/osh-services.git\n\n\nData-Processing : \nhttps://github.com/opensensorhub/osh-processing.git\n\n\nSecurity Stuff : \nhttps://github.com/opensensorhub/osh-security.git\n\n\nAndroid: \nhttps://github.com/opensensorhub/osh-android.git\n\n\n\n\nContributing\n\n\nIf you want to contribute, we feel the best way is that you create your own fork on GitHub, work on it, and when you have something working and tested, send us a Pull Request. To set this up, please follow the steps below:\n\n\nFork one or more repository of the project\n\n\nThe first step is to fork a repo by clicking the \nFork\n button on GitHub. This will clone the original code to your own GitHub account so you can then modify it and/or add to it as you wish. For this you'll need to have a GitHub account (it can be done in 30s using your email address) and log into it.\n\n\nForking the project this way will allow you to send us \nPull Requests\n via GitHub which makes it much easier for us to incorporate your contribution to the master branch. In addition, it creates a community around the software and lets others see what contributors are up to even before a patch is submitted. This can help you get the proper guidance when necessary.\n\n\nClone your GitHub repository\n\n\nClone your new GitHub repository locally by following the steps in the \nBuilding from Source\n section except you'll be using your own fork URL (e.g. https://github.com/yourusername/osh-*\n) instead of the \nopensensorhub\n version.\n\n\nWork on something new!\n\n\nYou can then start modifying the code and/or add new modules/features. We don't have coding guidelines yet but try to mimic the code that is already there. Don't forget to include Javadoc, especially on public parts of your APIs, and also inline comments explaining the different steps of your code.\n\n\nWhether you're trying to fix bugs or adding a brand new functionality, don't hesitate to tell us early-on what you're planning to work on. We may be able to point you in the right direction or maybe to somebody who has similar needs than you.\n\n\nYou can start by reading the instructions to \nCreate a New Module\n and \nAdd a New Sensor Driver\n for instance.\n\n\nAlso see the \nEclipse Tips\n section if you encounter problems while creating a new module.\n\n\nGet the latest updates from us\n\n\nWhile you're working on your stuff, don't forget to pull changes from the main repository once in a while. This will greatly help us merge your changes into the main branch when we receive your Pull Request. You can either do that from command line git or within Eclipse:\n\n\nUsing the \ngit\n command\n\n\nFirst add a new remote pointing to the \nopensensorhub\n master branch (you only have to do that the first time). For example, for the osh-core repository:\n\n\n$ git remote add upstream https://github.com/opensensorhub/osh-core\n\n\n\n\nThen pull changes from the \"upstream\" remote:\n\n\n$ git pull upstream master\n$ git submodule update\n\n\n\n\nNote 1: The \nsubmodule update\n command is only required in the \nosh-core\n repo that has submodules.\n\n\nNote 2: that you may have to manually merge with your working copy if you have made conflicting changes.\n\n\nUsing Eclipse\n\n\nFirst add a new remote pointing to the \nopensensorhub\n master branch (you only have to do that the first time):\n\n\n\n\nOpen the \"Git Repositories\" view (Window -\n Show view -\n Other -\n Git)\n\n\nOpen the \"sensorhub\" repository, right click on \"Remotes\" and select \"Create Remote\"\n\n\nEnter \"upstream\" as the remote name, select \"Configure fetch\" and click \"OK\"\n\n\nClick the \"Change\" button next to the URI text box\n\n\nEnter \nhttps://github.com/opensensorhub/osh-core\n as the URI and click \"Finish\"\n\n\nClick \"Save\"\n\n\n\n\nThen pull changes from the \"upstream\" remote:\n\n\n\n\nOpen the \"Git Repositories\" view (Window -\n Show view -\n Other -\n Git)\n\n\nRight click on the \"osh-core\" repository and select \"Remote -\n Fetch\" in the popup menu\n\n\nSelect the \"opensensorhub\" remote in the \"Configured remote repository\" item and click \"Finish\"\n\n\nRight click on the \"Submodules\" folder and select \"Update Submodule\" from the popup menu\n\n\n\n\nYou'll then eventually have to merge our changes with yours using the Egit merge command. Please see \nGit Documentation\n for more details\n\n\nNote: Also don't forget to import new Eclipse projects that may have been added since your last update. For this, follow these steps:\n\n\n\n\nRight click in your workspace and select \"Import...\" in the context menu\n\n\nSelect \"Existing project into workspace\" from the \"General\" section and click \"Next\"\n\n\nBrowse to the folder where you cloned our repo (usually called \"osh-core\" for the core software)\n\n\nSelect the missing projects in the list (all the projects that are not already in your workspace should already be selected) and click \"Finish\"   \n\n\n\n\nPush your changes to your own repo\n\n\nYou can push your changes to your own GitHub repo at any time, even if your code doesn't work yet. Remember this is your own sandbox so you won't mess up anybody else code base. We actually recommend that you do that often since it will provide you a good backup of your work, with full history.\n\n\nYou won't be able to push directly to the opensensorhub repos directly since you don't have write permissions (not until you become part of the team anyway). \n\n\nUsing the \ngit\n command\n\n\nTo do this with git command line tool, first stage and commit your changes locally:\n\n\n$ git commit -am \nYour commit message\n\n\n\n\n\nand then push them to your remote GitHub repository:\n\n\n$ git push\n\n\n\n\n(Please see the \ngit online documentation\n for more details and other ways to use git)\n\n\nUsing Eclipse\n\n\nWithin Eclipse, follow these steps:\n\n\nTo commit your changes locally:\n\n\n\n\nRight click on one of the Eclipse project with a name starting with \"sensorhub\"\n\n\nSelect \"Team -\n Commit\" from the popup menu\n\n\nEnter a commit message and select files you want to commit\n\n\nClick \"Commit\" (or \"Commit and Push\" if you want to commit locally and push to your remote repository in a single step)\n\n\nIf you have just pressed \"Commit\" you will see a arrow with a number on the right of the project names in the package explorer. This indicates that you have N local changes that need to be pushed to the remote repository (i.e. in git terms, your local repository is N commits ahead of your remote).\n\n\n\n\nIf you only want to push your last committed changes to your remote repository:\n\n\n\n\nRight click on one of the Eclipse project with a name starting with \"sensorhub\"\n\n\nSelect \"Team -\n Push to Upstream\" from the popup menu\n\n\nClick OK\n\n\n\n\n(Please see \nEgit online documentation\n for more advanced functionality)\n\n\nContribute your code\n\n\nWhen you feel you're ready to contribute all or some of your changes to the community, please send us a \nPull Request\n via GitHub.\n\n\nSo that we can better evaluate your contribution, please describe your improvements in as much details as you can. We'll do our best to process \nPull Request\n as fast as possible.\n\n\nThanks in advance for your contribution!\n\n\nEclipse Tips\n\n\nUpdate Gradle Settings\n\n\nEverytime a change is made to the Gradle build scripts, the Eclipse project settings must be updated with the following steps:\n\n\n\n\nClick one of the OSH module project\n\n\nSelect \"Gradle \n Refresh Gradle Project...\" from the context menu", 
            "title": "Developer's Guide"
        }, 
        {
            "location": "/dev/dev-guide/#developers-guide", 
            "text": "This guide is meant to help you setup a development environment based on the Eclipse IDE so that you can extend OpenSensorHub (OSH for short) with your own sensor drivers, web services and other components.  Don't forget to send us a Pull Request if you want to contribute your work back to this project. Other users may be interested by your modules and bug fixes!   Of course, contributing new modules to the community is optional as our license does not prevent proprietary and commercial derived work. However, keep in mind that  if you modify the source files we provide, you must make it available publicly in source form .   This page provides instructions for three possible options, depending on your level of involvement:    Exploring the code online    Downloading and building from source using Gradle from command-line or Eclipse    Contributing software and fixes to the project", 
            "title": "Developer's Guide"
        }, 
        {
            "location": "/dev/dev-guide/#exploring-the-code", 
            "text": "If you just want to explore the code, you can browse the source online directly on  Github . Alternatively, you can download it to your computer using the  Download ZIP  link on each GitHub repository or using the  git  program (please see the next section if you want to do just that).  To start with, the repositories of interest are OpenSensorHub  Core  and  Sensor Drivers .", 
            "title": "Exploring the Code"
        }, 
        {
            "location": "/dev/dev-guide/#building-from-source", 
            "text": "Below are the steps to download and build the code using either command line tools or the Eclipse IDE.", 
            "title": "Building from Source"
        }, 
        {
            "location": "/dev/dev-guide/#using-command-line-tools", 
            "text": "If you want to build the code and run it on your computer, you'll need  git 2.7  and  gradle 3.1  or later versions. Beware that a recent version of Gradle may not be provided with your Linux distribution but can be downloaded  here .", 
            "title": "Using Command-Line Tools"
        }, 
        {
            "location": "/dev/dev-guide/#build-the-core", 
            "text": "Use the following command to clone the  osh-core  repository:  $ git clone --recursive https://github.com/opensensorhub/osh-core  You can then build the code with:  $ cd osh-core\n$ gradle build  This command will build a JAR file for each module in the corresponding subfolder  {module-name}/build/libs  as well as a ZIP file containing all built module JARs in  build/distributions .  You can optionally the artifacts to your local Maven repository with:  $ gradle install  Note 1: The first time you launch Gradle, the build process can take a while because Gradle fetches its own dependencies (i.e. Gradle plugins) as well as OpenSensorHub's dependencies. Later builds will go faster because these dependencies are cached locally.  Note 2: Some of the JUnit tests automatically run during the 'test' phase of the OSH build process need to instantiate a server on port 8888. These tests will fail if something else is running on this port.", 
            "title": "Build the core"
        }, 
        {
            "location": "/dev/dev-guide/#build-sensor-modules", 
            "text": "Sensor drivers are provided in various  osh-sensors-***  repositories. First clone one of these repos in the same folder as osh-core (i.e.  osh-core  and  osh-sensors  must be sibbling directories):  $ git clone https://github.com/opensensorhub/osh-sensors  Some sensor drivers need specific communication modules to work (e.g. RXTX serial comm or Bluetooth LE). If you're building a dev version, you'll also have to build these modules from source code. For this, clone the  osh-comm  repository at the same level as the other repos:  $ git clone https://github.com/opensensorhub/osh-comm  Sensor drivers can be built individually depending which one you are interested in. To start with, you can build the simulated sensors since they don't require you to connect any hardware.  $ cd osh-sensors\n$ gradle sensorhub-driver-fakegps:build\n$ gradle sensorhub-driver-fakeweather:build  You can also build all of them at once by running the following command in the  osh-sensors  folder:  $ gradle build  This will build ZIP files (one for stable modules, one for dev) containing all sensor drivers in the  build/distributions  folder.", 
            "title": "Build sensor modules"
        }, 
        {
            "location": "/dev/dev-guide/#build-other-modules", 
            "text": "You can also clone other repositories of the project to build other types of modules.  The  osh-services ,  osh-persistence  and  osh-security  repositories are probably of interest if you want to go further.  There are also some Android specific modules and a demo app in the  osh-android  repository if you are interested in deploying on Android.", 
            "title": "Build other modules"
        }, 
        {
            "location": "/dev/dev-guide/#build-zip-distributions", 
            "text": "Distribution build scripts are located in the  osh-distros  repository:  $ git clone https://github.com/opensensorhub/osh-distros  You can build an installable ZIP package, complete with startup scripts by running:  $ cd osh-distros/osh-base\n$ gradle build  The distribution is built in the  build/distributions  folder. You can unzip it and run OpenSensorHub using the launch script (it will run with the provided example configuration file, including some simulated sensors, storage databases and an SOS service). Please see the  Installation Guide  for more details.", 
            "title": "Build ZIP distributions"
        }, 
        {
            "location": "/dev/dev-guide/#using-eclipse", 
            "text": "We provide Eclipse project configuration directly from the repository so it is the easiest way to get started, especially if you're already familiar with Eclipse.", 
            "title": "Using Eclipse"
        }, 
        {
            "location": "/dev/dev-guide/#pre-requisites", 
            "text": "Make sure you have the following Eclipse components installed:   Eclipse Neon or newer (the exact steps described here are for Neon)  Egit plugin for Eclipse (included in \"Eclipse IDE for Java Developers\" release)  Buildship plugin for Eclipse v2.0.0 or newer (Buildship is included in the \"Eclipse IDE for Java Developers\" release but you'll need to upgrade it to a newer version. See below for instructions)", 
            "title": "Pre-requisites"
        }, 
        {
            "location": "/dev/dev-guide/#how-to-upgrade-the-buildship-plugin", 
            "text": "Go to \"Help   Install New Software\" in the main menu  Add a new  Update Site  by clicking \"Add...\" at the top right  Set name to \"Buildship Snapshots\" and location to the following URL: https://builds.gradle.org/repository/download/Tooling_Master_IntegrationTests_Linux_Eclipse46Build/.lastSuccessful/update-site  Select the newly created update site in the list  Enter \"guest\" for login and password  Select \"Buildship: Eclipse Plug-ins for Gradle\" in the tree  Click \"Next\" to start the upgrade process to v2.0.0", 
            "title": "How to Upgrade the Buildship plugin"
        }, 
        {
            "location": "/dev/dev-guide/#clone-the-project-in-your-eclipse-workspace", 
            "text": "In the Package Explorer, right click and select \"Import\" from the popup menu  Open the \"Git\" category, select \"Projects from Git\" and click \"Next\"  Select \"Clone URI\" and click \"Next\"  In the \"URI\" text box, enter the URL of the OpenSensorHub Core repository  https://github.com/opensensorhub/osh-core.git  and click \"Next\"  Leave \"master\" selected and click \"Next\"  You can leave the Directory settings as-is on this page or change it to the location of your choice (Note that the Egit manual discourages cloning directly in the Eclipse workspace for performance reasons, however we haven't had any issue doing this with the opensensorhub code base. If you want to do like us, change the \"Directory\" to points directly to a sub-directory of your Eclipse workspace, for instance, \"/home/user/workspace/osh-core\")  Select \"Clone submodules\" and click \"Next\"  After the download is complete, leave \"Import existing projects\" selected and click \"Next\"  Leave all projects selected and click \"Finish\"  All projects should be imported successfully and visible in the \"Package Explorer\". Everything should compile without error.  If you like to keep your workspace tidy, you can group all the projects we just imported in a single Working Set   You'll probably need sensor drivers to fully test the software. To get more sensor drivers as well as other types of modules, repeat the steps above with the desired repositories of the opensensorhub github account.    Sensor Drivers:  https://github.com/opensensorhub/osh-sensors.git    Network Protocols:  https://github.com/opensensorhub/osh-comm.git  Other Services :  https://github.com/opensensorhub/osh-services.git  Data-Processing :  https://github.com/opensensorhub/osh-processing.git  Security Stuff :  https://github.com/opensensorhub/osh-security.git  Android:  https://github.com/opensensorhub/osh-android.git", 
            "title": "Clone the project in your Eclipse workspace"
        }, 
        {
            "location": "/dev/dev-guide/#contributing", 
            "text": "If you want to contribute, we feel the best way is that you create your own fork on GitHub, work on it, and when you have something working and tested, send us a Pull Request. To set this up, please follow the steps below:", 
            "title": "Contributing"
        }, 
        {
            "location": "/dev/dev-guide/#fork-one-or-more-repository-of-the-project", 
            "text": "The first step is to fork a repo by clicking the  Fork  button on GitHub. This will clone the original code to your own GitHub account so you can then modify it and/or add to it as you wish. For this you'll need to have a GitHub account (it can be done in 30s using your email address) and log into it.  Forking the project this way will allow you to send us  Pull Requests  via GitHub which makes it much easier for us to incorporate your contribution to the master branch. In addition, it creates a community around the software and lets others see what contributors are up to even before a patch is submitted. This can help you get the proper guidance when necessary.", 
            "title": "Fork one or more repository of the project"
        }, 
        {
            "location": "/dev/dev-guide/#clone-your-github-repository", 
            "text": "Clone your new GitHub repository locally by following the steps in the  Building from Source  section except you'll be using your own fork URL (e.g. https://github.com/yourusername/osh-* ) instead of the  opensensorhub  version.", 
            "title": "Clone your GitHub repository"
        }, 
        {
            "location": "/dev/dev-guide/#work-on-something-new", 
            "text": "You can then start modifying the code and/or add new modules/features. We don't have coding guidelines yet but try to mimic the code that is already there. Don't forget to include Javadoc, especially on public parts of your APIs, and also inline comments explaining the different steps of your code.  Whether you're trying to fix bugs or adding a brand new functionality, don't hesitate to tell us early-on what you're planning to work on. We may be able to point you in the right direction or maybe to somebody who has similar needs than you.  You can start by reading the instructions to  Create a New Module  and  Add a New Sensor Driver  for instance.  Also see the  Eclipse Tips  section if you encounter problems while creating a new module.", 
            "title": "Work on something new!"
        }, 
        {
            "location": "/dev/dev-guide/#get-the-latest-updates-from-us", 
            "text": "While you're working on your stuff, don't forget to pull changes from the main repository once in a while. This will greatly help us merge your changes into the main branch when we receive your Pull Request. You can either do that from command line git or within Eclipse:", 
            "title": "Get the latest updates from us"
        }, 
        {
            "location": "/dev/dev-guide/#using-the-git-command", 
            "text": "First add a new remote pointing to the  opensensorhub  master branch (you only have to do that the first time). For example, for the osh-core repository:  $ git remote add upstream https://github.com/opensensorhub/osh-core  Then pull changes from the \"upstream\" remote:  $ git pull upstream master\n$ git submodule update  Note 1: The  submodule update  command is only required in the  osh-core  repo that has submodules.  Note 2: that you may have to manually merge with your working copy if you have made conflicting changes.", 
            "title": "Using the git command"
        }, 
        {
            "location": "/dev/dev-guide/#using-eclipse_1", 
            "text": "First add a new remote pointing to the  opensensorhub  master branch (you only have to do that the first time):   Open the \"Git Repositories\" view (Window -  Show view -  Other -  Git)  Open the \"sensorhub\" repository, right click on \"Remotes\" and select \"Create Remote\"  Enter \"upstream\" as the remote name, select \"Configure fetch\" and click \"OK\"  Click the \"Change\" button next to the URI text box  Enter  https://github.com/opensensorhub/osh-core  as the URI and click \"Finish\"  Click \"Save\"   Then pull changes from the \"upstream\" remote:   Open the \"Git Repositories\" view (Window -  Show view -  Other -  Git)  Right click on the \"osh-core\" repository and select \"Remote -  Fetch\" in the popup menu  Select the \"opensensorhub\" remote in the \"Configured remote repository\" item and click \"Finish\"  Right click on the \"Submodules\" folder and select \"Update Submodule\" from the popup menu   You'll then eventually have to merge our changes with yours using the Egit merge command. Please see  Git Documentation  for more details  Note: Also don't forget to import new Eclipse projects that may have been added since your last update. For this, follow these steps:   Right click in your workspace and select \"Import...\" in the context menu  Select \"Existing project into workspace\" from the \"General\" section and click \"Next\"  Browse to the folder where you cloned our repo (usually called \"osh-core\" for the core software)  Select the missing projects in the list (all the projects that are not already in your workspace should already be selected) and click \"Finish\"", 
            "title": "Using Eclipse"
        }, 
        {
            "location": "/dev/dev-guide/#push-your-changes-to-your-own-repo", 
            "text": "You can push your changes to your own GitHub repo at any time, even if your code doesn't work yet. Remember this is your own sandbox so you won't mess up anybody else code base. We actually recommend that you do that often since it will provide you a good backup of your work, with full history.  You won't be able to push directly to the opensensorhub repos directly since you don't have write permissions (not until you become part of the team anyway).", 
            "title": "Push your changes to your own repo"
        }, 
        {
            "location": "/dev/dev-guide/#using-the-git-command_1", 
            "text": "To do this with git command line tool, first stage and commit your changes locally:  $ git commit -am  Your commit message   and then push them to your remote GitHub repository:  $ git push  (Please see the  git online documentation  for more details and other ways to use git)", 
            "title": "Using the git command"
        }, 
        {
            "location": "/dev/dev-guide/#using-eclipse_2", 
            "text": "Within Eclipse, follow these steps:  To commit your changes locally:   Right click on one of the Eclipse project with a name starting with \"sensorhub\"  Select \"Team -  Commit\" from the popup menu  Enter a commit message and select files you want to commit  Click \"Commit\" (or \"Commit and Push\" if you want to commit locally and push to your remote repository in a single step)  If you have just pressed \"Commit\" you will see a arrow with a number on the right of the project names in the package explorer. This indicates that you have N local changes that need to be pushed to the remote repository (i.e. in git terms, your local repository is N commits ahead of your remote).   If you only want to push your last committed changes to your remote repository:   Right click on one of the Eclipse project with a name starting with \"sensorhub\"  Select \"Team -  Push to Upstream\" from the popup menu  Click OK   (Please see  Egit online documentation  for more advanced functionality)", 
            "title": "Using Eclipse"
        }, 
        {
            "location": "/dev/dev-guide/#contribute-your-code", 
            "text": "When you feel you're ready to contribute all or some of your changes to the community, please send us a  Pull Request  via GitHub.  So that we can better evaluate your contribution, please describe your improvements in as much details as you can. We'll do our best to process  Pull Request  as fast as possible.  Thanks in advance for your contribution!", 
            "title": "Contribute your code"
        }, 
        {
            "location": "/dev/dev-guide/#eclipse-tips", 
            "text": "", 
            "title": "Eclipse Tips"
        }, 
        {
            "location": "/dev/dev-guide/#update-gradle-settings", 
            "text": "Everytime a change is made to the Gradle build scripts, the Eclipse project settings must be updated with the following steps:   Click one of the OSH module project  Select \"Gradle   Refresh Gradle Project...\" from the context menu", 
            "title": "Update Gradle Settings"
        }, 
        {
            "location": "/dev/architecture/", 
            "text": "Architecture\n\n\nThis page describes some of the key architecture and design principles used within OpenSensorHub. These are important concepts to understand if you want to contribute to the core or develop your own SensorHub modules (e.g. sensor drivers, database bindings, etc.)\n\n\nThe Event Bus\n\n\nSensorHub is designed around a generic bus through which transits all events coming from and going to the connected sensors and processes. SensorHub drivers convert standard or proprietary sensor/actuators protocols to the SWE common format so that the data can be communicated through the bus and made available to all other SensorHub components.\n\n\n\n\nAll data sent through the bus is described using the \nSWE Common Data Model\n so that each message is auto-describing and can be decoded by any sub-function connected to it.\n\n\nThe persistence engine is also connected to the bus and can archive the desired messages (data, commands, status info, etc...).\n\n\nWeb services that use real-time data are also connected to the bus and can distribute any data through standard web interfaces such as the \nSensor Observation Service\n from OGC.\n\n\nSensor Drivers\n\n\nDrivers are responsible for converting data going to and from the sensors into \nSWE Common\n messages, as well as for building a \nSensorML\n description of the connected sensor. The sensor is then always represented by this description in the system.\n\n\nWhenever possible, this description is fully or partially generated automatically from information stored in the sensor device (i.e serial number, calibration tables, etc.). If the sensor does not contain any such information, the driver generates a very simple document containing only the sensor ID, type and measurement output structure. In any case, this SensorML description can be further completed by the user when installing the sensor (the user will have to input the sensor location for instance).\n\n\nSensor drivers can be programmed to send data to the bus in various manners :\n\n\n\n\n\n\nIn 'push' mode, the sensor is programmed to make measurements at regular intervals or when certain conditions are met. In this case, the user does not request a reading explicitely.\n\n\n\n\n\n\nIn 'poll' mode, the user requests a reading from the sensor everytime. If no requests are made, no data is read.\n\n\n\n\n\n\nBoth modes can be mixed.\n\n\nPersistence/Storage Modules\n\n\nThe persistence engine is able to store any data that transits on the bus in a persistent storage. A simple API and several storage implementations are provided as part of the SensorHub software :\n\n\n\n\n\n\nThe \nPERST\n based storage uses a pure Java embedded object database which allows very efficient storage of data with a very small footprint (typically for embedded devices). See the [DataPersistencePERST PERST persistence page] for more details.\n\n\n\n\n\n\nThe \nPostgreSQL/PostGIS\n storage allows storing of SWE Common data in a robust SQL database but requires more powerful hardware and a database server to run.\n\n\n\n\n\n\nIn both cases, the database schema used is generic and can be used to store any data structure described in SWE Common and allows indexes on the specified fields.\n\n\nThe administration console allows the user to select what messages are to be stored and how (i.e. table name, what indexes should be created, etc.).\n\n\nWeb Service Modules\n\n\nWeb services can be developed and connected to other SensorHub modules to provide remote access to the different functions. SensorHub software already contains useful OGC services designed to communicate bi-directionnally with the connected sensors:\n\n\n\n\n\n\nThe Sensor Observation Service (SOS)\n is connected to the bus and to the persistent storage and allows retrieval of historical data as well as real-time data measurements.\n\n\n\n\n\n\nThe Sensor Planning Service (SPS)\n is connected to the bus and allows to send commands to the connected sensor.\n\n\n\n\n\n\nA simple \nWeb Feature Service (WFS)\n is connected to the sensor registry and allows one to retrieve the full SensorML descriptions of all connected sensors as well as simplified features containing only the name and location of the sensors for display on a map.\n\n\n\n\n\n\nAll web services are configurable through the administration web interface but most of the configuration is extracted automatically from the SensorML description of the sensors. The user mainly selects what sensor outputs should be exposed through SOS and/or what sensor parameters should be able to receive commands from SPS.\n\n\nProcessing Modules\n\n\nThe processing module is connected to the bus and the persistent storage and allows deployment of several processing instances that can either process data transiting on the bus (aka event-based or streaming processing) or process data from the storage on-demand (aka on-demand processing).\n\n\nProcess chains can be configured using the SensorML language so that new algorithms can be easily created without writing any code simply by connecting basic functions in the diagram editor (not currently available). However, the use of SensorML is not required and one can also write a plain Java plugin compliant with the processing API for implementing a particular algorithm.\n\n\nExample Deployment\n\n\nThe diagram below shows an example OSH instance configured with one sensor, one processing module, one storage module, SOS and SPS web services :\n\n\n\n\n\n\n\n\nThe sensor is connected via a proper sensor driver that pushes data to the bus as soon as it's available. Full description of the data structure is made available to other module via the sensor API.\n\n\n\n\n\n\nThe processing module instance listens to new sensor data and processes it as soon as it's available. The result is pushed back to the bus. Inputs and outputs are fully described in SensorML.\n\n\n\n\n\n\nThe storage module instance listens to both raw sensor and processed data and archives it all in a file or database. The archived data is then indexed and made available via the persistence API.\n\n\n\n\n\n\nThe SOS service can subscribe to and stream real-time sensor data when a user requests direct connection to it. It can also fetch data from archive storage on demand. In this case, data can be filtered by time, location, etc.\n\n\n\n\n\n\nThe SPS service is used to send commands to the sensor, such as turning the sensor on/off, changing the sampling rate, programming measurement triggers, etc. \n\n\n\n\n\n\nOf course, this is just an example and there are many more ways of configuring SensorHub. In particular, it is possible to :\n\n\n\n\n\n\nConnect several instances of SensorHub via standard OGC services so that one can create a larger network.\n\n\n\n\n\n\nImplement feedback loops so that one sensor can be used to trigger different behavior of another sensor.\n\n\n\n\n\n\nImplement complex processing flows that fuse data from many different sensors", 
            "title": "Architecture"
        }, 
        {
            "location": "/dev/architecture/#architecture", 
            "text": "This page describes some of the key architecture and design principles used within OpenSensorHub. These are important concepts to understand if you want to contribute to the core or develop your own SensorHub modules (e.g. sensor drivers, database bindings, etc.)", 
            "title": "Architecture"
        }, 
        {
            "location": "/dev/architecture/#the-event-bus", 
            "text": "SensorHub is designed around a generic bus through which transits all events coming from and going to the connected sensors and processes. SensorHub drivers convert standard or proprietary sensor/actuators protocols to the SWE common format so that the data can be communicated through the bus and made available to all other SensorHub components.   All data sent through the bus is described using the  SWE Common Data Model  so that each message is auto-describing and can be decoded by any sub-function connected to it.  The persistence engine is also connected to the bus and can archive the desired messages (data, commands, status info, etc...).  Web services that use real-time data are also connected to the bus and can distribute any data through standard web interfaces such as the  Sensor Observation Service  from OGC.", 
            "title": "The Event Bus"
        }, 
        {
            "location": "/dev/architecture/#sensor-drivers", 
            "text": "Drivers are responsible for converting data going to and from the sensors into  SWE Common  messages, as well as for building a  SensorML  description of the connected sensor. The sensor is then always represented by this description in the system.  Whenever possible, this description is fully or partially generated automatically from information stored in the sensor device (i.e serial number, calibration tables, etc.). If the sensor does not contain any such information, the driver generates a very simple document containing only the sensor ID, type and measurement output structure. In any case, this SensorML description can be further completed by the user when installing the sensor (the user will have to input the sensor location for instance).  Sensor drivers can be programmed to send data to the bus in various manners :    In 'push' mode, the sensor is programmed to make measurements at regular intervals or when certain conditions are met. In this case, the user does not request a reading explicitely.    In 'poll' mode, the user requests a reading from the sensor everytime. If no requests are made, no data is read.    Both modes can be mixed.", 
            "title": "Sensor Drivers"
        }, 
        {
            "location": "/dev/architecture/#persistencestorage-modules", 
            "text": "The persistence engine is able to store any data that transits on the bus in a persistent storage. A simple API and several storage implementations are provided as part of the SensorHub software :    The  PERST  based storage uses a pure Java embedded object database which allows very efficient storage of data with a very small footprint (typically for embedded devices). See the [DataPersistencePERST PERST persistence page] for more details.    The  PostgreSQL/PostGIS  storage allows storing of SWE Common data in a robust SQL database but requires more powerful hardware and a database server to run.    In both cases, the database schema used is generic and can be used to store any data structure described in SWE Common and allows indexes on the specified fields.  The administration console allows the user to select what messages are to be stored and how (i.e. table name, what indexes should be created, etc.).", 
            "title": "Persistence/Storage Modules"
        }, 
        {
            "location": "/dev/architecture/#web-service-modules", 
            "text": "Web services can be developed and connected to other SensorHub modules to provide remote access to the different functions. SensorHub software already contains useful OGC services designed to communicate bi-directionnally with the connected sensors:    The Sensor Observation Service (SOS)  is connected to the bus and to the persistent storage and allows retrieval of historical data as well as real-time data measurements.    The Sensor Planning Service (SPS)  is connected to the bus and allows to send commands to the connected sensor.    A simple  Web Feature Service (WFS)  is connected to the sensor registry and allows one to retrieve the full SensorML descriptions of all connected sensors as well as simplified features containing only the name and location of the sensors for display on a map.    All web services are configurable through the administration web interface but most of the configuration is extracted automatically from the SensorML description of the sensors. The user mainly selects what sensor outputs should be exposed through SOS and/or what sensor parameters should be able to receive commands from SPS.", 
            "title": "Web Service Modules"
        }, 
        {
            "location": "/dev/architecture/#processing-modules", 
            "text": "The processing module is connected to the bus and the persistent storage and allows deployment of several processing instances that can either process data transiting on the bus (aka event-based or streaming processing) or process data from the storage on-demand (aka on-demand processing).  Process chains can be configured using the SensorML language so that new algorithms can be easily created without writing any code simply by connecting basic functions in the diagram editor (not currently available). However, the use of SensorML is not required and one can also write a plain Java plugin compliant with the processing API for implementing a particular algorithm.", 
            "title": "Processing Modules"
        }, 
        {
            "location": "/dev/architecture/#example-deployment", 
            "text": "The diagram below shows an example OSH instance configured with one sensor, one processing module, one storage module, SOS and SPS web services :     The sensor is connected via a proper sensor driver that pushes data to the bus as soon as it's available. Full description of the data structure is made available to other module via the sensor API.    The processing module instance listens to new sensor data and processes it as soon as it's available. The result is pushed back to the bus. Inputs and outputs are fully described in SensorML.    The storage module instance listens to both raw sensor and processed data and archives it all in a file or database. The archived data is then indexed and made available via the persistence API.    The SOS service can subscribe to and stream real-time sensor data when a user requests direct connection to it. It can also fetch data from archive storage on demand. In this case, data can be filtered by time, location, etc.    The SPS service is used to send commands to the sensor, such as turning the sensor on/off, changing the sampling rate, programming measurement triggers, etc.     Of course, this is just an example and there are many more ways of configuring SensorHub. In particular, it is possible to :    Connect several instances of SensorHub via standard OGC services so that one can create a larger network.    Implement feedback loops so that one sensor can be used to trigger different behavior of another sensor.    Implement complex processing flows that fuse data from many different sensors", 
            "title": "Example Deployment"
        }, 
        {
            "location": "/dev/core-apis/", 
            "text": "OpenSensorHub Core APIs\n\n\nSensorHub software is implemented on top of public APIs that make the system modular and allow one to change almost any part of the system by pluging in new implementations.\n\n\nThe core APIs are:\n\n\n\n\nSWE Common and SensorML Bindings\n to create/read/write SensorML documents\n\n\nSensor API\n to implement sensor and actuator drivers\n\n\nProcess API\n to implement processing chains\n\n\nPersistence API\n to implement bindings to any database system\n\n\nCommunication API\n to implement drivers for various communication buses (serial, USB, Bluetooth, I2C, SPI, etc.)\n\n\nEvent Manager API\n to implement queuing and dispatching of events between modules or even sensorhub instances \n\n\n\n\nBefore you start implementing SensorHub's modules using these APIs, we also strongly encourage you to take the time to read about SensorHub's \nArchitecture\n.", 
            "title": "Introduction"
        }, 
        {
            "location": "/dev/core-apis/#opensensorhub-core-apis", 
            "text": "SensorHub software is implemented on top of public APIs that make the system modular and allow one to change almost any part of the system by pluging in new implementations.  The core APIs are:   SWE Common and SensorML Bindings  to create/read/write SensorML documents  Sensor API  to implement sensor and actuator drivers  Process API  to implement processing chains  Persistence API  to implement bindings to any database system  Communication API  to implement drivers for various communication buses (serial, USB, Bluetooth, I2C, SPI, etc.)  Event Manager API  to implement queuing and dispatching of events between modules or even sensorhub instances    Before you start implementing SensorHub's modules using these APIs, we also strongly encourage you to take the time to read about SensorHub's  Architecture .", 
            "title": "OpenSensorHub Core APIs"
        }, 
        {
            "location": "/dev/core-apis/sensorml-api/", 
            "text": "SWE Common / SensorML API\n\n\nIn SensorHub, sensor descriptions (or sensor metadata) are in the \nSensorML 2.0\n format, an international open standard from the \nOpen Geospatial Consortium (OGC)\n. They are often generated (at least partly) from code using the java SensorML bindings included in \nlib-sensorml\n.\n\n\nThese bindings are automatically generated from the 2.0 XML schemas and thus are a direct reflection of the types and properties that are defined by it. The general rule is that each \nXML Schema Complex Type\n (except OGC Property Types) becomes a Java interface with appropriate methods to handle each property (get/set/isSet/unSet, getNum/add for multiplicity \n 1, etc.).\n\n\nThere is one subtle difference compared to other bindings that could be generated with commonly used tools such as JAXB or XML Beans: OGC Property Types are not generated as separate objects thus removing many unnecessary layers in the generated object tree. Instead, properties are handled as a generic \nOgcProperty\n object, containing all info carried by the property such as name, xlink attributes, etc., and accessible via \n'getProperty'\n methods. This means that calls to regular get methods would return the property value directly which makes constructing the object much more straight forward. This design allows for handling the entire content model from many OGC schemas without making the resulting object tree too complex.\n\n\nLet's look at examples of how to set different parts of a SensorML document using this API (All code in the following section assumes you have an instance of \nPhysicalComponent\n or \nPhysicalSystem\n called \n'system'\n on hand).\n\n\nNote: Most of the following examples are actually extracted from the 'testGenerateInstance()' method of this \nJUnit Test Class\n so you can look at the code directly\n\n\nHigh-Level Descriptive Info\n\n\nThe first thing you need to do to create or add to a SensorML description is to instantiate SML and SWE helperfactories:\n\n\nSMLHelper smlFac = new SMLHelper();\nSWEHelper sweFac = new SWEHelper();\n\n\n\n\nThen, if you don't already have one, create the top level process or system instance. For instance a \nPhysicalSystem\n entity is created like so:\n\n\nPhysicalSystem system = smlFac.newPhysicalSystem();\n\n\n\n\nYou can then set name and description of the system:\n\n\nsystem.setName(\nGarage Thermometer\n);\nsystem.setDescription(\nThermometer located next to the door inside my garage\n);\n\n\n\n\nYou can also set the parent type of this sensor (this is typically used to reference a SensorML description providing more details about the sensor such as the SensorML document/datasheet provided by the manufacturer):\n\n\nsystem.setTypeOf(new ReferenceImpl(\nhttp://manufacturer.org/datasheets/sensor1234.xml\n));\n\n\n\n\nAdvanced Metadata\n\n\nAdd contact information:\n\n\nContactList contacts = smlFac.newContactList();\nCIResponsibleParty contact = smlFac.newResponsibleParty();\ncontact.setIndividualName(\nG\u00e9rard Blanquet\n);\ncontact.setOrganisationName(\nTime Soft S.A.\n);\ncontact.getContactInfo().getAddress().addDeliveryPoint(\n10 rue du Nord\n);\ncontact.getContactInfo().getAddress().setPostalCode(\n75896\n);\ncontact.getContactInfo().getAddress().setCity(\nParis\n);\ncontact.getContactInfo().getAddress().setCountry(\nFRANCE\n);\ncontact.setRole(new CodeListValueImpl(\noperator\n));\ncontacts.addContact(contact);\nsystem.addContacts(contacts);\n\n\n\n\nAdd characteristics:\n\n\nCharacteristicList mechSpecs = smlFac.newCharacteristicList();\nQuantity weightSpec = sweFac.newQuantity(\nhttp://sweet.jpl.nasa.gov/2.3/propMass.owl#Mass\n, \nWeight\n, null, \nkg\n);\nweightSpec.setValue(12.3);\nmechSpecs.addCharacteristic(\nweight\n, weightSpec);\nsystem.addCharacteristics(\nmechanical\n, mechSpecs);\n\n\n\n\nLocation\n\n\nAdd location as GML point:\n\n\nGMLFactory gmlFac = new GMLFactory();\nPoint pos = gmlFac.newPoint();\npos.setId(\nP01\n);\npos.setSrsName(\nhttp://www.opengis.net/def/crs/EPSG/0/4979\n);\npos.setPos(new double[] {45.6, 2.3, 193.2});\nsystem.addPositionAsPoint(pos);\n\n\n\n\nInputs/Outputs/Parameters\n\n\nAll inputs, outputs and parameters in SensorML are described using the SWE Common Language so you can use the \nSWEHelper\n class to create these structures. \n\n\nAdd observable property as input:\n\n\nObservableProperty obs = new ObservablePropertyImpl();\nobs.setDefinition(\nhttp://mmisw.org/ont/cf/parameter/weather\n);\nsystem.addInput(\nweather_phenomena\n, obs);\n\n\n\n\nYou can also add an input as xlink reference:\n\n\nsystem.getInputList().add(\nrain\n, \nhttp://remotedef.xml\n, null);\n\n\n\n\nAdd output record (in this case we first create the record object and then add sub-components to it, before we add it as output):\n\n\n// create output record and set description\nDataRecord rec = sweFac.newDataRecord();\nrec.setLabel(\nWeather Data Record\n);\nrec.setDescription(\nRecord of synchronous weather measurements\n);\n\n// sampling time\nrec.addField(\ntime\n, sweFac.newTimeStampIsoUTC());\n\n// temperature measurement\nrec.addField(\ntemp\n, sweFac.newQuantity(\n                            \nhttp://mmisw.org/ont/cf/parameter/air_temperature\n, \n                            \nAir Temperature\n, null, \nCel\n));\n\n// pressure\nrec.addField(\npress\n, sweFac.newQuantity(\n                            \nhttp://mmisw.org/ont/cf/parameter/air_pressure_at_sea_level\n,\n                            \nAir Pressure\n, null, \nmbar\n));\n\n// wind speed\nrec.addField(\nwind_speed\n, sweFac.newQuantity(\n                            \nhttp://mmisw.org/ont/cf/parameter/wind_speed\n,\n                            \nWind Speed\n, null, \nkm/h\n));\n\n// wind direction\nrec.addField(\nwind_dir\n, sweFac.newQuantity(\n                            \nhttp://mmisw.org/ont/cf/parameter/wind_to_direction\n,\n                            \nWind Direction\n, null, \ndeg\n));\n\n// add as output\nsystem.addOutput(\nweather_data\n, rec);\n\n\n\n\nYou can also add accuracy info to some of the measured outputs:\n\n\n// add accuracy info to temp output\nQuantity acc = sweFac.newQuantity(\n                      \nhttp://mmisw.org/ont/cf/parameter/accuracy\n,\n                      \nAccuracy\n, null, \n%\n);\n(Quantity)rec.getField(\ntemp\n)).addQuality(acc);\n\n\n\n\nParameters can be added in a similar fashion:\n\n\nsystem.addParameter(\nsamplingPeriod\n, sweFac.newQuantity(\n                       \nhttp://sensorml.com/ont/swe/property/SamplingPeriod\n,\n                       \nSampling Period\n, null, \ns\n));\n\n\n\n\nReference Frames\n\n\nOne important information that can be added to a sensor or system description is documentation about the reference frame that is attached to it. This is useful for properly processing positioning information in advanced geolocation workflows. Below is an example spatial reference frame definition:\n\n\nSpatialFrame systemFrame = smlFac.newSpatialFrame();\nsystemFrame.setId(\nSYSTEM_FRAME\n);\nsystemFrame.setLabel(\nSystem Reference Frame\n);\nsystemFrame.setDescription(\nCartesian reference frame attached to system assembly\n);\nsystemFrame.setOrigin(\nOrigin is located on the red marking at the bottom of the aluminum chassis\n);\nsystemFrame.addAxis(\nx\n, \nX axis is aligned with the horizontal edge of the chassis (see marking)\n);\nsystemFrame.addAxis(\ny\n, \nY axis is orthogonal to both X and Y in order to form a direct orthogonal frame\n);\nsystemFrame.addAxis(\nz\n, \nZ axis is pointing toward the top of the assembly, aligned with the vertical edge of the aluminum frame\n);\nsystem.addLocalReferenceFrame(systemFrame);\n\n\n\n\nWrite-out as XML\n\n\nOnce you have the java object tree created, it is trivial to serialize it as XML that is compliant to the SensorML standard:\n\n\nnew SMLUtils().writeProcess(System.out, system, true);", 
            "title": "SensorML API"
        }, 
        {
            "location": "/dev/core-apis/sensorml-api/#swe-common-sensorml-api", 
            "text": "In SensorHub, sensor descriptions (or sensor metadata) are in the  SensorML 2.0  format, an international open standard from the  Open Geospatial Consortium (OGC) . They are often generated (at least partly) from code using the java SensorML bindings included in  lib-sensorml .  These bindings are automatically generated from the 2.0 XML schemas and thus are a direct reflection of the types and properties that are defined by it. The general rule is that each  XML Schema Complex Type  (except OGC Property Types) becomes a Java interface with appropriate methods to handle each property (get/set/isSet/unSet, getNum/add for multiplicity   1, etc.).  There is one subtle difference compared to other bindings that could be generated with commonly used tools such as JAXB or XML Beans: OGC Property Types are not generated as separate objects thus removing many unnecessary layers in the generated object tree. Instead, properties are handled as a generic  OgcProperty  object, containing all info carried by the property such as name, xlink attributes, etc., and accessible via  'getProperty'  methods. This means that calls to regular get methods would return the property value directly which makes constructing the object much more straight forward. This design allows for handling the entire content model from many OGC schemas without making the resulting object tree too complex.  Let's look at examples of how to set different parts of a SensorML document using this API (All code in the following section assumes you have an instance of  PhysicalComponent  or  PhysicalSystem  called  'system'  on hand).  Note: Most of the following examples are actually extracted from the 'testGenerateInstance()' method of this  JUnit Test Class  so you can look at the code directly", 
            "title": "SWE Common / SensorML API"
        }, 
        {
            "location": "/dev/core-apis/sensorml-api/#high-level-descriptive-info", 
            "text": "The first thing you need to do to create or add to a SensorML description is to instantiate SML and SWE helperfactories:  SMLHelper smlFac = new SMLHelper();\nSWEHelper sweFac = new SWEHelper();  Then, if you don't already have one, create the top level process or system instance. For instance a  PhysicalSystem  entity is created like so:  PhysicalSystem system = smlFac.newPhysicalSystem();  You can then set name and description of the system:  system.setName( Garage Thermometer );\nsystem.setDescription( Thermometer located next to the door inside my garage );  You can also set the parent type of this sensor (this is typically used to reference a SensorML description providing more details about the sensor such as the SensorML document/datasheet provided by the manufacturer):  system.setTypeOf(new ReferenceImpl( http://manufacturer.org/datasheets/sensor1234.xml ));", 
            "title": "High-Level Descriptive Info"
        }, 
        {
            "location": "/dev/core-apis/sensorml-api/#advanced-metadata", 
            "text": "Add contact information:  ContactList contacts = smlFac.newContactList();\nCIResponsibleParty contact = smlFac.newResponsibleParty();\ncontact.setIndividualName( G\u00e9rard Blanquet );\ncontact.setOrganisationName( Time Soft S.A. );\ncontact.getContactInfo().getAddress().addDeliveryPoint( 10 rue du Nord );\ncontact.getContactInfo().getAddress().setPostalCode( 75896 );\ncontact.getContactInfo().getAddress().setCity( Paris );\ncontact.getContactInfo().getAddress().setCountry( FRANCE );\ncontact.setRole(new CodeListValueImpl( operator ));\ncontacts.addContact(contact);\nsystem.addContacts(contacts);  Add characteristics:  CharacteristicList mechSpecs = smlFac.newCharacteristicList();\nQuantity weightSpec = sweFac.newQuantity( http://sweet.jpl.nasa.gov/2.3/propMass.owl#Mass ,  Weight , null,  kg );\nweightSpec.setValue(12.3);\nmechSpecs.addCharacteristic( weight , weightSpec);\nsystem.addCharacteristics( mechanical , mechSpecs);", 
            "title": "Advanced Metadata"
        }, 
        {
            "location": "/dev/core-apis/sensorml-api/#location", 
            "text": "Add location as GML point:  GMLFactory gmlFac = new GMLFactory();\nPoint pos = gmlFac.newPoint();\npos.setId( P01 );\npos.setSrsName( http://www.opengis.net/def/crs/EPSG/0/4979 );\npos.setPos(new double[] {45.6, 2.3, 193.2});\nsystem.addPositionAsPoint(pos);", 
            "title": "Location"
        }, 
        {
            "location": "/dev/core-apis/sensorml-api/#inputsoutputsparameters", 
            "text": "All inputs, outputs and parameters in SensorML are described using the SWE Common Language so you can use the  SWEHelper  class to create these structures.   Add observable property as input:  ObservableProperty obs = new ObservablePropertyImpl();\nobs.setDefinition( http://mmisw.org/ont/cf/parameter/weather );\nsystem.addInput( weather_phenomena , obs);  You can also add an input as xlink reference:  system.getInputList().add( rain ,  http://remotedef.xml , null);  Add output record (in this case we first create the record object and then add sub-components to it, before we add it as output):  // create output record and set description\nDataRecord rec = sweFac.newDataRecord();\nrec.setLabel( Weather Data Record );\nrec.setDescription( Record of synchronous weather measurements );\n\n// sampling time\nrec.addField( time , sweFac.newTimeStampIsoUTC());\n\n// temperature measurement\nrec.addField( temp , sweFac.newQuantity(\n                             http://mmisw.org/ont/cf/parameter/air_temperature , \n                             Air Temperature , null,  Cel ));\n\n// pressure\nrec.addField( press , sweFac.newQuantity(\n                             http://mmisw.org/ont/cf/parameter/air_pressure_at_sea_level ,\n                             Air Pressure , null,  mbar ));\n\n// wind speed\nrec.addField( wind_speed , sweFac.newQuantity(\n                             http://mmisw.org/ont/cf/parameter/wind_speed ,\n                             Wind Speed , null,  km/h ));\n\n// wind direction\nrec.addField( wind_dir , sweFac.newQuantity(\n                             http://mmisw.org/ont/cf/parameter/wind_to_direction ,\n                             Wind Direction , null,  deg ));\n\n// add as output\nsystem.addOutput( weather_data , rec);  You can also add accuracy info to some of the measured outputs:  // add accuracy info to temp output\nQuantity acc = sweFac.newQuantity(\n                       http://mmisw.org/ont/cf/parameter/accuracy ,\n                       Accuracy , null,  % );\n(Quantity)rec.getField( temp )).addQuality(acc);  Parameters can be added in a similar fashion:  system.addParameter( samplingPeriod , sweFac.newQuantity(\n                        http://sensorml.com/ont/swe/property/SamplingPeriod ,\n                        Sampling Period , null,  s ));", 
            "title": "Inputs/Outputs/Parameters"
        }, 
        {
            "location": "/dev/core-apis/sensorml-api/#reference-frames", 
            "text": "One important information that can be added to a sensor or system description is documentation about the reference frame that is attached to it. This is useful for properly processing positioning information in advanced geolocation workflows. Below is an example spatial reference frame definition:  SpatialFrame systemFrame = smlFac.newSpatialFrame();\nsystemFrame.setId( SYSTEM_FRAME );\nsystemFrame.setLabel( System Reference Frame );\nsystemFrame.setDescription( Cartesian reference frame attached to system assembly );\nsystemFrame.setOrigin( Origin is located on the red marking at the bottom of the aluminum chassis );\nsystemFrame.addAxis( x ,  X axis is aligned with the horizontal edge of the chassis (see marking) );\nsystemFrame.addAxis( y ,  Y axis is orthogonal to both X and Y in order to form a direct orthogonal frame );\nsystemFrame.addAxis( z ,  Z axis is pointing toward the top of the assembly, aligned with the vertical edge of the aluminum frame );\nsystem.addLocalReferenceFrame(systemFrame);", 
            "title": "Reference Frames"
        }, 
        {
            "location": "/dev/core-apis/sensorml-api/#write-out-as-xml", 
            "text": "Once you have the java object tree created, it is trivial to serialize it as XML that is compliant to the SensorML standard:  new SMLUtils().writeProcess(System.out, system, true);", 
            "title": "Write-out as XML"
        }, 
        {
            "location": "/dev/core-apis/sensor-api/", 
            "text": "Sensor API\n\n\nThis page presents the base API that one needs to implement to add support for new sensors or actuators.\n\n\nThis API can only be used to implement drivers for single sensors (this limitation is due to the fact that the base API only allows the driver to define a single Feature of Interest (FOI) and a single sensor description). This means that a driver implementing only the base API would have to be instantiated N times to connect to a network of N sensors. Fortunately, SensorHub also defines an extension to the base sensor API allowing one to write drivers that can wrap sensor networks of any size within a single module. Please see the \nSensor Network API\n page for more details.\n\n\nWhen implementing the base sensor API, each new sensor (or actuator) driver is composed of at least 4 classes:\n\n\n\n\nAn implementation of the \nISensorModule\n interface\n\n\nZero or more implementations of \nISensorDataInterface\n (\nat least one for a sensor\n)\n\n\nZero or more implementations of \nISensorControlInterface\n (\nat least one for an actuator\n)\n\n\nAn extension of the \nSensorConfig\n class\n\n\nAn implementation of the \nIModuleDescriptor\n interface\n\n\n\n\nDetails about these different classes are given in the next sections.\n\n\nNote: Several sensor drivers can be packaged in a single Maven module, although we encourage this only if the drivers are very closely related and/or have tight inter-dependencies.\n\n\nISensorModule\n\n\nThe \nISensorModule\n interface is the top-level one to be implemented by sensor drivers. It provides methods for:\n\n\n\n\nGetting the SensorML description of an installed sensor or actuator\n\n\nGetting the feature of interest (FOI) currently observed by the sensor\n\n\nChecking for the presence of the device\n\n\nSubscribing for high level sensor events (activation, connection, etc.)\n\n\nGiving access to the sensor measurement outputs and control inputs\n\n\n\n\nThe main functions of the sensor module are shown on the figure below:\n\n\n\n\nEach data interface is an output that gives access to a stream of sensor measurements and is an implementation of \nISensorDataInterface\n. Data interfaces are asynchornous in the sense that each of them can produce data at a different rate.\n\n\nEach control interface is an input that can receive commands and is an implementation of \nISensorControlInterface\n. Each control input can receive different types of command messages.\n\n\nA sensor module implementation must also provide the description of the sensor as a SensorML process (any class derived from \nAbstractProcess\n is acceptable). Usually, this sensor description is a mix between information auto-generated by the driver and information provided as a SensorML file by the user. Versioning and updating the sensor description can be optionnally supported by the driver.\n\n\nIn order to help you implement the API, we provide the \nAbstractSensorModule\n class that is a simple partial implementation of \nISensorModule\n and can be used as the base for most sensor modules. It provides default implementations of most methods in the API.\n\n\nISensorDataInterface\n\n\nData produced by each output must be made available by an implementation of \nISensorDataInterface\n that provides methods for:\n\n\n\n\nDescribing the data structure of each measurement record\n\n\nReading data produced by a sensor (poll mode)\n\n\nSubscribing for data produced by a sensor (push mode)\n\n\nDiscovery methods allowing to advertise if push and storage are supported\n\n\n\n\nThe measurement record description must be provided as a tree of SWE Common data components (DataRecord, DataArray, Quantity, Time, Count, etc.). This structure will automatically be used to populate the output section of the SensorML description.\n\n\nA recommended encoding must also be defined which is usually text for simple measurements and some binary flavor for imagery, video and other multi-dimensionnal datasets. \n\n\nThese components and encodings are provided by the \nlib-swe-common\n module.\n\n\nAll data streamed through the same data interface must be synchronous and time-tagged together.\n\n\nThe \nAbstractSensorOutput\n class is provided to reduce redundant code and help you get started. It is a basic partial implementation of \nISensorDataInterface\n that can be used as the base for most sensor modules.\n\n\nISensorControlInterface\n\n\nCommands can be sent to the sensor via implementations of \nISensorControlInterface\n that provides methods for:\n\n\n\n\nSending commands to the sensor/actuator (synchronous or asynchronous)\n\n\nScheduling commands to be sent asynchronously and/or at specific times\n\n\nSubscribing to events related to a command that is executed asynchronously\n\n\n\n\nThe \nAbstractSensorControl\n class is provided to reduce redundant code and help you get started. It is a basic partial implementation of \nISensorControlInterface\n that can be used as the base for most sensor modules.\n\n\nSensorConfig\n\n\nA configuration class derived from SensorConfig must be provided with the new driver. This class is used as a \nstruct\n that contain public fields carrying the configuration of the sensor module.\n\n\nAll public fields in this class are used to automatically generate the administration user interface of this particular driver. Nesting configuration classes is supported.\n\n\nYou can use the \nDisplayInfo\n annotation to give hints to the UI renderer, by providing:\n\n\n\n\nA more readable label (if non is provided, the label is automatically derived from the field name)\n\n\nA description that will show up in a popup\n\n\n\n\nAbstractSensorModule\n\n\nThe \nAbstractSensorModule\n class can serve as a base to develop most sensor drivers. It provides default implementation for the following aspects:\n\n\n\n\nKeeping maps of outputs and command inputs. Derived classes should thus call the \naddOutput()\n and \naddControlInput()\n methods\n\n\nGeneration of SensorML description (more details are given below)\n\n\n\n\nHowever, there is no default support for:\n\n\n\n\nUpdating the sensor description from outside the driver (except by changing the base SensorML file)\n\n\nMaintaining a history of sensor descriptions (this is because, by default, this feature is better handled by the persistence layer in SensorHub).\n\n\n\n\nConsequently, the \nAbstractSensorModule\n class returns \nfalse\n in the two methods reporting support of these functionalities.\n\n\nDefault workflow for generating the SensorML description\n\n\nThe default workflow shown on the figure below illustrates the way the current sensor decription is generated when you derive a concrete driver implementation from \nAbstractSensorModule\n:\n\n\n\n\n\n\n\n\nOutput, control inputs and configuration parameter descriptions are actually defined by concrete driver implementation but appending to SensorML is done in \nAbstractSensorModule\n\n\n\n\n\n\nAutogenerated content is usually info obtained directly from sensor hardware\n(e.g. serial number, etc.) and/or internal driver state (e.g. depending on commands received)\n\n\n\n\n\n\nIModuleDescriptor\n\n\nLike any SensorHub module, a sensor driver must implement a class derived from this interface to become discoverable.", 
            "title": "Sensor API"
        }, 
        {
            "location": "/dev/core-apis/sensor-api/#sensor-api", 
            "text": "This page presents the base API that one needs to implement to add support for new sensors or actuators.  This API can only be used to implement drivers for single sensors (this limitation is due to the fact that the base API only allows the driver to define a single Feature of Interest (FOI) and a single sensor description). This means that a driver implementing only the base API would have to be instantiated N times to connect to a network of N sensors. Fortunately, SensorHub also defines an extension to the base sensor API allowing one to write drivers that can wrap sensor networks of any size within a single module. Please see the  Sensor Network API  page for more details.  When implementing the base sensor API, each new sensor (or actuator) driver is composed of at least 4 classes:   An implementation of the  ISensorModule  interface  Zero or more implementations of  ISensorDataInterface  ( at least one for a sensor )  Zero or more implementations of  ISensorControlInterface  ( at least one for an actuator )  An extension of the  SensorConfig  class  An implementation of the  IModuleDescriptor  interface   Details about these different classes are given in the next sections.  Note: Several sensor drivers can be packaged in a single Maven module, although we encourage this only if the drivers are very closely related and/or have tight inter-dependencies.", 
            "title": "Sensor API"
        }, 
        {
            "location": "/dev/core-apis/sensor-api/#isensormodule", 
            "text": "The  ISensorModule  interface is the top-level one to be implemented by sensor drivers. It provides methods for:   Getting the SensorML description of an installed sensor or actuator  Getting the feature of interest (FOI) currently observed by the sensor  Checking for the presence of the device  Subscribing for high level sensor events (activation, connection, etc.)  Giving access to the sensor measurement outputs and control inputs   The main functions of the sensor module are shown on the figure below:   Each data interface is an output that gives access to a stream of sensor measurements and is an implementation of  ISensorDataInterface . Data interfaces are asynchornous in the sense that each of them can produce data at a different rate.  Each control interface is an input that can receive commands and is an implementation of  ISensorControlInterface . Each control input can receive different types of command messages.  A sensor module implementation must also provide the description of the sensor as a SensorML process (any class derived from  AbstractProcess  is acceptable). Usually, this sensor description is a mix between information auto-generated by the driver and information provided as a SensorML file by the user. Versioning and updating the sensor description can be optionnally supported by the driver.  In order to help you implement the API, we provide the  AbstractSensorModule  class that is a simple partial implementation of  ISensorModule  and can be used as the base for most sensor modules. It provides default implementations of most methods in the API.", 
            "title": "ISensorModule"
        }, 
        {
            "location": "/dev/core-apis/sensor-api/#isensordatainterface", 
            "text": "Data produced by each output must be made available by an implementation of  ISensorDataInterface  that provides methods for:   Describing the data structure of each measurement record  Reading data produced by a sensor (poll mode)  Subscribing for data produced by a sensor (push mode)  Discovery methods allowing to advertise if push and storage are supported   The measurement record description must be provided as a tree of SWE Common data components (DataRecord, DataArray, Quantity, Time, Count, etc.). This structure will automatically be used to populate the output section of the SensorML description.  A recommended encoding must also be defined which is usually text for simple measurements and some binary flavor for imagery, video and other multi-dimensionnal datasets.   These components and encodings are provided by the  lib-swe-common  module.  All data streamed through the same data interface must be synchronous and time-tagged together.  The  AbstractSensorOutput  class is provided to reduce redundant code and help you get started. It is a basic partial implementation of  ISensorDataInterface  that can be used as the base for most sensor modules.", 
            "title": "ISensorDataInterface"
        }, 
        {
            "location": "/dev/core-apis/sensor-api/#isensorcontrolinterface", 
            "text": "Commands can be sent to the sensor via implementations of  ISensorControlInterface  that provides methods for:   Sending commands to the sensor/actuator (synchronous or asynchronous)  Scheduling commands to be sent asynchronously and/or at specific times  Subscribing to events related to a command that is executed asynchronously   The  AbstractSensorControl  class is provided to reduce redundant code and help you get started. It is a basic partial implementation of  ISensorControlInterface  that can be used as the base for most sensor modules.", 
            "title": "ISensorControlInterface"
        }, 
        {
            "location": "/dev/core-apis/sensor-api/#sensorconfig", 
            "text": "A configuration class derived from SensorConfig must be provided with the new driver. This class is used as a  struct  that contain public fields carrying the configuration of the sensor module.  All public fields in this class are used to automatically generate the administration user interface of this particular driver. Nesting configuration classes is supported.  You can use the  DisplayInfo  annotation to give hints to the UI renderer, by providing:   A more readable label (if non is provided, the label is automatically derived from the field name)  A description that will show up in a popup", 
            "title": "SensorConfig"
        }, 
        {
            "location": "/dev/core-apis/sensor-api/#abstractsensormodule", 
            "text": "The  AbstractSensorModule  class can serve as a base to develop most sensor drivers. It provides default implementation for the following aspects:   Keeping maps of outputs and command inputs. Derived classes should thus call the  addOutput()  and  addControlInput()  methods  Generation of SensorML description (more details are given below)   However, there is no default support for:   Updating the sensor description from outside the driver (except by changing the base SensorML file)  Maintaining a history of sensor descriptions (this is because, by default, this feature is better handled by the persistence layer in SensorHub).   Consequently, the  AbstractSensorModule  class returns  false  in the two methods reporting support of these functionalities.", 
            "title": "AbstractSensorModule"
        }, 
        {
            "location": "/dev/core-apis/sensor-api/#default-workflow-for-generating-the-sensorml-description", 
            "text": "The default workflow shown on the figure below illustrates the way the current sensor decription is generated when you derive a concrete driver implementation from  AbstractSensorModule :     Output, control inputs and configuration parameter descriptions are actually defined by concrete driver implementation but appending to SensorML is done in  AbstractSensorModule    Autogenerated content is usually info obtained directly from sensor hardware\n(e.g. serial number, etc.) and/or internal driver state (e.g. depending on commands received)", 
            "title": "Default workflow for generating the SensorML description"
        }, 
        {
            "location": "/dev/core-apis/sensor-api/#imoduledescriptor", 
            "text": "Like any SensorHub module, a sensor driver must implement a class derived from this interface to become discoverable.", 
            "title": "IModuleDescriptor"
        }, 
        {
            "location": "/dev/core-apis/sensornet-api/", 
            "text": "Sensor Network API\n\n\nThis page presents an extension of the base \nSensor API\n that allows one to implement drivers for sensor networks of any size as a single SensorHub module. This API is used in addition to the base sensor API when one needs to wrap such a sensor network instead of just a single sensor.\n\n\nIn addition to the base sensor API methods, a sensor network module would have to implement the \n'IMultiSourceDataProducer'\n interface which allows providing \nSensor Descriptions\n and \nFeatures of Interest\n (FOI) for multiple \nEntities\n:\n\n\nEntities\n\n\nThe 'IMultiSourceDataProducer' interface is based on the concept of \nEntity\n: An entity represents one member of the network. We use the term entity because this interface can also be used for other things than sensor networks, such as process grids.\n\n\nFor sensor networks, each entity usually corresponds to one sensor (or one measurement system such as a weather station) in the network. Although sensors in a network often measure the same quantities, it is not always the case, so SensorHub allows for completely heterogeneous sensors to be part of the same network.\n\n\nSensor Descriptions\n\n\nThe sensor network driver is responsible for providing sensor descriptions for each entity via the \ngetCurrentDescription(String entityId)\n method. This description can contain information specific to that entity such as its location (when fixed) and calibration tables for example.\n\n\nSince the driver also inherits the original methods from the base \nSensor API\n, the \ngetCurrentDescription()\n method shall be used to provide a description of the network as a whole. This description usually contains the list of sensors that are part of the network as SensorML components (for large networks, this will be preferably done by reference). It is also important to include discovery related information in this description since it is the only one directly referenced by the capabilities document of SWE services.\n\n\nChanges in the network or in a given entity configuration are notified using a \nSensorEvent\n. In the case of an entity change, use the constructor with the sensorID.\n\n\nNote: As for single sensors, the driver is only required to provide the most current sensor descriptions. Maintenance of the history of descriptions is done by storage modules in SensorHub.\n\n\nFeatures of Interest\n\n\nIn a sensor network, there can be as many features of interest (FOI) as there are entities in the network at any given point in time (e.g. for a network of weather station, there is one static sampling point per station). The FOI associated with each entity is provided via the \ngetCurrentFeatureOfInterest(String entityID)\n method.\n\n\nSince the driver also inherits the original methods from the base \nSensor API\n, the \ngetCurrentFeatureOfInterest()\n method shall be used to provide a FOI for the network as a whole (e.g. The FOI for a river monitoring sensor network is the river itself, while the FOI for each station/entity would be a sampling point at the station location). This corresponds to the sampled feature in the O\nM model.\n\n\nWhen one of the features of interest changes (as usually happens in networks of mobile sensors), this can be notified using an \nFoiEvent\n. If the FOI observed by one of the sensor changes (e.g. the sensor was moved to a new location), use the constructor with the entityID.\n\n\nNote: As for single sensors, the driver is only required to provide the feature of interest currently being observed. Maintenance of the history of FOIs is done by storage modules in SensorHub.\n\n\nNetwork Output\n\n\nFor sensor networks, the observation output(s) should include a field indicating the ID of the entity that generated the data record. For instance, the record description for weather measurements coming from a network of weather station could be such as:\n\n\nswe:DataRecord definition=\nhttp://sensorml.com/ont/swe/property/WeatherData\n\n    \nswe:field name=\ntime\n\n        \nswe:Time\n            definition=\nhttp://www.opengis.net/def/property/OGC/0/SamplingTime\n referenceFrame=\nhttp://www.opengis.net/def/trs/BIPM/0/UTC\n\n            \nswe:label\nSampling Time\n/swe:label\n\n            \nswe:uom xlink:href=\nhttp://www.opengis.net/def/uom/ISO-8601/0/Gregorian\n/\n\n        \n/swe:Time\n\n    \n/swe:field\n\n    \nswe:field name=\nstationID\n\n        \nswe:Text definition=\nhttp://sensorml.com/ont/swe/property/StationID\n\n            \nswe:label\nStation ID\n/swe:label\n\n        \n/swe:Text\n\n    \n/swe:field\n\n    \nswe:field name=\ntemp\n\n        \nswe:Quantity definition=\nhttp://sensorml.com/ont/swe/property/Temperature\n\n            \nswe:label\nAir Temperature\n/swe:label\n\n            \nswe:uom code=\ndegF\n/\n\n        \n/swe:Quantity\n\n    \n/swe:field\n\n    \nswe:field name=\nhumidity\n\n        \nswe:Quantity definition=\nhttp://sensorml.com/ont/swe/property/HumidityValue\n\n            \nswe:label\nRelative Humidity\n/swe:label\n\n            \nswe:uom code=\n%\n/\n\n        \n/swe:Quantity\n\n    \n/swe:field\n\n    \nswe:field name=\npress\n\n        \nswe:Quantity definition=\nhttp://sensorml.com/ont/swe/property/AirPressureValue\n\n            \nswe:label\nAtmospheric Pressure\n/swe:label\n\n            \nswe:uom code=\n[in_i]Hg\n/\n\n        \n/swe:Quantity\n\n    \n/swe:field\n\n\n/swe:DataRecord\n\n\n\n\n\nNotice the field `stationID' whose value would be the ID of the entity/station that generated the record.", 
            "title": "Sensor Network API"
        }, 
        {
            "location": "/dev/core-apis/sensornet-api/#sensor-network-api", 
            "text": "This page presents an extension of the base  Sensor API  that allows one to implement drivers for sensor networks of any size as a single SensorHub module. This API is used in addition to the base sensor API when one needs to wrap such a sensor network instead of just a single sensor.  In addition to the base sensor API methods, a sensor network module would have to implement the  'IMultiSourceDataProducer'  interface which allows providing  Sensor Descriptions  and  Features of Interest  (FOI) for multiple  Entities :", 
            "title": "Sensor Network API"
        }, 
        {
            "location": "/dev/core-apis/sensornet-api/#entities", 
            "text": "The 'IMultiSourceDataProducer' interface is based on the concept of  Entity : An entity represents one member of the network. We use the term entity because this interface can also be used for other things than sensor networks, such as process grids.  For sensor networks, each entity usually corresponds to one sensor (or one measurement system such as a weather station) in the network. Although sensors in a network often measure the same quantities, it is not always the case, so SensorHub allows for completely heterogeneous sensors to be part of the same network.", 
            "title": "Entities"
        }, 
        {
            "location": "/dev/core-apis/sensornet-api/#sensor-descriptions", 
            "text": "The sensor network driver is responsible for providing sensor descriptions for each entity via the  getCurrentDescription(String entityId)  method. This description can contain information specific to that entity such as its location (when fixed) and calibration tables for example.  Since the driver also inherits the original methods from the base  Sensor API , the  getCurrentDescription()  method shall be used to provide a description of the network as a whole. This description usually contains the list of sensors that are part of the network as SensorML components (for large networks, this will be preferably done by reference). It is also important to include discovery related information in this description since it is the only one directly referenced by the capabilities document of SWE services.  Changes in the network or in a given entity configuration are notified using a  SensorEvent . In the case of an entity change, use the constructor with the sensorID.  Note: As for single sensors, the driver is only required to provide the most current sensor descriptions. Maintenance of the history of descriptions is done by storage modules in SensorHub.", 
            "title": "Sensor Descriptions"
        }, 
        {
            "location": "/dev/core-apis/sensornet-api/#features-of-interest", 
            "text": "In a sensor network, there can be as many features of interest (FOI) as there are entities in the network at any given point in time (e.g. for a network of weather station, there is one static sampling point per station). The FOI associated with each entity is provided via the  getCurrentFeatureOfInterest(String entityID)  method.  Since the driver also inherits the original methods from the base  Sensor API , the  getCurrentFeatureOfInterest()  method shall be used to provide a FOI for the network as a whole (e.g. The FOI for a river monitoring sensor network is the river itself, while the FOI for each station/entity would be a sampling point at the station location). This corresponds to the sampled feature in the O M model.  When one of the features of interest changes (as usually happens in networks of mobile sensors), this can be notified using an  FoiEvent . If the FOI observed by one of the sensor changes (e.g. the sensor was moved to a new location), use the constructor with the entityID.  Note: As for single sensors, the driver is only required to provide the feature of interest currently being observed. Maintenance of the history of FOIs is done by storage modules in SensorHub.", 
            "title": "Features of Interest"
        }, 
        {
            "location": "/dev/core-apis/sensornet-api/#network-output", 
            "text": "For sensor networks, the observation output(s) should include a field indicating the ID of the entity that generated the data record. For instance, the record description for weather measurements coming from a network of weather station could be such as:  swe:DataRecord definition= http://sensorml.com/ont/swe/property/WeatherData \n     swe:field name= time \n         swe:Time\n            definition= http://www.opengis.net/def/property/OGC/0/SamplingTime  referenceFrame= http://www.opengis.net/def/trs/BIPM/0/UTC \n             swe:label Sampling Time /swe:label \n             swe:uom xlink:href= http://www.opengis.net/def/uom/ISO-8601/0/Gregorian / \n         /swe:Time \n     /swe:field \n     swe:field name= stationID \n         swe:Text definition= http://sensorml.com/ont/swe/property/StationID \n             swe:label Station ID /swe:label \n         /swe:Text \n     /swe:field \n     swe:field name= temp \n         swe:Quantity definition= http://sensorml.com/ont/swe/property/Temperature \n             swe:label Air Temperature /swe:label \n             swe:uom code= degF / \n         /swe:Quantity \n     /swe:field \n     swe:field name= humidity \n         swe:Quantity definition= http://sensorml.com/ont/swe/property/HumidityValue \n             swe:label Relative Humidity /swe:label \n             swe:uom code= % / \n         /swe:Quantity \n     /swe:field \n     swe:field name= press \n         swe:Quantity definition= http://sensorml.com/ont/swe/property/AirPressureValue \n             swe:label Atmospheric Pressure /swe:label \n             swe:uom code= [in_i]Hg / \n         /swe:Quantity \n     /swe:field  /swe:DataRecord   Notice the field `stationID' whose value would be the ID of the entity/station that generated the record.", 
            "title": "Network Output"
        }, 
        {
            "location": "/apidocs/", 
            "text": "", 
            "title": "Javadoc"
        }, 
        {
            "location": "/dev/android/", 
            "text": "OpenSensorHub on Android\n\n\nThe core modules of OpenSensorHub (OSH) can run natively on Android 5.0 (Lollipop) and later versions. We are also working on a working version for Android 4.4 (KitKat).\n\n\nAndroid support is still experimental at this stage although it is already functional to send phone sensor data to a remote OSH node.\n\n\nThe Android specific part is composed of a Service component that wraps the OSH engine and an demo application that can be configured to send data from one or more phone sensors to the SOS server of a remote OSH node. \n\n\nAndroid Build\n\n\nAndroid code is not built with Maven for now, but using the Eclipse ADT plugin. In order to build it yourself, follow these instructions:\n\n\n\n\n\n\nFirst follow the main \nDeveloper's Guide\n to clone and build projects in \nosh-core\n and \nosh-sensors\n repositories\n\n\n\n\n\n\nInstall the ADT plugin for Eclipse if you haven't already\n\n\n\n\n\n\nClone the \nosh-android\n repo and import all projects into your Eclipse Workspace.\n\n\n\n\n\n\nFrom there on you should be able to build and run the android app on your phone using the \"Run As \n Android Application\" context menu on the \"sensorhub-android-app\" project.", 
            "title": "Android Support"
        }, 
        {
            "location": "/dev/android/#opensensorhub-on-android", 
            "text": "The core modules of OpenSensorHub (OSH) can run natively on Android 5.0 (Lollipop) and later versions. We are also working on a working version for Android 4.4 (KitKat).  Android support is still experimental at this stage although it is already functional to send phone sensor data to a remote OSH node.  The Android specific part is composed of a Service component that wraps the OSH engine and an demo application that can be configured to send data from one or more phone sensors to the SOS server of a remote OSH node.", 
            "title": "OpenSensorHub on Android"
        }, 
        {
            "location": "/dev/android/#android-build", 
            "text": "Android code is not built with Maven for now, but using the Eclipse ADT plugin. In order to build it yourself, follow these instructions:    First follow the main  Developer's Guide  to clone and build projects in  osh-core  and  osh-sensors  repositories    Install the ADT plugin for Eclipse if you haven't already    Clone the  osh-android  repo and import all projects into your Eclipse Workspace.    From there on you should be able to build and run the android app on your phone using the \"Run As   Android Application\" context menu on the \"sensorhub-android-app\" project.", 
            "title": "Android Build"
        }, 
        {
            "location": "/dev/arduino/", 
            "text": "OpenSensorHub and Arduino\n\n\nAlthough OpenSensorHub is Java software and cannot run directly on low power micro-controllers like the ones used on Arduino boards (Atmel), there are several ways one can interface projects developed with Arduino (or other similar frameworks) to OSH.\n\n\nYour options are:\n\n\n\n\n\n\nUsing the OSHClient C++ library on your \u00b5C to connect your project to OSH without writing a single line of Java code\n\n\n\n\n\n\nMaking your \u00b5C software compatible with an existing sensor driver \n\n\n\n\n\n\nWriting a custom OSH driver that can talk to your \u00b5C board in any way you want\n\n\n\n\n\n\nUsing the OSHClient Arduino library\n\n\nWe have developed a small C++ library that makes it super easy to connect your (sensor related) Arduino project to an OSH node. You can find it on our \nosh-arduino GitHub Repo\n. This library allows you to generate a minimum set of metadata about the sensor(s) you're using, register it with an OSH node, and send your measurement values in the proper format. The communication with OSH uses a standard web service called \nSensor Observation Service\n (SOS) defined by the \nOGC\n.\n\n\nFor instance, with a few lines of code, you create a Sensor object with temperature and pressure measurements:\n\n\nSensor s1;\ns1.setUniqueID(\nurn:osh:nano:temp:001\n);\ns1.setName(\nMy Temp Sensor\n);\ns1.addTimeStampOBC(\nms\n);\ns1.addMeasurement(\ntemp\n, TEMP_URI, \nCel\n, \nAir Temperature\n);\ns1.addMeasurement(\npress\n, PRESS_URI, \nhPa\n, \nAtmospheric Pressure\n);\n\n\n\n\nYou register your sensor on the OSH node with:\n\n\nsos = new SOSClient(client, \nhttp://192.168.0.16:8181/sensorhub/sos\n);\nsos-\nregisterDevice(\ns1);\n\n\n\n\nAnd you publish measurements like this:\n\n\nsos-\nstartMeasurement(\ns1);\nsos-\npushInt(millis());\nsos-\npushFloat(random(15.0, 20.0)); // add random temperature value\nsos-\npushFloat(random(950, 1120));  // add random pressure value\nsos-\nsendMeasurement();\n\n\n\n\nThese last 5 lines are typically called in your loop function to send measurements repeatedly.\n\n\nFor more info, please visit our \nosh-arduino GitHub Repo\n. You will find full examples in the \"examples\" folder of the OSHClient library.\n\n\nConnecting with an Existing Sensor Driver\n\n\nOpenSensorHub's community is continuously adding drivers for supporting various kinds of sensors. Some of these drivers implement generic protocols that could fit the need of your project. If this is the case, you could simply implement the protocol in your \u00b5C software and configure OSH to connect to it.\n\n\nFor instance, the \nosh-sensors\n repo contains a generic NMEA driver, so if your sensor is a GPS or compass, you can connect it to OSH by this means.\n\n\nWriting a Custom Driver\n\n\nThis is the most flexible option but also the one that requires the most work since you have to develop both the \u00b5C software and a sensor driver for OSH written in Java.\n\n\nFortunately, OpenSensorHub already provides some components that you can use on the Java side to ease this process. In particular, low level communication via serial is supported on various platforms via the Java RXTX library, and SPI, I2C, GPIO are supported on Linux via the OpenJDK Device I/O implementation.\n\n\nWe also provide support for wireless protocols such as Bluetooth, Bluetooth LE and WiFi (including device discovery through these channels) so you could also leverage these features in your project.", 
            "title": "Arduino Support"
        }, 
        {
            "location": "/dev/arduino/#opensensorhub-and-arduino", 
            "text": "Although OpenSensorHub is Java software and cannot run directly on low power micro-controllers like the ones used on Arduino boards (Atmel), there are several ways one can interface projects developed with Arduino (or other similar frameworks) to OSH.  Your options are:    Using the OSHClient C++ library on your \u00b5C to connect your project to OSH without writing a single line of Java code    Making your \u00b5C software compatible with an existing sensor driver     Writing a custom OSH driver that can talk to your \u00b5C board in any way you want", 
            "title": "OpenSensorHub and Arduino"
        }, 
        {
            "location": "/dev/arduino/#using-the-oshclient-arduino-library", 
            "text": "We have developed a small C++ library that makes it super easy to connect your (sensor related) Arduino project to an OSH node. You can find it on our  osh-arduino GitHub Repo . This library allows you to generate a minimum set of metadata about the sensor(s) you're using, register it with an OSH node, and send your measurement values in the proper format. The communication with OSH uses a standard web service called  Sensor Observation Service  (SOS) defined by the  OGC .  For instance, with a few lines of code, you create a Sensor object with temperature and pressure measurements:  Sensor s1;\ns1.setUniqueID( urn:osh:nano:temp:001 );\ns1.setName( My Temp Sensor );\ns1.addTimeStampOBC( ms );\ns1.addMeasurement( temp , TEMP_URI,  Cel ,  Air Temperature );\ns1.addMeasurement( press , PRESS_URI,  hPa ,  Atmospheric Pressure );  You register your sensor on the OSH node with:  sos = new SOSClient(client,  http://192.168.0.16:8181/sensorhub/sos );\nsos- registerDevice( s1);  And you publish measurements like this:  sos- startMeasurement( s1);\nsos- pushInt(millis());\nsos- pushFloat(random(15.0, 20.0)); // add random temperature value\nsos- pushFloat(random(950, 1120));  // add random pressure value\nsos- sendMeasurement();  These last 5 lines are typically called in your loop function to send measurements repeatedly.  For more info, please visit our  osh-arduino GitHub Repo . You will find full examples in the \"examples\" folder of the OSHClient library.", 
            "title": "Using the OSHClient Arduino library"
        }, 
        {
            "location": "/dev/arduino/#connecting-with-an-existing-sensor-driver", 
            "text": "OpenSensorHub's community is continuously adding drivers for supporting various kinds of sensors. Some of these drivers implement generic protocols that could fit the need of your project. If this is the case, you could simply implement the protocol in your \u00b5C software and configure OSH to connect to it.  For instance, the  osh-sensors  repo contains a generic NMEA driver, so if your sensor is a GPS or compass, you can connect it to OSH by this means.", 
            "title": "Connecting with an Existing Sensor Driver"
        }, 
        {
            "location": "/dev/arduino/#writing-a-custom-driver", 
            "text": "This is the most flexible option but also the one that requires the most work since you have to develop both the \u00b5C software and a sensor driver for OSH written in Java.  Fortunately, OpenSensorHub already provides some components that you can use on the Java side to ease this process. In particular, low level communication via serial is supported on various platforms via the Java RXTX library, and SPI, I2C, GPIO are supported on Linux via the OpenJDK Device I/O implementation.  We also provide support for wireless protocols such as Bluetooth, Bluetooth LE and WiFi (including device discovery through these channels) so you could also leverage these features in your project.", 
            "title": "Writing a Custom Driver"
        }, 
        {
            "location": "/tutos/adding-new-modules/", 
            "text": "Adding New Modules\n\n\nSo that it can be more easily integrated to OpenSensorHub build process, we advise you to package each OSH module (or set of similar modules) as a separate eclipse project and corresponding Maven module. \n\n\nIf you are using Eclipse with the M2E plugin as described in the \nDeveloper's Guide\n, you can create the new project by following the steps below:\n\n\nCreate a new Maven Eclipse project\n\n\n\n\nRight click in package explorer and select \n\"New \n Other\"\n\n\nGo down to the \n\"Maven\"\n section and select \n\"Maven Project\"\n then click \n\"Next\"\n\n\nCheck \n\"Create a simple project\"\n and click \n\"Next\"\n\n\nSet \nGroupId=\"org.sensorhub\"\n and \nArtifactId=\"sensorhub-{moduletype}-{modulename}\"\n (for instance \nsensorhub-driver-axis\n for an Axis camera driver)\n\n\nFill up the name and description fields with meaningful information\n\n\nSet Parent Project to \nGroupId=\"org.sensorhub\"\n, \nArtifactId=\"sensorhub-all\"\n, \nVersion=0.5\n and click \n\"Finish\"\n\n\n\n\nMove the project inside the sensorhub main folder\n\n\nBy default your project should have been created at the root of the workspace. To move it into the correct sub-folder, follow these steps:\n\n\n\n\nRight click on the newly created project\n\n\nSelect \n\"Refactor \n Move\"\n from the popup menu\n\n\nIn the location field, insert \"osh-xxx/\" before the project name in order to obtain the following path: \n\"path/to/your/workspace/osh-xxx/sensorhub-{moduletype}-{modulename}\"\n \n\n\n\n\nAdd dependency to SensorHub core software module\n\n\n\n\nOpen the \npom.xml\n that was created at the root of the project (It should open in a special editor if the M2E plugin was properly installed)\n\n\nGo to the \n\"Dependencies\"\n tab and click the \n\"Add\"\n button\n\n\nEnter \n\"sensorhub\"\n in the search box (above the Search Results section)\n\n\nWait for results to appear, select \n\"sensorhub-core\"\n in the list and click OK\n\n\nYou can also edit the pom.xml to override the organization and developer name that are inherited from the parent project by putting your own.\n\n\nSave the file and close it \n\n\nDepending on the type of module you develop, you may have to add depencendies to other modules as well, and even to external libraries that you module may depend on.\n\n\n\n\nEnable Git version control\n\n\nTo associate the new project with the Git repository within Eclipse, follow these steps:\n\n\n\n\nRight click on the project and select \n\"Team -\n Share\"\n from the context menu\n\n\nSelect \n\"Git\"\n en click \n\"Next\"\n\n\nCheck \n\"Use or create repository in parent folder of project\"\n so that your new project can be associated to the main sensorhub repository\n\n\nSelect you project in the list and click \n\"Finish\"", 
            "title": "Adding New Modules"
        }, 
        {
            "location": "/tutos/adding-new-modules/#adding-new-modules", 
            "text": "So that it can be more easily integrated to OpenSensorHub build process, we advise you to package each OSH module (or set of similar modules) as a separate eclipse project and corresponding Maven module.   If you are using Eclipse with the M2E plugin as described in the  Developer's Guide , you can create the new project by following the steps below:", 
            "title": "Adding New Modules"
        }, 
        {
            "location": "/tutos/adding-new-modules/#create-a-new-maven-eclipse-project", 
            "text": "Right click in package explorer and select  \"New   Other\"  Go down to the  \"Maven\"  section and select  \"Maven Project\"  then click  \"Next\"  Check  \"Create a simple project\"  and click  \"Next\"  Set  GroupId=\"org.sensorhub\"  and  ArtifactId=\"sensorhub-{moduletype}-{modulename}\"  (for instance  sensorhub-driver-axis  for an Axis camera driver)  Fill up the name and description fields with meaningful information  Set Parent Project to  GroupId=\"org.sensorhub\" ,  ArtifactId=\"sensorhub-all\" ,  Version=0.5  and click  \"Finish\"", 
            "title": "Create a new Maven Eclipse project"
        }, 
        {
            "location": "/tutos/adding-new-modules/#move-the-project-inside-the-sensorhub-main-folder", 
            "text": "By default your project should have been created at the root of the workspace. To move it into the correct sub-folder, follow these steps:   Right click on the newly created project  Select  \"Refactor   Move\"  from the popup menu  In the location field, insert \"osh-xxx/\" before the project name in order to obtain the following path:  \"path/to/your/workspace/osh-xxx/sensorhub-{moduletype}-{modulename}\"", 
            "title": "Move the project inside the sensorhub main folder"
        }, 
        {
            "location": "/tutos/adding-new-modules/#add-dependency-to-sensorhub-core-software-module", 
            "text": "Open the  pom.xml  that was created at the root of the project (It should open in a special editor if the M2E plugin was properly installed)  Go to the  \"Dependencies\"  tab and click the  \"Add\"  button  Enter  \"sensorhub\"  in the search box (above the Search Results section)  Wait for results to appear, select  \"sensorhub-core\"  in the list and click OK  You can also edit the pom.xml to override the organization and developer name that are inherited from the parent project by putting your own.  Save the file and close it   Depending on the type of module you develop, you may have to add depencendies to other modules as well, and even to external libraries that you module may depend on.", 
            "title": "Add dependency to SensorHub core software module"
        }, 
        {
            "location": "/tutos/adding-new-modules/#enable-git-version-control", 
            "text": "To associate the new project with the Git repository within Eclipse, follow these steps:   Right click on the project and select  \"Team -  Share\"  from the context menu  Select  \"Git\"  en click  \"Next\"  Check  \"Use or create repository in parent folder of project\"  so that your new project can be associated to the main sensorhub repository  Select you project in the list and click  \"Finish\"", 
            "title": "Enable Git version control"
        }, 
        {
            "location": "/tutos/your-first-sensor/", 
            "text": "Your First Sensor Driver\n\n\nThis is a tutorial to help you write your first sensor driver, based on the \nFake Weather\n demo module that is provided with SensorHub source and binary releases. You may also find it easier to follow these steps in a \npresentation\n with screenshots that we made during a FOSS4G workshop in July 2015.\n\n\nMaven Project\n\n\nThe first step is to create a new Eclipse Maven project that will contain the new sensor module, as instructed on \nthis page\n. For the sake of coherency, you should name your driver project \nsensorhub-driver-{your_driver_name}\n. In the case of the Fake Weather module, we named it \nsensorhub-driver-fakeweather\n.\n\n\nYou then need to create at least 4 classes to add a new sensor module to the SensorHub system:\n\n\n\n\nThe module configuration class\n\n\nThe main sensor module class\n\n\nAt least one sensor output class\n\n\nThe module descriptor class\n\n\n\n\nThe Module Configuration Class\n\n\nThe sensor module configuration class must be derived from \nSensorConfig\n. You can add any other properties that your sensor needs to be properly configured. This class will be directly initialized by parsing equivalent JSON properties in the main SensorHub configuration file.\n\n\nThe configuration class for the Fake Weather module is \nFakeWeatherConfig\n, where we simply added fields to specify the station location:\n\n\npublic class FakeWeatherConfig extends SensorConfig\n{\n  public double centerLatitude = 34.8038; // in deg\n  public double centerLongitude = -86.7228; // in deg\n  public double centerAltitude = 0.000; // in meters\n}\n\n\n\n\nWe recommend that you use the \n@DisplayInfo\n annotation to provide rendering hints for UI classes. An example of this is shown below:\n\n\npublic class FakeWeatherConfig extends SensorConfig\n{\n  @DisplayInfo(label=\nLatitude\n, desc=\nLatitude of Weather Station\n)\n  public double centerLatitude = 34.8038; // in deg\n\n  @DisplayInfo(label=\nLongitude\n, desc=\nLongitude of Weather Station\n)\n  public double centerLongitude = -86.7228; // in deg\n\n  @DisplayInfo(label=\nAltitude\n, desc=\nAltitude of Weather Station\n)\n  public double centerAltitude = 150.000; // in meters\n}\n\n\n\n\nBelow is a JSON snippet to be included in the main SensorHub configuration file, giving a possible configuration for the Fake Weather module:\n\n\n{\n  \nobjClass\n: \norg.sensorhub.impl.sensor.fakeweather.FakeWeatherConfig\n,\n  \nid\n: \nd136b6ea-3950-4691-bf56-c84ec7d89d73\n,\n  \nname\n: \nFake Weather Sensor\n,\n  \nenabled\n: true,\n  \nmoduleClass\n: \norg.sensorhub.impl.sensor.fakeweather.FakeWeatherSensor\n,\n  \nsensorML\n: null,\n  \nautoActivate\n: true,\n  \nenableHistory\n: false,\n  \nhiddenIO\n: null,\n  \ncenterLatitude\n: 43.6182,\n  \ncenterLongitude\n: 1.4238,\n  \ncenterAltitude\n: 150.0\n}\n\n\n\n\nThe Sensor Module Class\n\n\nThe sensor module class is the main entry point to the sensor driver implementation and must implement the generic \nISensorModule\n interface. You can implement this interface directly but in most cases you should derive from the \nAbstractSensorModule\n class instead since it already provides some functionality common to most sensors. In both cases, your must further specify your class by setting the configuration class that you defined at the previous step as its generic parameter. \n\n\nThis is shown below for the Fake Weather example:\n\n\npublic class FakeWeatherSensor extends AbstractSensorModule\nFakeWeatherConfig\n\n\n\n\n\nThe sensor module class is responsible for creating an output interface object (implementation of \nISensorDataInterface\n) for each sensor ouput and preparing the SensorML description of the sensor.\n\n\nFor the Fake Weather example module, implementation is provided in \nFakeWeatherSensor\n. This module only defines a single output and no control input. The next snippet shows the constructor where the output interface is instantiated, initialized, and appended to the output list using the \naddOutput()\n method provided by \nAbstractSensorModule\n:\n\n\npublic FakeWeatherSensor()\n{\n  dataInterface = new FakeWeatherOutput(this);\n  addOutput(dataInterface, false);\n  dataInterface.init();\n}\n\n\n\n\nThe module \nstart()\n and \nstop()\n methods must also be implemented. They must do all processing needed when the sensor is enabled or disabled respectively. In the case of the Fake Weather module, these methods simply delegate to the output interface since it is this class that actually starts/stops the measurement thread.\n\n\npublic void start() throws SensorHubException\n{\n    dataInterface.start();        \n}\n\npublic void stop() throws SensorHubException\n{\n    dataInterface.stop();\n}\n\n\n\n\nThe Sensor Output Class\n\n\nEach output interface of a sensor must be defined by a class implementing \nISensorDataInterface\n. Just like for the main sensor module class, we provide the \nAbstractSensorOutput\n base class that already implements functionalities common to most sensors, so we highly recommend that you derive from it. For instance, the sole output of the Fake Weather example sensor is defined in the \nFakeWeatherOutput\n class.\n\n\nThe main functions of the sensor output class are to:\n\n\n\n\nDefine the output data structure and encoding\n\n\nProvide the approximate/average sampling time of this output\n\n\nStart/stop measurement collection thread\n\n\nProvide access to the latest measurement record and corresponding time stamp\n\n\n\n\nDefine the output data structure and encoding\n\n\nThe snippet below is extracted from the Fake Weather example and shows how to create the measurement record structure using the \nSWEHelper\n class:\n\n\nprotected void init()\n{\n    SWEHelper fac = new SWEHelper();\n\n    // build SWE Common record structure\n    weatherData = new DataRecordImpl(5);\n    weatherData.setName(getName());\n    weatherData.setDefinition(\nhttp://sensorml.com/ont/swe/property/Weather\n);\n\n    // add time, temperature, pressure, wind speed and wind direction fields\n    weatherData.addComponent(\ntime\n, fac.newTimeStampIsoUTC());\n    weatherData.addComponent(\ntemperature\n, fac.newQuantity(SWEHelper.getPropertyUri(\nAirTemperature\n), \nAir Temperature\n, null, \nCel\n));\n    weatherData.addComponent(\npressure\n, fac.newQuantity(SWEHelper.getPropertyUri(\nAtmosphericPressure\n), \nAir Pressure\n, null, \nhPa\n));\n    weatherData.addComponent(\nwindSpeed\n, fac.newQuantity(SWEHelper.getPropertyUri(\nWindSpeed\n), \nWind Speed\n, null, \nm/s\n));\n\n    // for wind direction, we also specify a reference frame\n    Quantity q = fac.newQuantity(SWEHelper.getPropertyUri(\nWindDirection\n), \nWind Direction\n, null, \ndeg\n);\n    q.setReferenceFrame(\nhttp://sensorml.com/ont/swe/property/NED\n);\n    q.setAxisID(\nz\n);\n    weatherData.addComponent(\nwindDirection\n, q);\n\n    // also generate encoding definition\n    weatherEncoding = fac.newTextEncoding(\n,\n, \n\\n\n);\n}\n\n\n\n\nIn this case, the sensor output is a record composed of the following values:\n\n\n\n\nTime stamp (ISO time stamp expressed in UTC time frame)\n\n\nAir temperature\n\n\nAtmospheric pressure\n\n\nWind speed\n\n\nWind direction (rotation about Z axis of NED frame)\n\n\n\n\nProvide the approximate/average sampling time of this output\n\n\nThis is achieved by implementing a simple method that must return the approximative sampling period (in seconds) of data generated by this output. If the rate is known and quasi constant, the method simply returns a fixed value, as in the Fake Weather example:\n\n\npublic double getAverageSamplingPeriod()\n{\n    // sample every 1 second\n    return 1.0;\n}\n\n\n\n\nWhen the rate is not known a-priori and/or can vary, an average can be computed online (This is what is done in the \nSOS-T Virtual Sensor\n for example since there is no way to know the rate of incoming data in advance).\n\n\nStart/stop measurement collection thread\n\n\nThe measurement thread gets readings from sensor hardware and package them in a \nDataBlock\n. The sensor output must thus provide methods to start/stop the measurement thread and implement the logic for connecting to the sensor and correctly generating the \nDataBlock\n.\n\n\nIn the Fake Weather example, the \nsendMeasurement()\n method is implemented and is called regularly using a Timer thread set to execute at the frequency specified by \ngetAverageSamplingPeriod()\n.\n\n\nprivate void sendMeasurement()\n{\n    // generate new weather values\n    double time = System.currentTimeMillis() / 1000.;\n\n    // temperature; value will increase or decrease by less than 1.0 deg\n    temp += 0.005 * (2.0 *Math.random() - 1.0);\n\n    // pressure; value will increase or decrease by less than 20 hPa\n    pressure += 20. * (2.0 * Math.random() - 1.0);\n\n    // wind speed; keep positive\n    // vary value between +/- 10 m/s\n    speed += 10.0 * (2.0 * Math.random() - 1.0);\n    speed = speed \n 0.0 ? 0.0 : speed;\n\n    // wind direction; keep between 0 and 360 degrees\n    direction += 4.0 * (2.0 * Math.random() - 1.0);\n    direction = direction \n 0.0 ? direction+360.0 : direction;\n    direction = direction \n 360.0 ? direction-360.0 : direction;\n\n    // build and publish datablock\n    DataBlock dataBlock = weatherData.createDataBlock();\n    dataBlock.setDoubleValue(0, time);\n    dataBlock.setDoubleValue(1, temp);\n    dataBlock.setDoubleValue(2, pressure);\n    dataBlock.setDoubleValue(3, speed);\n    dataBlock.setDoubleValue(4, direction);\n\n    // update latest record and send event\n    latestRecord = dataBlock;\n    eventHandler.publishEvent(new SensorDataEvent(time, FakeWeatherOutput.this, dataBlock));\n}\n\nprotected void start()\n{\n    if (timer != null)\n       return;\n    timer = new Timer();\n\n    // start main measurement generation thread\n    TimerTask task = new TimerTask() {\n       public void run()\n       {\n          sendMeasurement();\n       }\n    };\n    timer.scheduleAtFixedRate(task, 0, (long)(getAverageSamplingPeriod()*1000));\n}\n\nprotected void stop()\n{\n    if (timer != null)\n    {\n        timer.cancel();\n        timer = null;\n    }\n}\n\n\n\n\nThe Module Descriptor Class\n\n\nA module descriptor class must be provided to enable automatic discovery of your new module by the SensorHub module registry. By providing a class implementing the \nIModuleProvider\n interface, all SensorHub modules available on the classpath can indeed be discovered using the standard Java \nServiceLoader\n API.\n\n\nThe class provides metadata about the module such as a name, description and version. It also indicates which configuration class and module class make up the module. It should thus point to the classes you created in the first two steps of this tutorial.\n\n\nThe snippet below shows the module descriptor for the Fake Weather sensor module:\n\n\npublic class FakeWeatherModuleDescriptor implements IModuleProvider\n{\n  @Override\n  public String getModuleName()\n  {\n    return \nFake Weather Sensor\n;\n  }\n\n  @Override\n  public String getModuleDescription()\n  {\n    return \nFake weather station with randomly changing measurements\n;\n  }\n\n  @Override\n  public String getModuleVersion()\n  {\n    return \n0.1\n;\n  }\n\n  @Override\n  public String getProviderName()\n  {\n    return \nBotts Innovative Research Inc\n;\n  }\n\n  @Override\n  public Class\n? extends IModule\n?\n getModuleClass()\n  {\n    return FakeWeatherSensor.class;\n  }\n\n  @Override\n  public Class\n? extends ModuleConfig\n getModuleConfigClass()\n  {\n    return FakeWeatherConfig.class;\n  }\n}\n\n\n\n\nIn order to be discoverable by the \nServiceLoader\n API, the module descriptor class also needs to be advertised in a provider-configuration file called \norg.sensorhub.api.module.IModuleProvider\n in the resource directory \nMETA-INF/services\n (see \nServiceLoader\n documentation on Oracle website). For instance, the Fake Weather sensor module includes \nthis file\n file with the following line:\n\n\norg.sensorhub.impl.sensor.fakeweather.FakeWeatherModuleDescriptor", 
            "title": "Your First Sensor"
        }, 
        {
            "location": "/tutos/your-first-sensor/#your-first-sensor-driver", 
            "text": "This is a tutorial to help you write your first sensor driver, based on the  Fake Weather  demo module that is provided with SensorHub source and binary releases. You may also find it easier to follow these steps in a  presentation  with screenshots that we made during a FOSS4G workshop in July 2015.", 
            "title": "Your First Sensor Driver"
        }, 
        {
            "location": "/tutos/your-first-sensor/#maven-project", 
            "text": "The first step is to create a new Eclipse Maven project that will contain the new sensor module, as instructed on  this page . For the sake of coherency, you should name your driver project  sensorhub-driver-{your_driver_name} . In the case of the Fake Weather module, we named it  sensorhub-driver-fakeweather .  You then need to create at least 4 classes to add a new sensor module to the SensorHub system:   The module configuration class  The main sensor module class  At least one sensor output class  The module descriptor class", 
            "title": "Maven Project"
        }, 
        {
            "location": "/tutos/your-first-sensor/#the-module-configuration-class", 
            "text": "The sensor module configuration class must be derived from  SensorConfig . You can add any other properties that your sensor needs to be properly configured. This class will be directly initialized by parsing equivalent JSON properties in the main SensorHub configuration file.  The configuration class for the Fake Weather module is  FakeWeatherConfig , where we simply added fields to specify the station location:  public class FakeWeatherConfig extends SensorConfig\n{\n  public double centerLatitude = 34.8038; // in deg\n  public double centerLongitude = -86.7228; // in deg\n  public double centerAltitude = 0.000; // in meters\n}  We recommend that you use the  @DisplayInfo  annotation to provide rendering hints for UI classes. An example of this is shown below:  public class FakeWeatherConfig extends SensorConfig\n{\n  @DisplayInfo(label= Latitude , desc= Latitude of Weather Station )\n  public double centerLatitude = 34.8038; // in deg\n\n  @DisplayInfo(label= Longitude , desc= Longitude of Weather Station )\n  public double centerLongitude = -86.7228; // in deg\n\n  @DisplayInfo(label= Altitude , desc= Altitude of Weather Station )\n  public double centerAltitude = 150.000; // in meters\n}  Below is a JSON snippet to be included in the main SensorHub configuration file, giving a possible configuration for the Fake Weather module:  {\n   objClass :  org.sensorhub.impl.sensor.fakeweather.FakeWeatherConfig ,\n   id :  d136b6ea-3950-4691-bf56-c84ec7d89d73 ,\n   name :  Fake Weather Sensor ,\n   enabled : true,\n   moduleClass :  org.sensorhub.impl.sensor.fakeweather.FakeWeatherSensor ,\n   sensorML : null,\n   autoActivate : true,\n   enableHistory : false,\n   hiddenIO : null,\n   centerLatitude : 43.6182,\n   centerLongitude : 1.4238,\n   centerAltitude : 150.0\n}", 
            "title": "The Module Configuration Class"
        }, 
        {
            "location": "/tutos/your-first-sensor/#the-sensor-module-class", 
            "text": "The sensor module class is the main entry point to the sensor driver implementation and must implement the generic  ISensorModule  interface. You can implement this interface directly but in most cases you should derive from the  AbstractSensorModule  class instead since it already provides some functionality common to most sensors. In both cases, your must further specify your class by setting the configuration class that you defined at the previous step as its generic parameter.   This is shown below for the Fake Weather example:  public class FakeWeatherSensor extends AbstractSensorModule FakeWeatherConfig   The sensor module class is responsible for creating an output interface object (implementation of  ISensorDataInterface ) for each sensor ouput and preparing the SensorML description of the sensor.  For the Fake Weather example module, implementation is provided in  FakeWeatherSensor . This module only defines a single output and no control input. The next snippet shows the constructor where the output interface is instantiated, initialized, and appended to the output list using the  addOutput()  method provided by  AbstractSensorModule :  public FakeWeatherSensor()\n{\n  dataInterface = new FakeWeatherOutput(this);\n  addOutput(dataInterface, false);\n  dataInterface.init();\n}  The module  start()  and  stop()  methods must also be implemented. They must do all processing needed when the sensor is enabled or disabled respectively. In the case of the Fake Weather module, these methods simply delegate to the output interface since it is this class that actually starts/stops the measurement thread.  public void start() throws SensorHubException\n{\n    dataInterface.start();        \n}\n\npublic void stop() throws SensorHubException\n{\n    dataInterface.stop();\n}", 
            "title": "The Sensor Module Class"
        }, 
        {
            "location": "/tutos/your-first-sensor/#the-sensor-output-class", 
            "text": "Each output interface of a sensor must be defined by a class implementing  ISensorDataInterface . Just like for the main sensor module class, we provide the  AbstractSensorOutput  base class that already implements functionalities common to most sensors, so we highly recommend that you derive from it. For instance, the sole output of the Fake Weather example sensor is defined in the  FakeWeatherOutput  class.  The main functions of the sensor output class are to:   Define the output data structure and encoding  Provide the approximate/average sampling time of this output  Start/stop measurement collection thread  Provide access to the latest measurement record and corresponding time stamp", 
            "title": "The Sensor Output Class"
        }, 
        {
            "location": "/tutos/your-first-sensor/#define-the-output-data-structure-and-encoding", 
            "text": "The snippet below is extracted from the Fake Weather example and shows how to create the measurement record structure using the  SWEHelper  class:  protected void init()\n{\n    SWEHelper fac = new SWEHelper();\n\n    // build SWE Common record structure\n    weatherData = new DataRecordImpl(5);\n    weatherData.setName(getName());\n    weatherData.setDefinition( http://sensorml.com/ont/swe/property/Weather );\n\n    // add time, temperature, pressure, wind speed and wind direction fields\n    weatherData.addComponent( time , fac.newTimeStampIsoUTC());\n    weatherData.addComponent( temperature , fac.newQuantity(SWEHelper.getPropertyUri( AirTemperature ),  Air Temperature , null,  Cel ));\n    weatherData.addComponent( pressure , fac.newQuantity(SWEHelper.getPropertyUri( AtmosphericPressure ),  Air Pressure , null,  hPa ));\n    weatherData.addComponent( windSpeed , fac.newQuantity(SWEHelper.getPropertyUri( WindSpeed ),  Wind Speed , null,  m/s ));\n\n    // for wind direction, we also specify a reference frame\n    Quantity q = fac.newQuantity(SWEHelper.getPropertyUri( WindDirection ),  Wind Direction , null,  deg );\n    q.setReferenceFrame( http://sensorml.com/ont/swe/property/NED );\n    q.setAxisID( z );\n    weatherData.addComponent( windDirection , q);\n\n    // also generate encoding definition\n    weatherEncoding = fac.newTextEncoding( , ,  \\n );\n}  In this case, the sensor output is a record composed of the following values:   Time stamp (ISO time stamp expressed in UTC time frame)  Air temperature  Atmospheric pressure  Wind speed  Wind direction (rotation about Z axis of NED frame)", 
            "title": "Define the output data structure and encoding"
        }, 
        {
            "location": "/tutos/your-first-sensor/#provide-the-approximateaverage-sampling-time-of-this-output", 
            "text": "This is achieved by implementing a simple method that must return the approximative sampling period (in seconds) of data generated by this output. If the rate is known and quasi constant, the method simply returns a fixed value, as in the Fake Weather example:  public double getAverageSamplingPeriod()\n{\n    // sample every 1 second\n    return 1.0;\n}  When the rate is not known a-priori and/or can vary, an average can be computed online (This is what is done in the  SOS-T Virtual Sensor  for example since there is no way to know the rate of incoming data in advance).", 
            "title": "Provide the approximate/average sampling time of this output"
        }, 
        {
            "location": "/tutos/your-first-sensor/#startstop-measurement-collection-thread", 
            "text": "The measurement thread gets readings from sensor hardware and package them in a  DataBlock . The sensor output must thus provide methods to start/stop the measurement thread and implement the logic for connecting to the sensor and correctly generating the  DataBlock .  In the Fake Weather example, the  sendMeasurement()  method is implemented and is called regularly using a Timer thread set to execute at the frequency specified by  getAverageSamplingPeriod() .  private void sendMeasurement()\n{\n    // generate new weather values\n    double time = System.currentTimeMillis() / 1000.;\n\n    // temperature; value will increase or decrease by less than 1.0 deg\n    temp += 0.005 * (2.0 *Math.random() - 1.0);\n\n    // pressure; value will increase or decrease by less than 20 hPa\n    pressure += 20. * (2.0 * Math.random() - 1.0);\n\n    // wind speed; keep positive\n    // vary value between +/- 10 m/s\n    speed += 10.0 * (2.0 * Math.random() - 1.0);\n    speed = speed   0.0 ? 0.0 : speed;\n\n    // wind direction; keep between 0 and 360 degrees\n    direction += 4.0 * (2.0 * Math.random() - 1.0);\n    direction = direction   0.0 ? direction+360.0 : direction;\n    direction = direction   360.0 ? direction-360.0 : direction;\n\n    // build and publish datablock\n    DataBlock dataBlock = weatherData.createDataBlock();\n    dataBlock.setDoubleValue(0, time);\n    dataBlock.setDoubleValue(1, temp);\n    dataBlock.setDoubleValue(2, pressure);\n    dataBlock.setDoubleValue(3, speed);\n    dataBlock.setDoubleValue(4, direction);\n\n    // update latest record and send event\n    latestRecord = dataBlock;\n    eventHandler.publishEvent(new SensorDataEvent(time, FakeWeatherOutput.this, dataBlock));\n}\n\nprotected void start()\n{\n    if (timer != null)\n       return;\n    timer = new Timer();\n\n    // start main measurement generation thread\n    TimerTask task = new TimerTask() {\n       public void run()\n       {\n          sendMeasurement();\n       }\n    };\n    timer.scheduleAtFixedRate(task, 0, (long)(getAverageSamplingPeriod()*1000));\n}\n\nprotected void stop()\n{\n    if (timer != null)\n    {\n        timer.cancel();\n        timer = null;\n    }\n}", 
            "title": "Start/stop measurement collection thread"
        }, 
        {
            "location": "/tutos/your-first-sensor/#the-module-descriptor-class", 
            "text": "A module descriptor class must be provided to enable automatic discovery of your new module by the SensorHub module registry. By providing a class implementing the  IModuleProvider  interface, all SensorHub modules available on the classpath can indeed be discovered using the standard Java  ServiceLoader  API.  The class provides metadata about the module such as a name, description and version. It also indicates which configuration class and module class make up the module. It should thus point to the classes you created in the first two steps of this tutorial.  The snippet below shows the module descriptor for the Fake Weather sensor module:  public class FakeWeatherModuleDescriptor implements IModuleProvider\n{\n  @Override\n  public String getModuleName()\n  {\n    return  Fake Weather Sensor ;\n  }\n\n  @Override\n  public String getModuleDescription()\n  {\n    return  Fake weather station with randomly changing measurements ;\n  }\n\n  @Override\n  public String getModuleVersion()\n  {\n    return  0.1 ;\n  }\n\n  @Override\n  public String getProviderName()\n  {\n    return  Botts Innovative Research Inc ;\n  }\n\n  @Override\n  public Class ? extends IModule ?  getModuleClass()\n  {\n    return FakeWeatherSensor.class;\n  }\n\n  @Override\n  public Class ? extends ModuleConfig  getModuleConfigClass()\n  {\n    return FakeWeatherConfig.class;\n  }\n}  In order to be discoverable by the  ServiceLoader  API, the module descriptor class also needs to be advertised in a provider-configuration file called  org.sensorhub.api.module.IModuleProvider  in the resource directory  META-INF/services  (see  ServiceLoader  documentation on Oracle website). For instance, the Fake Weather sensor module includes  this file  file with the following line:  org.sensorhub.impl.sensor.fakeweather.FakeWeatherModuleDescriptor", 
            "title": "The Module Descriptor Class"
        }, 
        {
            "location": "/license/", 
            "text": "License\n\n\nOpenSensorHub is licensed under the Mozilla Public License, version 2.0, whose terms are as follows:\n\n\n\nMozilla Public License, version 2.0\n\n1. Definitions\n\n1.1. \"Contributor\"\n\n     means each individual or legal entity that creates, contributes to the\n     creation of, or owns Covered Software.\n\n1.2. \"Contributor Version\"\n\n     means the combination of the Contributions of others (if any) used by a\n     Contributor and that particular Contributor's Contribution.\n\n1.3. \"Contribution\"\n\n     means Covered Software of a particular Contributor.\n\n1.4. \"Covered Software\"\n\n     means Source Code Form to which the initial Contributor has attached the\n     notice in Exhibit A, the Executable Form of such Source Code Form, and\n     Modifications of such Source Code Form, in each case including portions\n     thereof.\n\n1.5. \"Incompatible With Secondary Licenses\"\n     means\n\n     a. that the initial Contributor has attached the notice described in\n        Exhibit B to the Covered Software; or\n\n     b. that the Covered Software was made available under the terms of\n        version 1.1 or earlier of the License, but not also under the terms of\n        a Secondary License.\n\n1.6. \"Executable Form\"\n\n     means any form of the work other than Source Code Form.\n\n1.7. \"Larger Work\"\n\n     means a work that combines Covered Software with other material, in a\n     separate file or files, that is not Covered Software.\n\n1.8. \"License\"\n\n     means this document.\n\n1.9. \"Licensable\"\n\n     means having the right to grant, to the maximum extent possible, whether\n     at the time of the initial grant or subsequently, any and all of the\n     rights conveyed by this License.\n\n1.10. \"Modifications\"\n\n     means any of the following:\n\n     a. any file in Source Code Form that results from an addition to,\n        deletion from, or modification of the contents of Covered Software; or\n\n     b. any new file in Source Code Form that contains any Covered Software.\n\n1.11. \"Patent Claims\" of a Contributor\n\n      means any patent claim(s), including without limitation, method,\n      process, and apparatus claims, in any patent Licensable by such\n      Contributor that would be infringed, but for the grant of the License,\n      by the making, using, selling, offering for sale, having made, import,\n      or transfer of either its Contributions or its Contributor Version.\n\n1.12. \"Secondary License\"\n\n      means either the GNU General Public License, Version 2.0, the GNU Lesser\n      General Public License, Version 2.1, the GNU Affero General Public\n      License, Version 3.0, or any later versions of those licenses.\n\n1.13. \"Source Code Form\"\n\n      means the form of the work preferred for making modifications.\n\n1.14. \"You\" (or \"Your\")\n\n      means an individual or a legal entity exercising rights under this\n      License. For legal entities, \"You\" includes any entity that controls, is\n      controlled by, or is under common control with You. For purposes of this\n      definition, \"control\" means (a) the power, direct or indirect, to cause\n      the direction or management of such entity, whether by contract or\n      otherwise, or (b) ownership of more than fifty percent (50%) of the\n      outstanding shares or beneficial ownership of such entity.\n\n\n2. License Grants and Conditions\n\n2.1. Grants\n\n     Each Contributor hereby grants You a world-wide, royalty-free,\n     non-exclusive license:\n\n     a. under intellectual property rights (other than patent or trademark)\n        Licensable by such Contributor to use, reproduce, make available,\n        modify, display, perform, distribute, and otherwise exploit its\n        Contributions, either on an unmodified basis, with Modifications, or\n        as part of a Larger Work; and\n\n     b. under Patent Claims of such Contributor to make, use, sell, offer for\n        sale, have made, import, and otherwise transfer either its\n        Contributions or its Contributor Version.\n\n2.2. Effective Date\n\n     The licenses granted in Section 2.1 with respect to any Contribution\n     become effective for each Contribution on the date the Contributor first\n     distributes such Contribution.\n\n2.3. Limitations on Grant Scope\n\n     The licenses granted in this Section 2 are the only rights granted under\n     this License. No additional rights or licenses will be implied from the\n     distribution or licensing of Covered Software under this License.\n     Notwithstanding Section 2.1(b) above, no patent license is granted by a\n     Contributor:\n\n     a. for any code that a Contributor has removed from Covered Software; or\n\n     b. for infringements caused by: (i) Your and any other third party's\n        modifications of Covered Software, or (ii) the combination of its\n        Contributions with other software (except as part of its Contributor\n        Version); or\n\n     c. under Patent Claims infringed by Covered Software in the absence of\n        its Contributions.\n\n     This License does not grant any rights in the trademarks, service marks,\n     or logos of any Contributor (except as may be necessary to comply with\n     the notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\n     No Contributor makes additional grants as a result of Your choice to\n     distribute the Covered Software under a subsequent version of this\n     License (see Section 10.2) or under the terms of a Secondary License (if\n     permitted under the terms of Section 3.3).\n\n2.5. Representation\n\n     Each Contributor represents that the Contributor believes its\n     Contributions are its original creation(s) or it has sufficient rights to\n     grant the rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\n     This License is not intended to limit any rights You have under\n     applicable copyright doctrines of fair use, fair dealing, or other\n     equivalents.\n\n2.7. Conditions\n\n     Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in\n     Section 2.1.\n\n\n3. Responsibilities\n\n3.1. Distribution of Source Form\n\n     All distribution of Covered Software in Source Code Form, including any\n     Modifications that You create or to which You contribute, must be under\n     the terms of this License. You must inform recipients that the Source\n     Code Form of the Covered Software is governed by the terms of this\n     License, and how they can obtain a copy of this License. You may not\n     attempt to alter or restrict the recipients' rights in the Source Code\n     Form.\n\n3.2. Distribution of Executable Form\n\n     If You distribute Covered Software in Executable Form then:\n\n     a. such Covered Software must also be made available in Source Code Form,\n        as described in Section 3.1, and You must inform recipients of the\n        Executable Form how they can obtain a copy of such Source Code Form by\n        reasonable means in a timely manner, at a charge no more than the cost\n        of distribution to the recipient; and\n\n     b. You may distribute such Executable Form under the terms of this\n        License, or sublicense it under different terms, provided that the\n        license for the Executable Form does not attempt to limit or alter the\n        recipients' rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\n     You may create and distribute a Larger Work under terms of Your choice,\n     provided that You also comply with the requirements of this License for\n     the Covered Software. If the Larger Work is a combination of Covered\n     Software with a work governed by one or more Secondary Licenses, and the\n     Covered Software is not Incompatible With Secondary Licenses, this\n     License permits You to additionally distribute such Covered Software\n     under the terms of such Secondary License(s), so that the recipient of\n     the Larger Work may, at their option, further distribute the Covered\n     Software under the terms of either this License or such Secondary\n     License(s).\n\n3.4. Notices\n\n     You may not remove or alter the substance of any license notices\n     (including copyright notices, patent notices, disclaimers of warranty, or\n     limitations of liability) contained within the Source Code Form of the\n     Covered Software, except that You may alter any license notices to the\n     extent required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\n     You may choose to offer, and to charge a fee for, warranty, support,\n     indemnity or liability obligations to one or more recipients of Covered\n     Software. However, You may do so only on Your own behalf, and not on\n     behalf of any Contributor. You must make it absolutely clear that any\n     such warranty, support, indemnity, or liability obligation is offered by\n     You alone, and You hereby agree to indemnify every Contributor for any\n     liability incurred by such Contributor as a result of warranty, support,\n     indemnity or liability terms You offer. You may include additional\n     disclaimers of warranty and limitations of liability specific to any\n     jurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n\n   If it is impossible for You to comply with any of the terms of this License\n   with respect to some or all of the Covered Software due to statute,\n   judicial order, or regulation then You must: (a) comply with the terms of\n   this License to the maximum extent possible; and (b) describe the\n   limitations and the code they affect. Such description must be placed in a\n   text file included with all distributions of the Covered Software under\n   this License. Except to the extent prohibited by statute or regulation,\n   such description must be sufficiently detailed for a recipient of ordinary\n   skill to be able to understand it.\n\n5. Termination\n\n5.1. The rights granted under this License will terminate automatically if You\n     fail to comply with any of its terms. However, if You become compliant,\n     then the rights granted under this License from a particular Contributor\n     are reinstated (a) provisionally, unless and until such Contributor\n     explicitly and finally terminates Your grants, and (b) on an ongoing\n     basis, if such Contributor fails to notify You of the non-compliance by\n     some reasonable means prior to 60 days after You have come back into\n     compliance. Moreover, Your grants from a particular Contributor are\n     reinstated on an ongoing basis if such Contributor notifies You of the\n     non-compliance by some reasonable means, this is the first time You have\n     received notice of non-compliance with this License from such\n     Contributor, and You become compliant prior to 30 days after Your receipt\n     of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\n     infringement claim (excluding declaratory judgment actions,\n     counter-claims, and cross-claims) alleging that a Contributor Version\n     directly or indirectly infringes any patent, then the rights granted to\n     You by any and all Contributors for the Covered Software under Section\n     2.1 of this License shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user\n     license agreements (excluding distributors and resellers) which have been\n     validly granted by You or Your distributors under this License prior to\n     termination shall survive termination.\n\n6. Disclaimer of Warranty\n\n   Covered Software is provided under this License on an \"as is\" basis,\n   without warranty of any kind, either expressed, implied, or statutory,\n   including, without limitation, warranties that the Covered Software is free\n   of defects, merchantable, fit for a particular purpose or non-infringing.\n   The entire risk as to the quality and performance of the Covered Software\n   is with You. Should any Covered Software prove defective in any respect,\n   You (not any Contributor) assume the cost of any necessary servicing,\n   repair, or correction. This disclaimer of warranty constitutes an essential\n   part of this License. No use of  any Covered Software is authorized under\n   this License except under this disclaimer.\n\n7. Limitation of Liability\n\n   Under no circumstances and under no legal theory, whether tort (including\n   negligence), contract, or otherwise, shall any Contributor, or anyone who\n   distributes Covered Software as permitted above, be liable to You for any\n   direct, indirect, special, incidental, or consequential damages of any\n   character including, without limitation, damages for lost profits, loss of\n   goodwill, work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses, even if such party shall have been\n   informed of the possibility of such damages. This limitation of liability\n   shall not apply to liability for death or personal injury resulting from\n   such party's negligence to the extent applicable law prohibits such\n   limitation. Some jurisdictions do not allow the exclusion or limitation of\n   incidental or consequential damages, so this exclusion and limitation may\n   not apply to You.\n\n8. Litigation\n\n   Any litigation relating to this License may be brought only in the courts\n   of a jurisdiction where the defendant maintains its principal place of\n   business and such litigation shall be governed by laws of that\n   jurisdiction, without reference to its conflict-of-law provisions. Nothing\n   in this Section shall prevent a party's ability to bring cross-claims or\n   counter-claims.\n\n9. Miscellaneous\n\n   This License represents the complete agreement concerning the subject\n   matter hereof. If any provision of this License is held to be\n   unenforceable, such provision shall be reformed only to the extent\n   necessary to make it enforceable. Any law or regulation which provides that\n   the language of a contract shall be construed against the drafter shall not\n   be used to construe this License against a Contributor.\n\n\n10. Versions of the License\n\n10.1. New Versions\n\n      Mozilla Foundation is the license steward. Except as provided in Section\n      10.3, no one other than the license steward has the right to modify or\n      publish new versions of this License. Each version will be given a\n      distinguishing version number.\n\n10.2. Effect of New Versions\n\n      You may distribute the Covered Software under the terms of the version\n      of the License under which You originally received the Covered Software,\n      or under the terms of any subsequent version published by the license\n      steward.\n\n10.3. Modified Versions\n\n      If you create software not governed by this License, and you want to\n      create a new license for such software, you may create and use a\n      modified version of this License if you rename the license and remove\n      any references to the name of the license steward (except to note that\n      such modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary\n      Licenses If You choose to distribute Source Code Form that is\n      Incompatible With Secondary Licenses under the terms of this version of\n      the License, the notice described in Exhibit B of this License must be\n      attached.\n\nExhibit A - Source Code Form License Notice\n\n      This Source Code Form is subject to the\n      terms of the Mozilla Public License, v.\n      2.0. If a copy of the MPL was not\n      distributed with this file, You can\n      obtain one at\n      http://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular file,\nthen You may include the notice in a location (such as a LICENSE file in a\nrelevant directory) where a recipient would be likely to look for such a\nnotice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - \"Incompatible With Secondary Licenses\" Notice\n\n      This Source Code Form is \"Incompatible\n      With Secondary Licenses\", as defined by\n      the Mozilla Public License, v. 2.0.", 
            "title": "License"
        }, 
        {
            "location": "/license/#license", 
            "text": "OpenSensorHub is licensed under the Mozilla Public License, version 2.0, whose terms are as follows:  \nMozilla Public License, version 2.0\n\n1. Definitions\n\n1.1. \"Contributor\"\n\n     means each individual or legal entity that creates, contributes to the\n     creation of, or owns Covered Software.\n\n1.2. \"Contributor Version\"\n\n     means the combination of the Contributions of others (if any) used by a\n     Contributor and that particular Contributor's Contribution.\n\n1.3. \"Contribution\"\n\n     means Covered Software of a particular Contributor.\n\n1.4. \"Covered Software\"\n\n     means Source Code Form to which the initial Contributor has attached the\n     notice in Exhibit A, the Executable Form of such Source Code Form, and\n     Modifications of such Source Code Form, in each case including portions\n     thereof.\n\n1.5. \"Incompatible With Secondary Licenses\"\n     means\n\n     a. that the initial Contributor has attached the notice described in\n        Exhibit B to the Covered Software; or\n\n     b. that the Covered Software was made available under the terms of\n        version 1.1 or earlier of the License, but not also under the terms of\n        a Secondary License.\n\n1.6. \"Executable Form\"\n\n     means any form of the work other than Source Code Form.\n\n1.7. \"Larger Work\"\n\n     means a work that combines Covered Software with other material, in a\n     separate file or files, that is not Covered Software.\n\n1.8. \"License\"\n\n     means this document.\n\n1.9. \"Licensable\"\n\n     means having the right to grant, to the maximum extent possible, whether\n     at the time of the initial grant or subsequently, any and all of the\n     rights conveyed by this License.\n\n1.10. \"Modifications\"\n\n     means any of the following:\n\n     a. any file in Source Code Form that results from an addition to,\n        deletion from, or modification of the contents of Covered Software; or\n\n     b. any new file in Source Code Form that contains any Covered Software.\n\n1.11. \"Patent Claims\" of a Contributor\n\n      means any patent claim(s), including without limitation, method,\n      process, and apparatus claims, in any patent Licensable by such\n      Contributor that would be infringed, but for the grant of the License,\n      by the making, using, selling, offering for sale, having made, import,\n      or transfer of either its Contributions or its Contributor Version.\n\n1.12. \"Secondary License\"\n\n      means either the GNU General Public License, Version 2.0, the GNU Lesser\n      General Public License, Version 2.1, the GNU Affero General Public\n      License, Version 3.0, or any later versions of those licenses.\n\n1.13. \"Source Code Form\"\n\n      means the form of the work preferred for making modifications.\n\n1.14. \"You\" (or \"Your\")\n\n      means an individual or a legal entity exercising rights under this\n      License. For legal entities, \"You\" includes any entity that controls, is\n      controlled by, or is under common control with You. For purposes of this\n      definition, \"control\" means (a) the power, direct or indirect, to cause\n      the direction or management of such entity, whether by contract or\n      otherwise, or (b) ownership of more than fifty percent (50%) of the\n      outstanding shares or beneficial ownership of such entity.\n\n\n2. License Grants and Conditions\n\n2.1. Grants\n\n     Each Contributor hereby grants You a world-wide, royalty-free,\n     non-exclusive license:\n\n     a. under intellectual property rights (other than patent or trademark)\n        Licensable by such Contributor to use, reproduce, make available,\n        modify, display, perform, distribute, and otherwise exploit its\n        Contributions, either on an unmodified basis, with Modifications, or\n        as part of a Larger Work; and\n\n     b. under Patent Claims of such Contributor to make, use, sell, offer for\n        sale, have made, import, and otherwise transfer either its\n        Contributions or its Contributor Version.\n\n2.2. Effective Date\n\n     The licenses granted in Section 2.1 with respect to any Contribution\n     become effective for each Contribution on the date the Contributor first\n     distributes such Contribution.\n\n2.3. Limitations on Grant Scope\n\n     The licenses granted in this Section 2 are the only rights granted under\n     this License. No additional rights or licenses will be implied from the\n     distribution or licensing of Covered Software under this License.\n     Notwithstanding Section 2.1(b) above, no patent license is granted by a\n     Contributor:\n\n     a. for any code that a Contributor has removed from Covered Software; or\n\n     b. for infringements caused by: (i) Your and any other third party's\n        modifications of Covered Software, or (ii) the combination of its\n        Contributions with other software (except as part of its Contributor\n        Version); or\n\n     c. under Patent Claims infringed by Covered Software in the absence of\n        its Contributions.\n\n     This License does not grant any rights in the trademarks, service marks,\n     or logos of any Contributor (except as may be necessary to comply with\n     the notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\n     No Contributor makes additional grants as a result of Your choice to\n     distribute the Covered Software under a subsequent version of this\n     License (see Section 10.2) or under the terms of a Secondary License (if\n     permitted under the terms of Section 3.3).\n\n2.5. Representation\n\n     Each Contributor represents that the Contributor believes its\n     Contributions are its original creation(s) or it has sufficient rights to\n     grant the rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\n     This License is not intended to limit any rights You have under\n     applicable copyright doctrines of fair use, fair dealing, or other\n     equivalents.\n\n2.7. Conditions\n\n     Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in\n     Section 2.1.\n\n\n3. Responsibilities\n\n3.1. Distribution of Source Form\n\n     All distribution of Covered Software in Source Code Form, including any\n     Modifications that You create or to which You contribute, must be under\n     the terms of this License. You must inform recipients that the Source\n     Code Form of the Covered Software is governed by the terms of this\n     License, and how they can obtain a copy of this License. You may not\n     attempt to alter or restrict the recipients' rights in the Source Code\n     Form.\n\n3.2. Distribution of Executable Form\n\n     If You distribute Covered Software in Executable Form then:\n\n     a. such Covered Software must also be made available in Source Code Form,\n        as described in Section 3.1, and You must inform recipients of the\n        Executable Form how they can obtain a copy of such Source Code Form by\n        reasonable means in a timely manner, at a charge no more than the cost\n        of distribution to the recipient; and\n\n     b. You may distribute such Executable Form under the terms of this\n        License, or sublicense it under different terms, provided that the\n        license for the Executable Form does not attempt to limit or alter the\n        recipients' rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\n     You may create and distribute a Larger Work under terms of Your choice,\n     provided that You also comply with the requirements of this License for\n     the Covered Software. If the Larger Work is a combination of Covered\n     Software with a work governed by one or more Secondary Licenses, and the\n     Covered Software is not Incompatible With Secondary Licenses, this\n     License permits You to additionally distribute such Covered Software\n     under the terms of such Secondary License(s), so that the recipient of\n     the Larger Work may, at their option, further distribute the Covered\n     Software under the terms of either this License or such Secondary\n     License(s).\n\n3.4. Notices\n\n     You may not remove or alter the substance of any license notices\n     (including copyright notices, patent notices, disclaimers of warranty, or\n     limitations of liability) contained within the Source Code Form of the\n     Covered Software, except that You may alter any license notices to the\n     extent required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\n     You may choose to offer, and to charge a fee for, warranty, support,\n     indemnity or liability obligations to one or more recipients of Covered\n     Software. However, You may do so only on Your own behalf, and not on\n     behalf of any Contributor. You must make it absolutely clear that any\n     such warranty, support, indemnity, or liability obligation is offered by\n     You alone, and You hereby agree to indemnify every Contributor for any\n     liability incurred by such Contributor as a result of warranty, support,\n     indemnity or liability terms You offer. You may include additional\n     disclaimers of warranty and limitations of liability specific to any\n     jurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n\n   If it is impossible for You to comply with any of the terms of this License\n   with respect to some or all of the Covered Software due to statute,\n   judicial order, or regulation then You must: (a) comply with the terms of\n   this License to the maximum extent possible; and (b) describe the\n   limitations and the code they affect. Such description must be placed in a\n   text file included with all distributions of the Covered Software under\n   this License. Except to the extent prohibited by statute or regulation,\n   such description must be sufficiently detailed for a recipient of ordinary\n   skill to be able to understand it.\n\n5. Termination\n\n5.1. The rights granted under this License will terminate automatically if You\n     fail to comply with any of its terms. However, if You become compliant,\n     then the rights granted under this License from a particular Contributor\n     are reinstated (a) provisionally, unless and until such Contributor\n     explicitly and finally terminates Your grants, and (b) on an ongoing\n     basis, if such Contributor fails to notify You of the non-compliance by\n     some reasonable means prior to 60 days after You have come back into\n     compliance. Moreover, Your grants from a particular Contributor are\n     reinstated on an ongoing basis if such Contributor notifies You of the\n     non-compliance by some reasonable means, this is the first time You have\n     received notice of non-compliance with this License from such\n     Contributor, and You become compliant prior to 30 days after Your receipt\n     of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\n     infringement claim (excluding declaratory judgment actions,\n     counter-claims, and cross-claims) alleging that a Contributor Version\n     directly or indirectly infringes any patent, then the rights granted to\n     You by any and all Contributors for the Covered Software under Section\n     2.1 of this License shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user\n     license agreements (excluding distributors and resellers) which have been\n     validly granted by You or Your distributors under this License prior to\n     termination shall survive termination.\n\n6. Disclaimer of Warranty\n\n   Covered Software is provided under this License on an \"as is\" basis,\n   without warranty of any kind, either expressed, implied, or statutory,\n   including, without limitation, warranties that the Covered Software is free\n   of defects, merchantable, fit for a particular purpose or non-infringing.\n   The entire risk as to the quality and performance of the Covered Software\n   is with You. Should any Covered Software prove defective in any respect,\n   You (not any Contributor) assume the cost of any necessary servicing,\n   repair, or correction. This disclaimer of warranty constitutes an essential\n   part of this License. No use of  any Covered Software is authorized under\n   this License except under this disclaimer.\n\n7. Limitation of Liability\n\n   Under no circumstances and under no legal theory, whether tort (including\n   negligence), contract, or otherwise, shall any Contributor, or anyone who\n   distributes Covered Software as permitted above, be liable to You for any\n   direct, indirect, special, incidental, or consequential damages of any\n   character including, without limitation, damages for lost profits, loss of\n   goodwill, work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses, even if such party shall have been\n   informed of the possibility of such damages. This limitation of liability\n   shall not apply to liability for death or personal injury resulting from\n   such party's negligence to the extent applicable law prohibits such\n   limitation. Some jurisdictions do not allow the exclusion or limitation of\n   incidental or consequential damages, so this exclusion and limitation may\n   not apply to You.\n\n8. Litigation\n\n   Any litigation relating to this License may be brought only in the courts\n   of a jurisdiction where the defendant maintains its principal place of\n   business and such litigation shall be governed by laws of that\n   jurisdiction, without reference to its conflict-of-law provisions. Nothing\n   in this Section shall prevent a party's ability to bring cross-claims or\n   counter-claims.\n\n9. Miscellaneous\n\n   This License represents the complete agreement concerning the subject\n   matter hereof. If any provision of this License is held to be\n   unenforceable, such provision shall be reformed only to the extent\n   necessary to make it enforceable. Any law or regulation which provides that\n   the language of a contract shall be construed against the drafter shall not\n   be used to construe this License against a Contributor.\n\n\n10. Versions of the License\n\n10.1. New Versions\n\n      Mozilla Foundation is the license steward. Except as provided in Section\n      10.3, no one other than the license steward has the right to modify or\n      publish new versions of this License. Each version will be given a\n      distinguishing version number.\n\n10.2. Effect of New Versions\n\n      You may distribute the Covered Software under the terms of the version\n      of the License under which You originally received the Covered Software,\n      or under the terms of any subsequent version published by the license\n      steward.\n\n10.3. Modified Versions\n\n      If you create software not governed by this License, and you want to\n      create a new license for such software, you may create and use a\n      modified version of this License if you rename the license and remove\n      any references to the name of the license steward (except to note that\n      such modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary\n      Licenses If You choose to distribute Source Code Form that is\n      Incompatible With Secondary Licenses under the terms of this version of\n      the License, the notice described in Exhibit B of this License must be\n      attached.\n\nExhibit A - Source Code Form License Notice\n\n      This Source Code Form is subject to the\n      terms of the Mozilla Public License, v.\n      2.0. If a copy of the MPL was not\n      distributed with this file, You can\n      obtain one at\n      http://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular file,\nthen You may include the notice in a location (such as a LICENSE file in a\nrelevant directory) where a recipient would be likely to look for such a\nnotice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - \"Incompatible With Secondary Licenses\" Notice\n\n      This Source Code Form is \"Incompatible\n      With Secondary Licenses\", as defined by\n      the Mozilla Public License, v. 2.0.", 
            "title": "License"
        }
    ]
}